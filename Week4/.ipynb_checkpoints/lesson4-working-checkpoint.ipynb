{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set FIXED variables\n",
    "HOMEPATH = \"/home/ubuntu/fastai/\"\n",
    "\n",
    "import os, errno\n",
    "from datetime import datetime\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nb: need to install packages as below for standard aws ubuntu deep learning community AMI   \n",
    "sudo -H pip install unidecode\n",
    "sudo -H pip install bcolz  \n",
    "sudo -H pip install toolz  \n",
    "\n",
    "nb: original utils.py from https://github.com/fastai/courses.git needs fix.\n",
    "update to utils.py as per https://github.com/fastai/courses/issues/146 required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIT_REPO_PATH = \"/home/ubuntu/courses/deeplearning1/nbs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working directory: /home/ubuntu/courses/deeplearning1/nbs\n"
     ]
    }
   ],
   "source": [
    "os.chdir(GIT_REPO_PATH)\n",
    "print (\"current working directory:\", os.getcwd())\n",
    "\n",
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip  \n",
    "wget http://files.grouplens.org/datasets/movielens/ml-20m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ubuntu/fastai/data/ml-latest-small/\"\n",
    "model_path = path + 'models/'\n",
    "if not os.path.exists(model_path): os.mkdir(model_path)\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Set up data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We're working with the movielens data, which contains one rating per row, like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "userId,movieId,rating,timestamp\n",
    "1,31,2.5,1260759144\n",
    "1,1029,3.0,1260759179\n",
    "1,1061,3.0,1260759182\n",
    "1,1129,2.0,1260759185\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(path+'ratings.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100004"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Just for display purposes, let's read in the movie names too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "movieId,title,genres\n",
    "1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy\n",
    "2,Jumanji (1995),Adventure|Children|Fantasy\n",
    "3,Grumpier Old Men (1995),Comedy|Romance\n",
    "4,Waiting to Exhale (1995),Comedy|Drama|Romance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "movie_names = pd.read_csv(path+'movies.csv', encoding = 'utf8').set_index('movieId')['title']#.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "\"Great Performances\" Cats (1998)                                          1\n",
       "$9.99 (2008)                                                              1\n",
       "'Hellboy': The Seeds of Creation (2004)                                   1\n",
       "'Neath the Arizona Skies (1934)                                           1\n",
       "'Round Midnight (1986)                                                    1\n",
       "'Salem's Lot (2004)                                                       1\n",
       "'Til There Was You (1997)                                                 1\n",
       "'burbs, The (1989)                                                        1\n",
       "'night Mother (1986)                                                      1\n",
       "(500) Days of Summer (2009)                                               1\n",
       "*batteries not included (1987)                                            1\n",
       "...And God Spoke (1993)                                                   1\n",
       "...And Justice for All (1979)                                             1\n",
       "1-900 (06) (1994)                                                         1\n",
       "10 (1979)                                                                 1\n",
       "10 Attitudes (2001)                                                       1\n",
       "10 Cloverfield Lane (2016)                                                1\n",
       "10 Items or Less (2006)                                                   1\n",
       "10 Things I Hate About You (1999)                                         1\n",
       "10 Years (2011)                                                           1\n",
       "10,000 BC (2008)                                                          1\n",
       "100 Girls (2000)                                                          1\n",
       "100 Rifles (1969)                                                         1\n",
       "101 Dalmatians (1996)                                                     1\n",
       "101 Dalmatians (One Hundred and One Dalmatians) (1961)                    1\n",
       "101 Reykjavik (101 Reykjavík) (2000)                                      1\n",
       "102 Dalmatians (2000)                                                     1\n",
       "10th Kingdom, The (2000)                                                  1\n",
       "11'09\"01 - September 11 (2002)                                            1\n",
       "11:14 (2003)                                                              1\n",
       "                                                                         ..\n",
       "Zenon: Girl of the 21st Century (1999)                                    1\n",
       "Zenon: The Zequel (2001)                                                  1\n",
       "Zenon: Z3 (2004)                                                          1\n",
       "Zero Dark Thirty (2012)                                                   1\n",
       "Zero Effect (1998)                                                        1\n",
       "Zero Theorem, The (2013)                                                  1\n",
       "Zerophilia (2005)                                                         1\n",
       "Zodiac (2007)                                                             1\n",
       "Zombeavers (2014)                                                         1\n",
       "Zombie (a.k.a. Zombie 2: The Dead Are Among Us) (Zombi 2) (1979)          1\n",
       "Zombie Holocaust (a.k.a. Doctor Butcher M.D.) (Zombi Holocaust) (1980)    1\n",
       "Zombieland (2009)                                                         1\n",
       "Zoolander (2001)                                                          1\n",
       "Zoolander 2 (2016)                                                        1\n",
       "Zoom (2006)                                                               1\n",
       "Zoot Suit (1981)                                                          1\n",
       "Zootopia (2016)                                                           1\n",
       "Zorba the Greek (Alexis Zorbas) (1964)                                    1\n",
       "Zorn's Lemma (1970)                                                       1\n",
       "Zorro, the Gay Blade (1981)                                               1\n",
       "Zulu (1964)                                                               1\n",
       "Zulu (2013)                                                               1\n",
       "[REC] (2007)                                                              1\n",
       "eXistenZ (1999)                                                           1\n",
       "loudQUIETloud: A Film About the Pixies (2006)                             1\n",
       "xXx (2002)                                                                1\n",
       "xXx: State of the Union (2005)                                            1\n",
       "¡Three Amigos! (1986)                                                     1\n",
       "À nous la liberté (Freedom for Us) (1931)                                 1\n",
       "İtirazım Var (2014)                                                       1\n",
       "Name: genres, Length: 9123, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempdf = pd.DataFrame.from_csv(path+'movies.csv')\n",
    "type(tempdf), tempdf.shape, list(tempdf)\n",
    "tempdf.groupby('title')['genres'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'> (9125,)\n",
      "movieId\n",
      "1                      Toy Story (1995)\n",
      "2                        Jumanji (1995)\n",
      "3               Grumpier Old Men (1995)\n",
      "4              Waiting to Exhale (1995)\n",
      "5    Father of the Bride Part II (1995)\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (type(movie_names), movie_names.shape)  \n",
    "print (movie_names.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "users = ratings.userId.unique()\n",
    "movies = ratings.movieId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users: <type 'numpy.ndarray'> (671,)\n",
      "movies: <type 'numpy.ndarray'> (9066,)\n"
     ]
    }
   ],
   "source": [
    "print (\"users:\", type(users), users.shape)\n",
    "print (\"movies:\", type(movies), movies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users: [1 2 3 4 5]\n",
      "movies: [  31 1029 1061 1129 1172]\n"
     ]
    }
   ],
   "source": [
    "print (\"users:\", users[0:5])\n",
    "print (\"movies:\", movies[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'> 671\n",
      "<type 'dict'> 9066\n"
     ]
    }
   ],
   "source": [
    "userid2idx = {o:i for i,o in enumerate(users)}\n",
    "movieid2idx = {o:i for i,o in enumerate(movies)}\n",
    "print(type(userid2idx), len(userid2idx))\n",
    "print(type(movieid2idx), len(movieid2idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "userid2idx.keys()[0:5] (ratings.csv).userId.unique(): [1, 2, 3, 4, 5] <type 'numpy.int64'>\n",
      "movieid2idx.keys()[0:5] (ratings.csv).movieId.unique(): [1, 2, 3, 4, 5] <type 'numpy.int64'>\n",
      "1 1\n",
      "movieid2idx[2]: 650 1\n",
      "movieid2idx[3]: 319 1\n"
     ]
    }
   ],
   "source": [
    "print (next(iter(userid2idx)))\n",
    "print (next(iter(userid2idx)))\n",
    "\n",
    "print (\"userid2idx.keys()[0:5] (ratings.csv).userId.unique():\", userid2idx.keys()[0:5], type(userid2idx.keys()[0]))\n",
    "print (\"movieid2idx.keys()[0:5] (ratings.csv).movieId.unique():\", movieid2idx.keys()[0:5], type(movieid2idx.keys()[0]))\n",
    "print (userid2idx[2], list(users.flatten()).count(2))\n",
    "print (\"movieid2idx[2]:\", movieid2idx[2], list(movies.flatten()).count(2))\n",
    "print (\"movieid2idx[3]:\", movieid2idx[3], list(movies.flatten()).count(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We update the movie and user ids so that they are contiguous integers, which we want when using embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "417\n"
     ]
    }
   ],
   "source": [
    "print (type(ratings.movieId))\n",
    "print (movieid2idx[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ratings.movieId = ratings.movieId.apply(lambda x: movieid2idx[x])\n",
    "ratings.userId = ratings.userId.apply(lambda x: userid2idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 670 0 9065\n"
     ]
    }
   ],
   "source": [
    "user_min, user_max, movie_min, movie_max = (ratings.userId.min(), \n",
    "    ratings.userId.max(), ratings.movieId.min(), ratings.movieId.max())\n",
    "print (user_min, user_max, movie_min, movie_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(671, 9066)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = ratings.userId.nunique()\n",
    "n_movies = ratings.movieId.nunique()\n",
    "\n",
    "#https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.nunique.html\n",
    "#Return number of unique elements in the object.\n",
    "\n",
    "print (type(ratings.userId))\n",
    "print (type(ratings.movieId))\n",
    "n_users, n_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is the number of latent factors in each embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_factors = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.random.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Randomly split into training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ratings): 100004\n",
      "msk: <type 'numpy.ndarray'> (100004,)\n",
      "<type 'numpy.ndarray'> True\n"
     ]
    }
   ],
   "source": [
    "print (\"len(ratings):\", len(ratings))\n",
    "msk = np.random.rand(len(ratings)) < 0.8\n",
    "print (\"msk:\", type(msk), msk.shape)\n",
    "#creates numpy array of True or False values with probably 80% true\n",
    "print (type(msk), msk[0])\n",
    "trn = ratings[msk]\n",
    "val = ratings[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create subset for Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We create a crosstab of the most popular movies and most movie-addicted users which we'll copy into Excel for creating a simple example. This isn't necessary for any of the modeling below however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print (ratings.shape)\n",
    "print (ratings[0:4])\n",
    "\n",
    "g=ratings.groupby('userId')['rating'].count()\n",
    "#group by 'userId', 'rating', count rows\n",
    "\n",
    "print (type(g), g.shape)\n",
    "print (g[0:4])\n",
    "print (g.sort_values(ascending=False)[0:5])\n",
    "topUsers=g.sort_values(ascending=False)[:15]\n",
    "#select top 15 users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "g=ratings.groupby('movieId')['rating'].count()\n",
    "topMovies=g.sort_values(ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_r = ratings.join(topUsers, rsuffix='_r', how='inner', on='userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_r = top_r.join(topMovies, rsuffix='_r', how='inner', on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(top_r.userId, top_r.movieId, top_r.rating, aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "## Dot product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The most basic model is a dot product of a movie embedding and a user embedding. Let's see how well that works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "user_in = Input(shape=(1,), dtype='int64', name='user_in')\n",
    "u = Embedding(n_users, n_factors, input_length=1, W_regularizer=l2(1e-4))(user_in)\n",
    "movie_in = Input(shape=(1,), dtype='int64', name='movie_in')\n",
    "m = Embedding(n_movies, n_factors, input_length=1, W_regularizer=l2(1e-4))(movie_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = merge([u, m], mode='dot')\n",
    "x = Flatten()(x)\n",
    "model = Model([user_in, movie_in], x)\n",
    "#https://keras.io/models/model/\n",
    "\n",
    "model.compile(Adam(0.001), loss='mse')\n",
    "print (type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.fit([trn.userId, trn.movieId], trn.rating, batch_size=64, nb_epoch=1, \n",
    "          validation_data=([val.userId, val.movieId], val.rating))\n",
    "#github gets loss: 9.8328 - val_loss: 3.7591 cf loss: 9.9450 - val_loss: 4.3126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print (\"start\")\n",
    "startTime= datetime.now()\n",
    "model.fit([trn.userId, trn.movieId], trn.rating, batch_size=64, nb_epoch=3, \n",
    "          validation_data=([val.userId, val.movieId], val.rating))\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print (\"start\")\n",
    "startTime= datetime.now()\n",
    "model.fit([trn.userId, trn.movieId], trn.rating, batch_size=64, nb_epoch=6, \n",
    "          validation_data=([val.userId, val.movieId], val.rating))\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "#github = loss: 2.0673 - val_loss: 1.4457 vs loss: 2.0542 - val_loss: 2.5753\n",
    "#nb: loss is reducing, val_loss is not. loss is much less than val_loss overtraining?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The [best benchmarks](http://www.librec.net/example.html) are a bit over 0.9, so this model doesn't seem to be working that well..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The problem is likely to be that we don't have bias terms - that is, a single bias for each user and each movie representing how positive or negative each user is, and how good each movie is. We can add that easily by simply creating an embedding with one output for each movie and each user, and adding it to our output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out, reg):\n",
    "    inp = Input(shape=(1,), dtype='int64', name=name)\n",
    "    return inp, Embedding(n_in, n_out, input_length=1, W_regularizer=l2(reg))(inp)\n",
    "#refer lesson 5 video @ 14\"40'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "user_in, u = embedding_input('user_in', n_users, n_factors, 1e-4)\n",
    "movie_in, m = embedding_input('movie_in', n_movies, n_factors, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_bias(inp, n_in):\n",
    "    x = Embedding(n_in, 1, input_length=1)(inp)\n",
    "    return Flatten()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ub = create_bias(user_in, n_users)\n",
    "mb = create_bias(movie_in, n_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refer video lesson 5 @ 27\"08'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = merge([u, m], mode='dot')\n",
    "x = Flatten()(x)\n",
    "x = merge([x, ub], mode='sum')\n",
    "x = merge([x, mb], mode='sum')\n",
    "model = Model([user_in, movie_in], x)\n",
    "model.compile(Adam(0.001), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.fit([trn.userId, trn.movieId], trn.rating, batch_size=64, nb_epoch=1, \n",
    "          validation_data=([val.userId, val.movieId], val.rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.fit([trn.userId, trn.movieId], trn.rating, batch_size=64, nb_epoch=20, \n",
    "          validation_data=([val.userId, val.movieId], val.rating))\n",
    "#github result = loss: 0.5747 - val_loss: 0.7979 vs my result after 6 epochs loss: 1.5886 - val_loss: 1.7878\n",
    "#very bad result by comparison.\n",
    "#after 20 epochs,  loss: 0.6405 - val_loss: 1.0564 both losses are consistently reducing. \n",
    "#loss is << val_loss so overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "model.fit([trn.userId, trn.movieId], trn.rating, batch_size=64, nb_epoch=20, \n",
    "          validation_data=([val.userId, val.movieId], val.rating))\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "#ran with 10 epochs then again with 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "model.fit([trn.userId, trn.movieId], trn.rating, batch_size=64, nb_epoch=20, \n",
    "          validation_data=([val.userId, val.movieId], val.rating))\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "#NB: video lecture val_loss is down to 0.7979 = refer lesson 5 @ 15\"07'\n",
    "#github results : loss: 0.5747 - val_loss: 0.7979\n",
    "#ran w 5 epochs, loss is stabilising around 0.523 val_loss stabilising around 1.03\n",
    "#quite different margins to the examples in github and video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This result is quite a bit better than the best benchmarks that we could find with a quick google search - so looks like a great approach!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights(model_path+'bias.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#model.load_weights(model_path+'bias.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can use the model to generate predictions by passing a pair of ints - a user id and a movie id. For instance, this predicts that user #3 would really enjoy movie #6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.predict([np.array([3]), np.array([6])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To make the analysis of the factors more interesting, we'll restrict it to the top 2000 most popular movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "g=ratings.groupby('movieId')['rating'].count()\n",
    "topMovies=g.sort_values(ascending=False)[:2000]\n",
    "topMovies = np.array(topMovies.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First, we'll look at the movie bias term. We create a 'model' - which in keras is simply a way of associating one or more inputs with one more more outputs, using the functional API. Here, our input is the movie id (a single id), and the output is the movie bias (a single float)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(movie_in))\n",
    "print (type(mb))\n",
    "print (type(topMovies), topMovies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_movie_bias = Model(movie_in, mb)\n",
    "#does a lookup in the movie bias table\n",
    "#keras.models.Model\n",
    "movie_bias = get_movie_bias.predict(topMovies)\n",
    "movie_ratings = [(b[0], movie_names[movies[i]]) for i,b in zip(topMovies,movie_bias)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can look at the top and bottom rated movies. These ratings are corrected for different levels of reviewer sentiment, as well as different types of movies that different reviewers watch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted(movie_ratings, key=itemgetter(0))[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted(movie_ratings, key=itemgetter(0), reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can now do the same thing for the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_movie_emb = Model(movie_in, m)\n",
    "movie_emb = np.squeeze(get_movie_emb.predict([topMovies]))\n",
    "movie_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Because it's hard to interpret 50 embeddings, we use [PCA](https://plot.ly/ipython-notebooks/principal-component-analysis/) to simplify them down to just 3 vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "movie_pca = pca.fit(movie_emb.T).components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fac0 = movie_pca[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "movie_comp = [(f, movie_names[movies[i]]) for f,i in zip(fac0, topMovies)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here's the 1st component. It seems to be 'critically acclaimed' or 'classic'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted(movie_comp, key=itemgetter(0), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted(movie_comp, key=itemgetter(0))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fac1 = movie_pca[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "movie_comp = [(f, movie_names[movies[i]]) for f,i in zip(fac1, topMovies)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The 2nd is 'hollywood blockbuster'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted(movie_comp, key=itemgetter(0), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(movie_comp, key=itemgetter(0))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fac2 = movie_pca[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "movie_comp = [(f, movie_names[movies[i]]) for f,i in zip(fac2, topMovies)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The 3rd is 'violent vs happy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted(movie_comp, key=itemgetter(0), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted(movie_comp, key=itemgetter(0))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can draw a picture to see how various movies appear on the map of these components. This picture shows the 1st and 3rd components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "stdout, stderr = sys.stdout, sys.stderr # save notebook stdout and stderr\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout, sys.stderr = stdout, stderr # restore notebook stdout and stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=50; end=100\n",
    "X = fac0[start:end]\n",
    "Y = fac2[start:end]\n",
    "print (type(X), X.shape)\n",
    "print (type(Y), Y.shape)\n",
    "\n",
    "print (type(topMovies), topMovies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(X, Y)\n",
    "for i, x, y in zip(topMovies[start:end], X, Y):\n",
    "    plt.text(x,y,movie_names[movies[i]], color=np.random.rand(3)*0.7, fontsize=14)\n",
    "    #print (x,y,movies[i], movie_names[movies[i]])\n",
    "    #plt.text(x,y,movie_names[movies[i]], color='red', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than creating a special purpose architecture (like our dot-product with bias earlier), it's often both easier and more accurate to use a standard neural network. Let's try it! Here, we simply concatenate the user and movie embeddings into a single vector, which we feed into the neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_in, u = embedding_input('user_in', n_users, n_factors, 1e-4)\n",
    "movie_in, m = embedding_input('movie_in', n_movies, n_factors, 1e-4)\n",
    "print (\"user_in:\", type(user_in))\n",
    "print (\"movie_in:\", type(movie_in))\n",
    "print (\"u:\", type(u))\n",
    "print (\"m:\", type(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = merge([u, m], mode='concat')\n",
    "print (\"x:\", type(x))\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(70, activation='relu')(x)\n",
    "x = Dropout(0.75)(x)\n",
    "x = Dense(1)(x)\n",
    "nn = Model([user_in, movie_in], x)\n",
    "print (\"nn:\", type(nn), type(nn.layers))\n",
    "print (\"type(nn.layers[0]:\", type(nn.layers[0]))\n",
    "print (nn.summary())\n",
    "nn.compile(Adam(0.001), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.fit([trn.userId, trn.movieId], trn.rating, batch_size=64, nb_epoch=40, \n",
    "          validation_data=([val.userId, val.movieId], val.rating))\n",
    "\n",
    "#lesson 5 video @ 15\"15' returned val_loss 0.7943"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This improves on our already impressive accuracy even further!\n",
    "\n",
    "Epoch 8/8\n",
    "79907/79907 [==============================] - 13s - loss: 0.8087 - val_loss: 0.8274\n",
    "\n",
    "after 8 epochs : loss: 0.8078 - val_loss: 0.8307\n",
    "running again w 2- epochs : "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
