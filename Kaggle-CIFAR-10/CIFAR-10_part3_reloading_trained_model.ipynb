{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('DATA_WORKING      :', '/home/ubuntu/fastai/data/cifar-10/sample/')\n",
      "('DATA_WORKING_RESULTS:', '/home/ubuntu/fastai/data/cifar-10/sample/results/')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "HOMEPATH = \"/home/ubuntu/fastai/\"\n",
    "DATA_HOME_DIR = HOMEPATH + \"data/cifar-10/\"\n",
    "DATA_WORKING = DATA_HOME_DIR + \"sample/\"\n",
    "DATA_WORKING_RESULTS = DATA_WORKING + \"results/\"\n",
    "\n",
    "print (\"DATA_WORKING      :\", DATA_WORKING)\n",
    "print (\"DATA_WORKING_RESULTS:\", DATA_WORKING_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5110)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model #move this to top when run complete.\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"----------------\")\n",
    "def set_keras_backend(backend):\n",
    "\n",
    "    if K.backend() != backend:\n",
    "        os.environ['KERAS_BACKEND'] = backend\n",
    "        reload(K)\n",
    "        assert K.backend() == backend\n",
    "\n",
    "set_keras_backend(\"theano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('os.getcwd:', '/home/ubuntu/fastai')\n"
     ]
    }
   ],
   "source": [
    "os.chdir(HOMEPATH)\n",
    "print (\"os.getcwd:\", os.getcwd())\n",
    "# Rather than importing everything manually, we'll make things easy\n",
    "#   and load them all in utils.py, and just import them from there.\n",
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from utils import plots, get_batches, plot_confusion_matrix, get_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('os.getcwd:', '/home/ubuntu/fastai')\n"
     ]
    }
   ],
   "source": [
    "os.chdir(HOMEPATH)\n",
    "print (\"os.getcwd:\", os.getcwd())\n",
    "%matplotlib inline\n",
    "from __future__ import division,print_function\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from random import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = HOMEPATH + \"data/dogscats/sample/\"\n",
    "path = DATA_HOME_DIR \n",
    "#path = DATA_HOME_DIR + \"sample/\"\n",
    "train_path = path + 'train/'\n",
    "test_path = path + 'test/'\n",
    "testUnknown_path = path + 'test/unknown/'\n",
    "valid_path = path + 'valid/'\n",
    "model_path = path + 'models/'\n",
    "sample_path = path + 'sample/'\n",
    "sampleTrain_path = path + 'sample/train/'\n",
    "sampleTest_path = path + 'sample/test/'\n",
    "sampleValid_path = path + 'sample/valid/'\n",
    "sampleResults_path = path + 'sample/results/'\n",
    "sampleTestUnknown_path = path + 'sample/test/unknown/'\n",
    "\n",
    "categories = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirFileList(dir_path):\n",
    "    return [name for name in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, name))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/airplane : 2048\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/automobile : 2048\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/bird : 2048\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/cat : 2048\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/deer : 2048\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/dog : 2048\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/frog : 2048\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/horse : 2048\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/ship : 2048\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/truck : 2048\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/airplane : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/automobile : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/bird : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/cat : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/deer : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/dog : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/frog : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/horse : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/ship : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/truck : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/airplane : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/automobile : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/bird : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/cat : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/deer : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/dog : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/frog : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/horse : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/ship : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/truck : 1312\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/airplane : 328\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/automobile : 328\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/bird : 328\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/cat : 328\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/deer : 328\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/dog : 328\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/frog : 328\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/horse : 328\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/ship : 328\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/truck : 328\n"
     ]
    }
   ],
   "source": [
    "dirList = [train_path, valid_path, sampleTrain_path, sampleValid_path]\n",
    "\n",
    "for dir_path in dirList:\n",
    "    for category in categories:\n",
    "        print (\"# of files in\", dir_path+category, \":\", len(dirFileList(dir_path+category)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(vgg): <type 'instance'>\n",
      "type(model): <class 'keras.models.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "vgg = Vgg16()\n",
    "model = vgg.model\n",
    "print (\"type(vgg):\", type(vgg))\n",
    "print (\"type(model):\", type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showLayersInfo(model):\n",
    "    print (\"Number of layers : \", len(model.layers))\n",
    "    for layer in model.layers:\n",
    "        print (type(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers :  38\n",
      "<class 'keras.layers.core.Lambda'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.core.Flatten'>\n",
      "<class 'keras.layers.core.Dense'>\n",
      "<class 'keras.layers.core.Dropout'>\n",
      "<class 'keras.layers.core.Dense'>\n",
      "<class 'keras.layers.core.Dropout'>\n",
      "<class 'keras.layers.core.Dense'>\n"
     ]
    }
   ],
   "source": [
    "showLayersInfo(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 3, 224, 224)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 224, 224)  1792        zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 64, 226, 226)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 224, 224)  36928       zeropadding2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 112, 112) 73856       zeropadding2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 128, 114, 114) 0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 128, 112, 112) 147584      zeropadding2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 128, 58, 58)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 56, 56)   295168      zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 256, 30, 30)   0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 512, 28, 28)   1180160     zeropadding2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 512, 30, 30)   0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 28, 28)   2359808     zeropadding2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25088)         0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096)          102764544   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4096)          16781312    dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4096)          0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1000)          4097000     dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 2017-12-14 02:32:50.899441\n",
      "Found 3280 images belonging to 10 classes.\n",
      "val_batches: Time elapsed (hh:mm:ss.ms) 0:00:00.105788\n",
      "\n",
      "\n",
      "startTime: 2017-12-14 02:32:51.005554\n",
      "Found 13120 images belonging to 10 classes.\n",
      "batches : Time elapsed (hh:mm:ss.ms) 0:00:00.317985\n"
     ]
    }
   ],
   "source": [
    "# Use batch size of 1 since we're just doing preprocessing on the CPU\n",
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "val_batches = get_batches(DATA_WORKING+'valid/', shuffle=False, batch_size=1)\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('val_batches: Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "print (\"\\n\")\n",
    "\n",
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "batches     = get_batches(DATA_WORKING+'train/', shuffle=False, batch_size=1)\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('batches : Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_WORKING: /home/ubuntu/fastai/data/cifar-10/sample/\n"
     ]
    }
   ],
   "source": [
    "print(\"DATA_WORKING:\", DATA_WORKING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras returns *classes* as a single column, so we convert to one hot encoding\n",
    "def onehot(x): \n",
    "    return np.array(OneHotEncoder().fit_transform(x.reshape(-1,1)).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_classes: <type 'numpy.ndarray'> (3280,)\n",
      "val_classes[0:10]: [0 0 0 0 0 0 0 0 0 0]\n",
      "trn_classes: <type 'numpy.ndarray'> (13120,)\n",
      "trn_classes[0:10]: [0 0 0 0 0 0 0 0 0 0]\n",
      "after onehot conversion.\n",
      "val_labels: [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "trn_labels: [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "val_classes = val_batches.classes\n",
    "trn_classes = batches.classes\n",
    "print (\"val_classes:\", type(val_classes), val_classes.shape)\n",
    "print(\"val_classes[0:10]:\", val_classes[0:10])\n",
    "print (\"trn_classes:\", type(trn_classes), trn_classes.shape)\n",
    "print(\"trn_classes[0:10]:\", trn_classes[0:10])\n",
    "val_labels = onehot(val_classes)\n",
    "trn_labels = onehot(trn_classes)\n",
    "print (\"after onehot conversion.\")\n",
    "print (\"val_labels:\", val_labels[0])\n",
    "print (\"trn_labels:\", trn_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_WORKING_RESULTS: /home/ubuntu/fastai/data/cifar-10/sample/results/\n",
      "/home/ubuntu/fastai/data/cifar-10/sample/results/train_data.bc\n",
      "trn_data: <type 'numpy.ndarray'> (8000, 3, 224, 224)\n",
      "val_data: <type 'numpy.ndarray'> (2000, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "print (\"DATA_WORKING_RESULTS:\", DATA_WORKING_RESULTS)\n",
    "print (DATA_WORKING_RESULTS+'train_data.bc')\n",
    "trn_data = load_array(DATA_WORKING_RESULTS+'train_data.bc')\n",
    "val_data = load_array(DATA_WORKING_RESULTS+'valid_data.bc')\n",
    "print (\"trn_data:\", type(trn_data), trn_data.shape)#should return trn_data: <type 'numpy.ndarray'> (8000, 3, 224, 224)\n",
    "print (\"val_data:\", type(val_data), val_data.shape)#should return val_data: <type 'numpy.ndarray'> (2000, 3, 224, 224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_features = load_array(DATA_WORKING_RESULTS+'train_lastlayer_features.bc')\n",
    "val_features = load_array(DATA_WORKING_RESULTS+'valid_lastlayer_features.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 2017-12-14 02:32:59.297303\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.019583\n"
     ]
    }
   ],
   "source": [
    "# 1000 inputs, since that's the saved features, and 10 outputs, for # of categories\n",
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "\n",
    "\n",
    "lm = Sequential([ Dense(10, activation='softmax', input_shape=(1000,)) ])\n",
    "lm.compile(optimizer=RMSprop(lr=0.1), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_features: <type 'numpy.ndarray'> (8000, 1000)\n",
      "trn_labels: <type 'numpy.ndarray'> (13120, 10)\n",
      "val_features: <type 'numpy.ndarray'> (2000, 1000)\n",
      "val_labels: <type 'numpy.ndarray'> (3280, 10)\n"
     ]
    }
   ],
   "source": [
    "print (\"trn_features:\", type(trn_features), trn_features.shape)\n",
    "print (\"trn_labels:\", type(trn_labels), trn_labels.shape)\n",
    "print (\"val_features:\", type(val_features), val_features.shape)\n",
    "print (\"val_labels:\", type(val_labels), val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input arrays should have the same number of samples as target arrays. Found 8000 input samples and 13120 target samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-cc7b4c0ce3f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m lm.fit(trn_features, trn_labels, nb_epoch=3, batch_size=batch_size, \n\u001b[0;32m----> 2\u001b[0;31m        validation_data=(val_features, val_labels))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1117\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1039\u001b[0m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                           in zip(y, sample_weights, class_weights, self.sample_weight_modes)]\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0mcheck_array_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m         \u001b[0mcheck_loss_and_target_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_output_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mcheck_array_lengths\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    191\u001b[0m                          \u001b[0;34m'the same number of samples as target arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                          \u001b[0;34m'Found '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input samples '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                          'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         raise ValueError('Sample_weight arrays should have '\n",
      "\u001b[0;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 8000 input samples and 13120 target samples."
     ]
    }
   ],
   "source": [
    "lm.fit(trn_features, trn_labels, nb_epoch=3, batch_size=batch_size, \n",
    "       validation_data=(val_features, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(lm))\n",
    "print (lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lm.predict_classes(val_features, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilities of each category results in numpy array with column for each category.\n",
    "probs = lm.predict_proba(val_features, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = val_batches.filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(val_classes, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"before pop, # of layers:\", len(model.layers))\n",
    "model.pop()\n",
    "print (\"after pop, # of layers:\", len(model.layers))\n",
    "for layer in model.layers: layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(vgg.model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))#NB: Dense requires 10 because 10 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"after adding dense layer, # of layers:\", len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"# of layers:\", len(model.layers))\n",
    "for layer in model.layers:\n",
    "    print (type(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = model.layers\n",
    "# Get the index of the first dense layer...\n",
    "first_dense_idx = [index for index,layer in enumerate(layers) if type(layer) is Dense][0]\n",
    "print (type(first_dense_idx), first_dense_idx)\n",
    "# ...and set this and all subsequent layers to trainable\n",
    "for layer in layers[first_dense_idx:]: \n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "model.load_weights(DATA_WORKING_RESULTS+'finetune2.h5')\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = RMSprop(lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in layers[12:]: layer.trainable=True\n",
    "K.set_value(opt.lr, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(DATA_WORKING_RESULTS+'finetune3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lm.predict_classes(val_features, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(val_classes, preds)\n",
    "plot_confusion_matrix(cm, val_batches.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, batches, val_batches, nb_epoch=1):\n",
    "    model.fit_generator(batches, \n",
    "                        samples_per_epoch=batches.n, \n",
    "                        nb_epoch=nb_epoch, \n",
    "                        validation_data=val_batches, \n",
    "                        nb_val_samples=val_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = RMSprop(lr=0.1)\n",
    "#https://keras.io/optimizers/#rmsprop\n",
    "#This optimizer is usually a good choice for recurrent neural networks.\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fit_model(model, batches, val_batches, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_classes(val_data, batch_size=batch_size)\n",
    "probs = model.predict_proba(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
