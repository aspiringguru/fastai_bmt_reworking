{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_or_prod = True #True = sample, False = production\n",
    "\n",
    "train_valid_fract = 0.3\n",
    "sample_fract = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('HOMEPATH:', '/home/ubuntu/fastai/')\n",
      "('DATA_PATH:', '/home/ubuntu/fastai/data/fish/')\n"
     ]
    }
   ],
   "source": [
    "HOMEPATH = \"/home/ubuntu/fastai/\"\n",
    "DATA_PATH = HOMEPATH + \"data/fish/\"\n",
    "print(\"HOMEPATH:\", HOMEPATH)\n",
    "print(\"DATA_PATH:\", DATA_PATH)\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from random import shuffle\n",
    "from shutil import copyfile\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.getcwd: /home/ubuntu/fastai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(HOMEPATH)\n",
    "print (\"os.getcwd:\", os.getcwd())\n",
    "\n",
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"data/fish/sample/\"\n",
    "path = DATA_PATH\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING_DATA: /home/ubuntu/fastai/data/fish/sample/\n",
      "WORKING_TEST: /home/ubuntu/fastai/data/fish/sample/test/\n",
      "WORKING_TRAIN: /home/ubuntu/fastai/data/fish/sample/train/\n",
      "WORKING_VALID: /home/ubuntu/fastai/data/fish/sample/valid/\n",
      "s_or_p: _sample_\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = DATA_PATH+\"models/\"\n",
    "RESULTS_PATH = DATA_PATH+\"results/\"\n",
    "\n",
    "\n",
    "SAMPLE_DATA_PATH = DATA_PATH + \"sample/\"#choose this for testing or above for production\n",
    "SAMPLE_TEST_PATH = SAMPLE_DATA_PATH+\"test/\"\n",
    "SAMPLE_TRAIN_PATH = SAMPLE_DATA_PATH + \"train/\"\n",
    "SAMPLE_VALID_PATH = SAMPLE_DATA_PATH + \"valid/\"\n",
    "\n",
    "\n",
    "TEST_PATH = DATA_PATH+\"test/\"\n",
    "TRAIN_PATH = DATA_PATH + \"train/\"\n",
    "VALID_PATH = DATA_PATH + \"valid/\"\n",
    "\n",
    "if sample_or_prod:\n",
    "    WORKING_DATA  = SAMPLE_DATA_PATH\n",
    "    WORKING_TEST  = SAMPLE_TEST_PATH\n",
    "    WORKING_TRAIN = SAMPLE_TRAIN_PATH\n",
    "    WORKING_VALID = SAMPLE_VALID_PATH\n",
    "    s_or_p = \"_sample_\"\n",
    "else:\n",
    "    WORKING_DATA  = DATA_PATH\n",
    "    WORKING_TEST  = TEST_PATH\n",
    "    WORKING_TRAIN = TRAIN_PATH\n",
    "    WORKING_VALID = VALID_PATH\n",
    "    s_or_p = \"_prod_\"\n",
    "\n",
    "    \n",
    "print (\"WORKING_DATA:\", WORKING_DATA)\n",
    "print (\"WORKING_TEST:\", WORKING_TEST)\n",
    "print (\"WORKING_TRAIN:\", WORKING_TRAIN)\n",
    "print (\"WORKING_VALID:\", WORKING_VALID)\n",
    "print (\"s_or_p:\", s_or_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_PATH: /home/ubuntu/fastai/data/fish/train/\n",
      "CATEGORIES: ['OTHER', 'LAG', 'ALB', 'NoF', 'BET', 'SHARK', 'DOL', 'YFT']\n",
      "CATEGORIES: ['OTHER/', 'LAG/', 'ALB/', 'NoF/', 'BET/', 'SHARK/', 'DOL/', 'YFT/']\n"
     ]
    }
   ],
   "source": [
    "#since this dataset unzips files into category subdirectories we can obtain categories from a directory list.\n",
    "print (\"TRAIN_PATH:\", TRAIN_PATH)\n",
    "CATEGORIES = list(os.walk(TRAIN_PATH))[0][1]\n",
    "print (\"CATEGORIES:\", CATEGORIES)\n",
    "for i in range(len(CATEGORIES)):\n",
    "    CATEGORIES[i] = CATEGORIES[i] + \"/\"\n",
    "print (\"CATEGORIES:\", CATEGORIES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirFileList(dir_path):\n",
    "    return [name for name in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, name))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listDirsFileCount(DATA_DIR_LIST):\n",
    "    DATA_DIR_LIST = sorted(DATA_DIR_LIST)\n",
    "    for dir_ in DATA_DIR_LIST:\n",
    "        try:\n",
    "            numFiles = len(dirFileList(dir_))\n",
    "            print (dir_, numFiles)\n",
    "        except Exception as e: \n",
    "            print(\"\\nlistDirsFileCount:\"+dir_+\"\\n\"+ str(e)+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if dir exists, create if not already.\n",
    "def makeNewDir(newDirPath):\n",
    "    if not os.path.exists(newDirPath): \n",
    "        print(\"directory \", newDirPath, \" did not exist, creating:\")\n",
    "        os.mkdir(newDirPath)\n",
    "    else:\n",
    "        print(\"directory \", newDirPath, \"already existed. filecount = \", len(dirFileList(newDirPath)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory  /home/ubuntu/fastai/data/fish/sample/ already existed. filecount =  0\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/test/ already existed. filecount =  0\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/test/unknown/ already existed. filecount =  200\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/train/ already existed. filecount =  0\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/valid/ already existed. filecount =  0\n",
      "directory  /home/ubuntu/fastai/data/fish/models/ already existed. filecount =  0\n",
      "directory  /home/ubuntu/fastai/data/fish/results/ already existed. filecount =  0\n",
      "directory  /home/ubuntu/fastai/data/fish/test/ already existed. filecount =  0\n",
      "directory  /home/ubuntu/fastai/data/fish/test/unknown/ already existed. filecount =  1000\n",
      "directory  /home/ubuntu/fastai/data/fish/train/ already existed. filecount =  1\n",
      "directory  /home/ubuntu/fastai/data/fish/valid/ already existed. filecount =  0\n",
      "directory  /home/ubuntu/fastai/data/fish/train/OTHER/ already existed. filecount =  210\n",
      "directory  /home/ubuntu/fastai/data/fish/valid/OTHER/ already existed. filecount =  89\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/train/OTHER/ already existed. filecount =  42\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/valid/OTHER/ already existed. filecount =  17\n",
      "directory  /home/ubuntu/fastai/data/fish/train/LAG/ already existed. filecount =  47\n",
      "directory  /home/ubuntu/fastai/data/fish/valid/LAG/ already existed. filecount =  20\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/train/LAG/ already existed. filecount =  9\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/valid/LAG/ already existed. filecount =  4\n",
      "directory  /home/ubuntu/fastai/data/fish/train/ALB/ already existed. filecount =  1204\n",
      "directory  /home/ubuntu/fastai/data/fish/valid/ALB/ already existed. filecount =  515\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/train/ALB/ already existed. filecount =  240\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/valid/ALB/ already existed. filecount =  103\n",
      "directory  /home/ubuntu/fastai/data/fish/train/NoF/ already existed. filecount =  326\n",
      "directory  /home/ubuntu/fastai/data/fish/valid/NoF/ already existed. filecount =  139\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/train/NoF/ already existed. filecount =  65\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/valid/NoF/ already existed. filecount =  27\n",
      "directory  /home/ubuntu/fastai/data/fish/train/BET/ already existed. filecount =  140\n",
      "directory  /home/ubuntu/fastai/data/fish/valid/BET/ already existed. filecount =  60\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/train/BET/ already existed. filecount =  28\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/valid/BET/ already existed. filecount =  12\n",
      "directory  /home/ubuntu/fastai/data/fish/train/SHARK/ already existed. filecount =  124\n",
      "directory  /home/ubuntu/fastai/data/fish/valid/SHARK/ already existed. filecount =  52\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/train/SHARK/ already existed. filecount =  24\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/valid/SHARK/ already existed. filecount =  10\n",
      "directory  /home/ubuntu/fastai/data/fish/train/DOL/ already existed. filecount =  82\n",
      "directory  /home/ubuntu/fastai/data/fish/valid/DOL/ already existed. filecount =  35\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/train/DOL/ already existed. filecount =  16\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/valid/DOL/ already existed. filecount =  7\n",
      "directory  /home/ubuntu/fastai/data/fish/train/YFT/ already existed. filecount =  514\n",
      "directory  /home/ubuntu/fastai/data/fish/valid/YFT/ already existed. filecount =  220\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/train/YFT/ already existed. filecount =  102\n",
      "directory  /home/ubuntu/fastai/data/fish/sample/valid/YFT/ already existed. filecount =  44\n"
     ]
    }
   ],
   "source": [
    "UNKNOWN = 'unknown/'\n",
    "\n",
    "#NB: train and test are created by unzipping the data.\n",
    "makeNewDir(SAMPLE_DATA_PATH)\n",
    "makeNewDir(SAMPLE_TEST_PATH)\n",
    "makeNewDir(SAMPLE_TEST_PATH+UNKNOWN)\n",
    "makeNewDir(SAMPLE_TRAIN_PATH)\n",
    "makeNewDir(SAMPLE_VALID_PATH)\n",
    "\n",
    "makeNewDir(MODEL_PATH)\n",
    "makeNewDir(RESULTS_PATH)\n",
    "\n",
    "makeNewDir(TEST_PATH)\n",
    "makeNewDir(TEST_PATH+UNKNOWN)\n",
    "makeNewDir(TRAIN_PATH)\n",
    "makeNewDir(VALID_PATH)\n",
    "\n",
    "DATA_DIR_LIST = [DATA_PATH, SAMPLE_DATA_PATH, SAMPLE_TEST_PATH, SAMPLE_TEST_PATH+UNKNOWN, SAMPLE_TRAIN_PATH, \n",
    "                 SAMPLE_VALID_PATH, TEST_PATH, TEST_PATH+UNKNOWN, TRAIN_PATH, VALID_PATH, MODEL_PATH, RESULTS_PATH]\n",
    "\n",
    "\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    makeNewDir(TRAIN_PATH+category)\n",
    "    makeNewDir(VALID_PATH+category)\n",
    "    makeNewDir(SAMPLE_TRAIN_PATH+category)\n",
    "    makeNewDir(SAMPLE_VALID_PATH+category)\n",
    "    #\n",
    "    DATA_DIR_LIST.append(TRAIN_PATH+category)\n",
    "    DATA_DIR_LIST.append(VALID_PATH+category)\n",
    "    DATA_DIR_LIST.append(SAMPLE_TRAIN_PATH+category)\n",
    "    DATA_DIR_LIST.append(SAMPLE_VALID_PATH+category)\n",
    "    \n",
    "DATA_DIR_LIST.append(DATA_PATH + \"test_stg1/\") #destination for unzipped files from kaggle\n",
    "DATA_DIR_LIST.append(DATA_PATH + \"test_stg2/\") #destination for unzipped files from kaggle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastai/data/fish/ 7\n",
      "/home/ubuntu/fastai/data/fish/models/ 0\n",
      "/home/ubuntu/fastai/data/fish/results/ 0\n",
      "/home/ubuntu/fastai/data/fish/sample/ 0\n",
      "/home/ubuntu/fastai/data/fish/sample/test/ 0\n",
      "/home/ubuntu/fastai/data/fish/sample/test/unknown/ 200\n",
      "/home/ubuntu/fastai/data/fish/sample/train/ 0\n",
      "/home/ubuntu/fastai/data/fish/sample/train/ALB/ 240\n",
      "/home/ubuntu/fastai/data/fish/sample/train/BET/ 28\n",
      "/home/ubuntu/fastai/data/fish/sample/train/DOL/ 16\n",
      "/home/ubuntu/fastai/data/fish/sample/train/LAG/ 9\n",
      "/home/ubuntu/fastai/data/fish/sample/train/NoF/ 65\n",
      "/home/ubuntu/fastai/data/fish/sample/train/OTHER/ 42\n",
      "/home/ubuntu/fastai/data/fish/sample/train/SHARK/ 24\n",
      "/home/ubuntu/fastai/data/fish/sample/train/YFT/ 102\n",
      "/home/ubuntu/fastai/data/fish/sample/valid/ 0\n",
      "/home/ubuntu/fastai/data/fish/sample/valid/ALB/ 103\n",
      "/home/ubuntu/fastai/data/fish/sample/valid/BET/ 12\n",
      "/home/ubuntu/fastai/data/fish/sample/valid/DOL/ 7\n",
      "/home/ubuntu/fastai/data/fish/sample/valid/LAG/ 4\n",
      "/home/ubuntu/fastai/data/fish/sample/valid/NoF/ 27\n",
      "/home/ubuntu/fastai/data/fish/sample/valid/OTHER/ 17\n",
      "/home/ubuntu/fastai/data/fish/sample/valid/SHARK/ 10\n",
      "/home/ubuntu/fastai/data/fish/sample/valid/YFT/ 44\n",
      "/home/ubuntu/fastai/data/fish/test/ 0\n",
      "/home/ubuntu/fastai/data/fish/test/unknown/ 1000\n",
      "/home/ubuntu/fastai/data/fish/test_stg1/ 0\n",
      "\n",
      "listDirsFileCount:/home/ubuntu/fastai/data/fish/test_stg2/\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/fastai/data/fish/test_stg2/'\n",
      "\n",
      "/home/ubuntu/fastai/data/fish/train/ 1\n",
      "/home/ubuntu/fastai/data/fish/train/ALB/ 1204\n",
      "/home/ubuntu/fastai/data/fish/train/BET/ 140\n",
      "/home/ubuntu/fastai/data/fish/train/DOL/ 82\n",
      "/home/ubuntu/fastai/data/fish/train/LAG/ 47\n",
      "/home/ubuntu/fastai/data/fish/train/NoF/ 326\n",
      "/home/ubuntu/fastai/data/fish/train/OTHER/ 210\n",
      "/home/ubuntu/fastai/data/fish/train/SHARK/ 124\n",
      "/home/ubuntu/fastai/data/fish/train/YFT/ 514\n",
      "/home/ubuntu/fastai/data/fish/valid/ 0\n",
      "/home/ubuntu/fastai/data/fish/valid/ALB/ 515\n",
      "/home/ubuntu/fastai/data/fish/valid/BET/ 60\n",
      "/home/ubuntu/fastai/data/fish/valid/DOL/ 35\n",
      "/home/ubuntu/fastai/data/fish/valid/LAG/ 20\n",
      "/home/ubuntu/fastai/data/fish/valid/NoF/ 139\n",
      "/home/ubuntu/fastai/data/fish/valid/OTHER/ 89\n",
      "/home/ubuntu/fastai/data/fish/valid/SHARK/ 52\n",
      "/home/ubuntu/fastai/data/fish/valid/YFT/ 220\n"
     ]
    }
   ],
   "source": [
    "listDirsFileCount(DATA_DIR_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastai/data/fish\n",
      "\u001b[01;34m.\u001b[00m\r\n",
      "├── \u001b[01;34mannos\u001b[00m\r\n",
      "├── \u001b[01;34m__MACOSX\u001b[00m\r\n",
      "│   └── \u001b[01;34mtrain\u001b[00m\r\n",
      "├── \u001b[01;34mmodels\u001b[00m\r\n",
      "├── \u001b[01;34mresults\u001b[00m\r\n",
      "├── \u001b[01;34msample\u001b[00m\r\n",
      "│   ├── \u001b[01;34mtest\u001b[00m\r\n",
      "│   │   └── \u001b[01;34munknown\u001b[00m\r\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34mALB\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34mBET\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34mDOL\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34mLAG\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34mNoF\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34mOTHER\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34mSHARK\u001b[00m\r\n",
      "│   │   └── \u001b[01;34mYFT\u001b[00m\r\n",
      "│   └── \u001b[01;34mvalid\u001b[00m\r\n",
      "│       ├── \u001b[01;34mALB\u001b[00m\r\n",
      "│       ├── \u001b[01;34mBET\u001b[00m\r\n",
      "│       ├── \u001b[01;34mDOL\u001b[00m\r\n",
      "│       ├── \u001b[01;34mLAG\u001b[00m\r\n",
      "│       ├── \u001b[01;34mNoF\u001b[00m\r\n",
      "│       ├── \u001b[01;34mOTHER\u001b[00m\r\n",
      "│       ├── \u001b[01;34mSHARK\u001b[00m\r\n",
      "│       └── \u001b[01;34mYFT\u001b[00m\r\n",
      "├── \u001b[01;34mtest\u001b[00m\r\n",
      "│   └── \u001b[01;34munknown\u001b[00m\r\n",
      "├── \u001b[01;34mtest_stg1\u001b[00m\r\n",
      "├── \u001b[01;34mtrain\u001b[00m\r\n",
      "│   ├── \u001b[01;34mALB\u001b[00m\r\n",
      "│   ├── \u001b[01;34mBET\u001b[00m\r\n",
      "│   ├── \u001b[01;34mDOL\u001b[00m\r\n",
      "│   ├── \u001b[01;34mLAG\u001b[00m\r\n",
      "│   ├── \u001b[01;34mNoF\u001b[00m\r\n",
      "│   ├── \u001b[01;34mOTHER\u001b[00m\r\n",
      "│   ├── \u001b[01;34mSHARK\u001b[00m\r\n",
      "│   └── \u001b[01;34mYFT\u001b[00m\r\n",
      "└── \u001b[01;34mvalid\u001b[00m\r\n",
      "    ├── \u001b[01;34mALB\u001b[00m\r\n",
      "    ├── \u001b[01;34mBET\u001b[00m\r\n",
      "    ├── \u001b[01;34mDOL\u001b[00m\r\n",
      "    ├── \u001b[01;34mLAG\u001b[00m\r\n",
      "    ├── \u001b[01;34mNoF\u001b[00m\r\n",
      "    ├── \u001b[01;34mOTHER\u001b[00m\r\n",
      "    ├── \u001b[01;34mSHARK\u001b[00m\r\n",
      "    └── \u001b[01;34mYFT\u001b[00m\r\n",
      "\r\n",
      "47 directories\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir(DATA_PATH)\n",
    "print (os.getcwd())\n",
    "!tree -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showLayersInfo(model):\n",
    "    print (\"Number of layers : \", len(model.layers))\n",
    "    count = 0\n",
    "    for layer in model.layers:\n",
    "        print (count, type(layer), \", trainable:\", layer.trainable)\n",
    "        print (\"input:\", layer.input_shape, \", output:\",layer.output_shape, \"\\n\")\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(histories):\n",
    "    #histories : list of history objects. nb: history.history dictionary structure\n",
    "    print (\"len(histories):\", len(histories))\n",
    "    if len(histories)==1: \n",
    "        history = histories\n",
    "        #needs fix\n",
    "    else:\n",
    "        #create empty history to copy into\n",
    "        history = {}\n",
    "        for i in histories[0].history.keys():\n",
    "            history[i] = []\n",
    "        #now combine all history[key] lists into one history[key] list.\n",
    "        for hist in histories:\n",
    "            for key in history.keys():\n",
    "                history[key] += hist.history[key]\n",
    "                #print (key, len(hist.history[key]), len(history[key]))\n",
    "\n",
    "    # list all data in history\n",
    "    print(history.keys(), len(history[history.keys()[0]]))\n",
    "    for key in history.keys():\n",
    "        print (key, \":\", history[key][-1])\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history['acc'])\n",
    "    plt.plot(history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validate'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validate'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING_TRAIN: /home/ubuntu/fastai/data/fish/sample/train/\n",
      "WORKING_VALID: /home/ubuntu/fastai/data/fish/sample/valid/\n"
     ]
    }
   ],
   "source": [
    "print (\"WORKING_TRAIN:\", WORKING_TRAIN)\n",
    "print (\"WORKING_VALID:\", WORKING_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg640.input_shape: (None, 3, 360, 640)\n",
      "vgg640.output_shape: (None, 512, 11, 20)\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "vgg640 = Vgg16BN((360, 640)).model\n",
    "print (\"vgg640.input_shape:\", vgg640.input_shape)\n",
    "print (\"vgg640.output_shape:\", vgg640.output_shape)\n",
    "print(len(vgg640.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "vgg640.input_shape: (None, 3, 360, 640)\n",
      "vgg640.output_shape: (None, 512, 22, 40)\n"
     ]
    }
   ],
   "source": [
    "vgg640.pop()\n",
    "print(len(vgg640.layers))\n",
    "print (\"vgg640.input_shape:\", vgg640.input_shape)\n",
    "print (\"vgg640.output_shape:\", vgg640.output_shape)\n",
    "vgg640.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 3, 360, 640)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 362, 642)   0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 360, 640)  1792        zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 64, 362, 642)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 360, 640)  36928       zeropadding2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 180, 320)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 64, 182, 322)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 180, 320) 73856       zeropadding2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 128, 182, 322) 0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 128, 180, 320) 147584      zeropadding2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 90, 160)  0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 128, 92, 162)  0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 90, 160)  295168      zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 92, 162)  0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 256, 90, 160)  590080      zeropadding2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 256, 92, 162)  0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 90, 160)  590080      zeropadding2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 45, 80)   0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 256, 47, 82)   0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 512, 45, 80)   1180160     zeropadding2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 512, 47, 82)   0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 45, 80)   2359808     zeropadding2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 512, 47, 82)   0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 45, 80)   2359808     zeropadding2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 22, 40)   0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 512, 24, 42)   0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 512, 22, 40)   2359808     zeropadding2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 512, 24, 42)   0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 512, 22, 40)   2359808     zeropadding2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 512, 24, 42)   0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 512, 22, 40)   2359808     zeropadding2d_13[0][0]           \n",
      "====================================================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg640.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers :  31\n",
      "0 <class 'keras.layers.core.Lambda'> , trainable: True\n",
      "input: (None, 3, 360, 640) , output: (None, 3, 360, 640) \n",
      "\n",
      "1 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 3, 360, 640) , output: (None, 3, 362, 642) \n",
      "\n",
      "2 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 3, 362, 642) , output: (None, 64, 360, 640) \n",
      "\n",
      "3 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 64, 360, 640) , output: (None, 64, 362, 642) \n",
      "\n",
      "4 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 64, 362, 642) , output: (None, 64, 360, 640) \n",
      "\n",
      "5 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 64, 360, 640) , output: (None, 64, 180, 320) \n",
      "\n",
      "6 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 64, 180, 320) , output: (None, 64, 182, 322) \n",
      "\n",
      "7 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 64, 182, 322) , output: (None, 128, 180, 320) \n",
      "\n",
      "8 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 128, 180, 320) , output: (None, 128, 182, 322) \n",
      "\n",
      "9 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 182, 322) , output: (None, 128, 180, 320) \n",
      "\n",
      "10 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 128, 180, 320) , output: (None, 128, 90, 160) \n",
      "\n",
      "11 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 128, 90, 160) , output: (None, 128, 92, 162) \n",
      "\n",
      "12 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 92, 162) , output: (None, 256, 90, 160) \n",
      "\n",
      "13 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 90, 160) , output: (None, 256, 92, 162) \n",
      "\n",
      "14 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 92, 162) , output: (None, 256, 90, 160) \n",
      "\n",
      "15 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 90, 160) , output: (None, 256, 92, 162) \n",
      "\n",
      "16 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 92, 162) , output: (None, 256, 90, 160) \n",
      "\n",
      "17 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 256, 90, 160) , output: (None, 256, 45, 80) \n",
      "\n",
      "18 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 45, 80) , output: (None, 256, 47, 82) \n",
      "\n",
      "19 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 47, 82) , output: (None, 512, 45, 80) \n",
      "\n",
      "20 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 45, 80) , output: (None, 512, 47, 82) \n",
      "\n",
      "21 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 47, 82) , output: (None, 512, 45, 80) \n",
      "\n",
      "22 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 45, 80) , output: (None, 512, 47, 82) \n",
      "\n",
      "23 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 47, 82) , output: (None, 512, 45, 80) \n",
      "\n",
      "24 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 45, 80) , output: (None, 512, 22, 40) \n",
      "\n",
      "25 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 22, 40) , output: (None, 512, 24, 42) \n",
      "\n",
      "26 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 24, 42) , output: (None, 512, 22, 40) \n",
      "\n",
      "27 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 22, 40) , output: (None, 512, 24, 42) \n",
      "\n",
      "28 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 24, 42) , output: (None, 512, 22, 40) \n",
      "\n",
      "29 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 22, 40) , output: (None, 512, 24, 42) \n",
      "\n",
      "30 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 24, 42) , output: (None, 512, 22, 40) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "showLayersInfo(vgg640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers,_ = split_at(vgg640, Convolution2D)\n",
    "#utils.split_at(model, layer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers :  31\n",
      "0 <class 'keras.layers.core.Lambda'> , trainable: True\n",
      "input: (None, 3, 360, 640) , output: (None, 3, 360, 640) \n",
      "\n",
      "1 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 3, 360, 640) , output: (None, 3, 362, 642) \n",
      "\n",
      "2 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 3, 362, 642) , output: (None, 64, 360, 640) \n",
      "\n",
      "3 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 64, 360, 640) , output: (None, 64, 362, 642) \n",
      "\n",
      "4 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 64, 362, 642) , output: (None, 64, 360, 640) \n",
      "\n",
      "5 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 64, 360, 640) , output: (None, 64, 180, 320) \n",
      "\n",
      "6 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 64, 180, 320) , output: (None, 64, 182, 322) \n",
      "\n",
      "7 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 64, 182, 322) , output: (None, 128, 180, 320) \n",
      "\n",
      "8 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 128, 180, 320) , output: (None, 128, 182, 322) \n",
      "\n",
      "9 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 182, 322) , output: (None, 128, 180, 320) \n",
      "\n",
      "10 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 128, 180, 320) , output: (None, 128, 90, 160) \n",
      "\n",
      "11 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 128, 90, 160) , output: (None, 128, 92, 162) \n",
      "\n",
      "12 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 92, 162) , output: (None, 256, 90, 160) \n",
      "\n",
      "13 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 90, 160) , output: (None, 256, 92, 162) \n",
      "\n",
      "14 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 92, 162) , output: (None, 256, 90, 160) \n",
      "\n",
      "15 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 90, 160) , output: (None, 256, 92, 162) \n",
      "\n",
      "16 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 92, 162) , output: (None, 256, 90, 160) \n",
      "\n",
      "17 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 256, 90, 160) , output: (None, 256, 45, 80) \n",
      "\n",
      "18 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 45, 80) , output: (None, 256, 47, 82) \n",
      "\n",
      "19 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 47, 82) , output: (None, 512, 45, 80) \n",
      "\n",
      "20 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 45, 80) , output: (None, 512, 47, 82) \n",
      "\n",
      "21 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 47, 82) , output: (None, 512, 45, 80) \n",
      "\n",
      "22 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 45, 80) , output: (None, 512, 47, 82) \n",
      "\n",
      "23 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 47, 82) , output: (None, 512, 45, 80) \n",
      "\n",
      "24 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 45, 80) , output: (None, 512, 22, 40) \n",
      "\n",
      "25 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 22, 40) , output: (None, 512, 24, 42) \n",
      "\n",
      "26 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 24, 42) , output: (None, 512, 22, 40) \n",
      "\n",
      "27 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 22, 40) , output: (None, 512, 24, 42) \n",
      "\n",
      "28 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 24, 42) , output: (None, 512, 22, 40) \n",
      "\n",
      "29 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 22, 40) , output: (None, 512, 24, 42) \n",
      "\n",
      "30 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 24, 42) , output: (None, 512, 22, 40) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "showLayersInfo(Sequential(conv_layers))\n",
    "#9 layers, only last layers is trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf=128; p=0.4  #NB: was originally p=0 trying different dropout for impact on training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrg_layers():\n",
    "    return [\n",
    "        BatchNormalization(axis=1, input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((1,2)),\n",
    "        Convolution2D(8,3,3, border_mode='same'),\n",
    "        Dropout(p),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Activation('softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB: dropout set to zero by p=0 above.\n",
    "#vgg640 = Vgg16BN((360, 640)).model\n",
    "#conv_layers,_ = split_at(vgg640, Convolution2D)\n",
    "#input_shape=conv_layers[-1].output_shape[1:]\n",
    "#NB: input shape of layers return by get_lrg_layers() is defined by \n",
    "# the output shape of Vgg16BN split at last Convolution2D layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_model = Sequential(get_lrg_layers())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_5 (BatchNorma (None, 512, 22, 40)   2048        batchnormalization_input_2[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 128, 22, 40)   589952      batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 128, 22, 40)   512         convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_9 (MaxPooling2D)    (None, 128, 11, 20)   0           batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D) (None, 128, 11, 20)   147584      maxpooling2d_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNorma (None, 128, 11, 20)   512         convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_10 (MaxPooling2D)   (None, 128, 5, 10)    0           batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D) (None, 128, 5, 10)    147584      maxpooling2d_10[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_8 (BatchNorma (None, 128, 5, 10)    512         convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_11 (MaxPooling2D)   (None, 128, 5, 5)     0           batchnormalization_8[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_21 (Convolution2D) (None, 8, 5, 5)       9224        maxpooling2d_11[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 8, 5, 5)       0           convolution2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "globalaveragepooling2d_2 (Global (None, 8)             0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 8)             0           globalaveragepooling2d_2[0][0]   \n",
      "====================================================================================================\n",
      "Total params: 897,928\n",
      "Trainable params: 896,136\n",
      "Non-trainable params: 1,792\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lrg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers :  14\n",
      "0 <class 'keras.layers.normalization.BatchNormalization'> , trainable: True\n",
      "input: (None, 512, 22, 40) , output: (None, 512, 22, 40) \n",
      "\n",
      "1 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 22, 40) , output: (None, 128, 22, 40) \n",
      "\n",
      "2 <class 'keras.layers.normalization.BatchNormalization'> , trainable: True\n",
      "input: (None, 128, 22, 40) , output: (None, 128, 22, 40) \n",
      "\n",
      "3 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 128, 22, 40) , output: (None, 128, 11, 20) \n",
      "\n",
      "4 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 11, 20) , output: (None, 128, 11, 20) \n",
      "\n",
      "5 <class 'keras.layers.normalization.BatchNormalization'> , trainable: True\n",
      "input: (None, 128, 11, 20) , output: (None, 128, 11, 20) \n",
      "\n",
      "6 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 128, 11, 20) , output: (None, 128, 5, 10) \n",
      "\n",
      "7 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 5, 10) , output: (None, 128, 5, 10) \n",
      "\n",
      "8 <class 'keras.layers.normalization.BatchNormalization'> , trainable: True\n",
      "input: (None, 128, 5, 10) , output: (None, 128, 5, 10) \n",
      "\n",
      "9 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 128, 5, 10) , output: (None, 128, 5, 5) \n",
      "\n",
      "10 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 5, 5) , output: (None, 8, 5, 5) \n",
      "\n",
      "11 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 8, 5, 5) , output: (None, 8, 5, 5) \n",
      "\n",
      "12 <class 'keras.layers.pooling.GlobalAveragePooling2D'> , trainable: True\n",
      "input: (None, 8, 5, 5) , output: (None, 8) \n",
      "\n",
      "13 <class 'keras.layers.core.Activation'> , trainable: True\n",
      "input: (None, 8) , output: (None, 8) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "showLayersInfo(lrg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall\n",
    "#trn = get_data(WORKING_TRAIN, (360,640))\n",
    "#conv_trn_feat = vgg640.predict(trn, batch_size=32, verbose=1)\n",
    "#(val_classes, trn_classes, val_labels, trn_labels, val_filenames, filenames, test_filenames) = get_classes(WORKING_DATA)\n",
    "#val = get_data(WORKING_VALID, (360,640))\n",
    "#conv_val_feat = vgg640.predict(val, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 526 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "trn = get_data(WORKING_TRAIN, (360,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526/526 [==============================] - 67s    \n"
     ]
    }
   ],
   "source": [
    "conv_trn_feat = vgg640.predict(trn, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 526 images belonging to 8 classes.\n",
      "Found 224 images belonging to 8 classes.\n",
      "Found 200 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, val_filenames, filenames, test_filenames) = get_classes(WORKING_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 224 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val = get_data(WORKING_VALID, (360,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 28s    \n"
     ]
    }
   ],
   "source": [
    "conv_val_feat = vgg640.predict(val, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_trn_feat: <type 'numpy.ndarray'> (526, 512, 22, 40)\n"
     ]
    }
   ],
   "source": [
    "print (\"conv_trn_feat:\", type(conv_trn_feat), conv_trn_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 526 samples, validate on 224 samples\n",
      "Epoch 1/5\n",
      "526/526 [==============================] - 2s - loss: 1.3742 - acc: 0.5323 - val_loss: 8.3042 - val_acc: 0.1964\n",
      "Epoch 2/5\n",
      " 64/526 [==>...........................] - ETA: 1s - loss: 0.6474 - acc: 0.8594"
     ]
    }
   ],
   "source": [
    "history1 = lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=5, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"history1:\", history1, type(history1), type(history1.history.keys()) )\n",
    "print (history1.history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_model.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=6, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([history1, history2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=6, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([history1, history2, history3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history4 = lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=6, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([history1, history2, history3, history4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history5 = lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=20, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([history1, history2, history3, history4, history5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_clip(arr, mx): return np.clip(arr, (1-mx)/7, mx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
