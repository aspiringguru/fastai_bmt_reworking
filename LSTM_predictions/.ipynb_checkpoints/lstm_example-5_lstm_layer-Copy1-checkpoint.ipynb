{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on\n",
    "#https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/\n",
    "#https://datamarket.com/data/set/22r0/sales-of-shampoo-over-a-three-year-period#!ds=22r0&display=line\n",
    "\n",
    "#Transform Time Series to Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/ubuntu/fastai/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load and plot dataset\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime as pddatetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "def parser(x):\n",
    "    return pddatetime.strptime('190'+x, '%Y-%m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "\tcolumns.append(df)\n",
    "\tdf = concat(columns, axis=1)\n",
    "\tdf.fillna(0, inplace=True)\n",
    "\treturn df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "    #does this guarantee test_scaled will be within -1, 1 range?\n",
    "    #since scale is set from train data not test.\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = numpy.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    #NB: The batch_size must be set to 1. This is because it must be a factor of the size of the training and test datasets.\n",
    "    #look at this when fit_lstm is called.\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, 1, len(X))\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month\n",
      "1901-01-01    266.0\n",
      "1901-02-01    145.9\n",
      "1901-03-01    183.1\n",
      "1901-04-01    119.3\n",
      "1901-05-01    180.3\n",
      "Name: Sales, dtype: float64\n",
      "(36,)\n"
     ]
    }
   ],
   "source": [
    "series = read_csv(DATA_DIR+'shampoo_sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "# summarize first few rows\n",
    "print(series.head())\n",
    "print (series.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_values: <class 'numpy.ndarray'> (36,)\n",
      "diff_values: <class 'pandas.core.series.Series'> (35,)\n"
     ]
    }
   ],
   "source": [
    "# transform data to be stationary\n",
    "raw_values = series.values\n",
    "diff_values = difference(raw_values, 1)\n",
    "#\n",
    "print (\"raw_values:\", type(raw_values), raw_values.shape)\n",
    "print (\"diff_values:\", type(diff_values), diff_values.shape)\n",
    "\n",
    "#we now have 1 less row since we calculated difference between current and immediately previous value.\n",
    "#nbb: extra work would be required to create data over multiple time periods back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervised_values: <class 'numpy.ndarray'> (35, 2)\n"
     ]
    }
   ],
   "source": [
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    "print (\"supervised_values:\", type(supervised_values), supervised_values.shape)\n",
    "#nb: we now have 2 columns since we are comparing sequence of data over a time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test-sets\n",
    "train = supervised_values[0:-12]\n",
    "test  = supervised_values[-12:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (23, 2)\n",
      "test: (12, 2)\n",
      "train_scaled: (23, 2) <class 'numpy.ndarray'>\n",
      "test_scaled: (12, 2) <class 'numpy.ndarray'>\n",
      "test_scaled: -1.26760183437 1.32802805503\n",
      "train_scaled: -1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print (\"train:\", train.shape)\n",
    "print (\"test:\", test.shape)\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "#def scale : scale train and test data to [-1, 1]\n",
    "print (\"train_scaled:\", train_scaled.shape, type(train_scaled))\n",
    "print (\"test_scaled:\", test_scaled.shape, type(test_scaled))\n",
    "print (\"test_scaled:\", numpy.amin(test_scaled), numpy.amax(test_scaled))\n",
    "print (\"train_scaled:\", numpy.amin(train_scaled), numpy.amax(train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 2018-01-11 23:08:03.843795\n"
     ]
    }
   ],
   "source": [
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "\n",
    "# fit the model\n",
    "#def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "#batch_input_shape=(batch_size, X.shape[1], X.shape[2])\n",
    "#nb: batch_size must be a factor of both the training and test datasets. \n",
    "# lazy/easiest option is set batch_size = 1\n",
    "\n",
    "#lstm_model = fit_lstm(train_scaled, 1, 3000, 4)\n",
    "lstm_model = fit_lstm(train_scaled, 1, 1500, 1)\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast the entire training dataset to build up state for forecasting\n",
    "train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "#nb: select column 0 of train_scaled and reshape to suit input shape required for the lstm model.\n",
    "\n",
    "print (\"train_reshaped:\", type(train_reshaped), train_reshaped.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.predict(train_reshaped, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk-forward validation on the test data\n",
    "predictions = list()\n",
    "for i in range(len(test_scaled)):\n",
    "\t# make one-step forecast\n",
    "\tX = test_scaled[i, 0:-1]\n",
    "\ty = test_scaled[i, -1]\n",
    "\t#yhat = forecast_lstm(lstm_model, 1, X)\n",
    "\tyhat = y\n",
    "\t# invert scaling\n",
    "\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t# invert differencing\n",
    "\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t# store forecast\n",
    "\tpredictions.append(yhat)\n",
    "\texpected = raw_values[len(train) + i + 1]\n",
    "\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "# line plot of observed vs predicted\n",
    "pyplot.plot(raw_values[-12:], color='red')\n",
    "pyplot.plot(predictions, color='blue')\n",
    "pyplot.show()\n",
    "\n",
    "#Test RMSE: 154.670 when using fit_lstm(train_scaled, 1, 3000, 4)\n",
    "#Test RMSE: 112.663 when using fit_lstm(train_scaled, 1, 1500, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(predictions - raw_values[-12:])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
