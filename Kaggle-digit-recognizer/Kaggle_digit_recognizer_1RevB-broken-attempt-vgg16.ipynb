{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('HOMEPATH:', '/home/ubuntu/fastai/')\n",
      "('DATAPATH:', '/home/ubuntu/fastai/data/Kaggle_digit_recognizer/')\n"
     ]
    }
   ],
   "source": [
    "HOMEPATH = \"/home/ubuntu/fastai/\"\n",
    "DATAPATH = HOMEPATH + \"data/Kaggle_digit_recognizer/\"\n",
    "print(\"HOMEPATH:\", HOMEPATH)\n",
    "print(\"DATAPATH:\", DATAPATH)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('os.getcwd:', '/home/ubuntu/fastai')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5110)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(HOMEPATH)\n",
    "print (\"os.getcwd:\", os.getcwd())\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from __future__ import division, print_function\n",
    "\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n"
     ]
    }
   ],
   "source": [
    "def set_keras_backend(backend):\n",
    "\n",
    "    if K.backend() != backend:\n",
    "        #nb: utils has 'from keras import backend as K'\n",
    "        os.environ['KERAS_BACKEND'] = backend\n",
    "        reload(K)\n",
    "        assert K.backend() == backend\n",
    "\n",
    "set_keras_backend(\"theano\")\n",
    "print (K.image_dim_ordering())#th\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pixel0', 'pixel1', 'pixel782', 'pixel783']\n",
      "['label', 'pixel0', 'pixel782', 'pixel783']\n"
     ]
    }
   ],
   "source": [
    "#Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive.\n",
    "colNames = []\n",
    "colDtypes = {}\n",
    "colDtypes[\"label\"] = np.int64\n",
    "\n",
    "for i in range(784):\n",
    "    colNames.append(\"pixel\"+str(i))\n",
    "    colDtypes[\"pixel\"+str(i)] = np.int64\n",
    "print (colNames[0:2] + colNames[-2:])\n",
    "colNames = ['label'] + colNames\n",
    "print (colNames[0:2] + colNames[-2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATAPATH+'train.csv', names=colNames, dtype=colDtypes, header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, (41999, 785))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df), df.shape\n",
    "#785 columns = 1 + 28*28\n",
    "#reshape into numy array with shape (4199, 1, 28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      0       0       0       0       0       0       0       0       0   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques = list(df.label.unique())\n",
    "uniques.sort()\n",
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixelData.shape: (41999, 784)\n",
      "labelData.shape: (41999,) [0 1 4 0 0 7 3 5 3 8]\n"
     ]
    }
   ],
   "source": [
    "pixelData = df.as_matrix()[:,1:]\n",
    "print (\"pixelData.shape:\", pixelData.shape)\n",
    "labelData = df.as_matrix()[:,0]\n",
    "print (\"labelData.shape:\", labelData.shape, labelData[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixelData.shape: (41999, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "pixelData = pixelData.reshape((41999, 28, 28))\n",
    "print (\"pixelData.shape:\", pixelData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pixelData, labelData, test_size=0.1, random_state=42)#split was 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (37799, 28, 28)\n",
      "X_test: (4200, 28, 28)\n",
      "y_train: (37799,)\n",
      "y_test: (4200,)\n"
     ]
    }
   ],
   "source": [
    "print (\"X_train:\", X_train.shape)\n",
    "print (\"X_test:\", X_test.shape)\n",
    "print (\"y_train:\", y_train.shape)\n",
    "print (\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expand shape\n",
      "type(X_test): <type 'numpy.ndarray'> (4200, 1, 28, 28)\n",
      "type(X_train): <type 'numpy.ndarray'> (37799, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "if len(X_test.shape)==3:\n",
    "    print(\"expand shape\")\n",
    "    X_test = np.expand_dims(X_test,1)\n",
    "    X_train = np.expand_dims(X_train,1)\n",
    "else:\n",
    "        print(\"expand shape already done, don't do again.\")\n",
    "\n",
    "print (\"type(X_test):\", type(X_test), X_test.shape)\n",
    "print (\"type(X_train):\", type(X_train), X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (37799, 1, 28, 28)\n",
      "X_test: (4200, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print (\"X_train:\", X_train.shape)\n",
    "print (\"X_test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(y_train): <type 'numpy.ndarray'> (37799,) 1\n",
      "type(y_test): <type 'numpy.ndarray'> (4200,) 1\n"
     ]
    }
   ],
   "source": [
    "print (\"type(y_train):\", type(y_train), y_train.shape, len(y_train.shape))\n",
    "print (\"type(y_test):\", type(y_test), y_test.shape, len(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(y_train): <type 'numpy.ndarray'> (37799, 10)\n",
      "type(y_test): <type 'numpy.ndarray'> (4200, 10)\n"
     ]
    }
   ],
   "source": [
    "if len(y_test.shape)==1:\n",
    "    y_train = to_categorical(y_train)\n",
    "else:\n",
    "    print (\"y_train already onehot'd, dont try again.\")\n",
    "\n",
    "if len(y_test.shape)==1:\n",
    "    y_test = to_categorical(y_test)\n",
    "else:\n",
    "    print (\"y_train already onehot'd, dont try again.\")\n",
    "\n",
    "print (\"type(y_train):\", type(y_train), y_train.shape)\n",
    "print (\"type(y_test):\", type(y_test), y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train\n",
      " [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]]\n",
      "y_test\n",
      " [[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print (\"y_train\\n\", y_train[0:5, :])\n",
    "print (\"y_test\\n\", y_test[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showLayersInfo(model):\n",
    "    print (\"Number of layers : \", len(model.layers))\n",
    "    count = 0\n",
    "    for layer in model.layers:\n",
    "        print (count, type(layer), \", trainable:\", layer.trainable)\n",
    "        print (\"input:\", layer.input_shape, \", output:\",layer.output_shape, \", len(weights)\", len(layer.get_weights()), \"\\n\")\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(histories):\n",
    "    #histories : list of history objects. nb: history.history dictionary structure\n",
    "    print (\"len(histories):\", len(histories))\n",
    "    if len(histories)==1: \n",
    "        history = histories\n",
    "    else:\n",
    "        history = {}\n",
    "        for i in histories[0].history.keys():\n",
    "            history[i] = []\n",
    "        #create empty history to copy into\n",
    "        for hist in histories:\n",
    "            for key in history.keys():\n",
    "                history[key] += hist.history[key]\n",
    "                #print (key, len(hist.history[key]), len(history[key]))\n",
    "\n",
    "    # list all data in history\n",
    "    print(history.keys(), len(history[history.keys()[0]]))\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history['acc'])\n",
    "    plt.plot(history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validate'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validate'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "#recall: (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "test_batches = gen.flow(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(layers, filters):\n",
    "    #ConvBlock(layers, filters): (ZeroPadding2D+Convolution2D(filters))*layers+MaxPooling2D\n",
    "    layer_list = []\n",
    "    for i in range(layers):\n",
    "        layer_list.append(ZeroPadding2D((1, 1)))\n",
    "        layer_list.append(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "    layer_list.append(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    #print (\"ConvBlock.layer_list:\\n\", layer_list)\n",
    "    return layer_list\n",
    "\n",
    "\n",
    "def FCBlock():\n",
    "    #FCBlock: Dense, BatchNormalization, Dropout\n",
    "    layer_list = []\n",
    "    layer_list.append(Dense(4096, activation='relu'))\n",
    "    layer_list.append(BatchNormalization())\n",
    "    layer_list.append(Dropout(0.5))\n",
    "    #print (\"FCBlock.layer_list:\\n\", layer_list)\n",
    "    return layer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model2():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(norm_input, input_shape=(1, 28, 28)))\n",
    "    #model.add(Lambda(norm_input, input_shape=(1, 28, 28), output_shape=(1, 28, 28)))\n",
    "    #model.add(Lambda(norm_input, batch_input_shape=(1, 28, 28), output_shape=(1, 28, 28)))\n",
    "    \n",
    "    \n",
    "    print (model.summary())\n",
    "    print (\"11111111111\")\n",
    "    #ConvBlock(layers, filters): (ZeroPadding2D+Convolution2D(filters))*layers+MaxPooling2D\n",
    "    layers_to_add = []\n",
    "    layers_to_add = layers_to_add + ConvBlock(2, 64)\n",
    "    layers_to_add = layers_to_add + ConvBlock(2, 128)\n",
    "    layers_to_add = layers_to_add + ConvBlock(3, 256)\n",
    "    layers_to_add = layers_to_add + ConvBlock(3, 512)\n",
    "    layers_to_add = layers_to_add + ConvBlock(3, 512)\n",
    "    for layer in layers_to_add:\n",
    "        print (type(layer))\n",
    "        model.add(layer)\n",
    "    print (model.summary())\n",
    "    print (showLayersInfo(model))\n",
    "    print (\"22222\")\n",
    "\n",
    "    model.add(Flatten())#error here: The shape of the input to \"Flatten\" is not fully defined (got (512, 0, 0). \n",
    "    #Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model.\n",
    "    \n",
    "    \n",
    "    ##FCBlock: Dense, BatchNormalization, Dropout\n",
    "    layers_to_add = []\n",
    "    layers_to_add = layers_to_add + FCBlock()\n",
    "    layers_to_add = layers_to_add + FCBlock()\n",
    "    for layer in layers_to_add:\n",
    "        print (type(layer))\n",
    "        model.add(layer)\n",
    "    print (\"3333\")\n",
    "    print (model.summary())\n",
    "    model.add(Dense(10, activation='softmax'))#nb: dense 10 output since 10 categories (10 digits 0-9)\n",
    "    #\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_9 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_9 (Lambda)                (None, 1, 28, 28)     0           lambda_input_9[0][0]             \n",
      "====================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "11111111111\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_9 (Lambda)                (None, 1, 28, 28)     0           lambda_input_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_79 (ZeroPadding2D) (None, 1, 30, 30)     0           lambda_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_87 (Convolution2D) (None, 64, 28, 28)    640         zeropadding2d_79[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_80 (ZeroPadding2D) (None, 64, 30, 30)    0           convolution2d_87[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_88 (Convolution2D) (None, 64, 28, 28)    36928       zeropadding2d_80[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_35 (MaxPooling2D)   (None, 64, 14, 14)    0           convolution2d_88[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_81 (ZeroPadding2D) (None, 64, 16, 16)    0           maxpooling2d_35[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_89 (Convolution2D) (None, 128, 14, 14)   73856       zeropadding2d_81[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_82 (ZeroPadding2D) (None, 128, 16, 16)   0           convolution2d_89[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_90 (Convolution2D) (None, 128, 14, 14)   147584      zeropadding2d_82[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_36 (MaxPooling2D)   (None, 128, 7, 7)     0           convolution2d_90[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_83 (ZeroPadding2D) (None, 128, 9, 9)     0           maxpooling2d_36[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_91 (Convolution2D) (None, 256, 7, 7)     295168      zeropadding2d_83[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_84 (ZeroPadding2D) (None, 256, 9, 9)     0           convolution2d_91[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_92 (Convolution2D) (None, 256, 7, 7)     590080      zeropadding2d_84[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_85 (ZeroPadding2D) (None, 256, 9, 9)     0           convolution2d_92[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_93 (Convolution2D) (None, 256, 7, 7)     590080      zeropadding2d_85[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_37 (MaxPooling2D)   (None, 256, 3, 3)     0           convolution2d_93[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_86 (ZeroPadding2D) (None, 256, 5, 5)     0           maxpooling2d_37[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_94 (Convolution2D) (None, 512, 3, 3)     1180160     zeropadding2d_86[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_87 (ZeroPadding2D) (None, 512, 5, 5)     0           convolution2d_94[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_95 (Convolution2D) (None, 512, 3, 3)     2359808     zeropadding2d_87[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_88 (ZeroPadding2D) (None, 512, 5, 5)     0           convolution2d_95[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_96 (Convolution2D) (None, 512, 3, 3)     2359808     zeropadding2d_88[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_38 (MaxPooling2D)   (None, 512, 1, 1)     0           convolution2d_96[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_89 (ZeroPadding2D) (None, 512, 3, 3)     0           maxpooling2d_38[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_97 (Convolution2D) (None, 512, 1, 1)     2359808     zeropadding2d_89[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_90 (ZeroPadding2D) (None, 512, 3, 3)     0           convolution2d_97[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_98 (Convolution2D) (None, 512, 1, 1)     2359808     zeropadding2d_90[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_91 (ZeroPadding2D) (None, 512, 3, 3)     0           convolution2d_98[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_99 (Convolution2D) (None, 512, 1, 1)     2359808     zeropadding2d_91[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_39 (MaxPooling2D)   (None, 512, 0, 0)     0           convolution2d_99[0][0]           \n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 14,713,536\n",
      "Trainable params: 14,713,536\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Number of layers :  32\n",
      "0 <class 'keras.layers.core.Lambda'> , trainable: True\n",
      "input: (None, 1, 28, 28) , output: (None, 1, 28, 28) , len(weights) 0 \n",
      "\n",
      "1 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 1, 28, 28) , output: (None, 1, 30, 30) , len(weights) 0 \n",
      "\n",
      "2 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 1, 30, 30) , output: (None, 64, 28, 28) , len(weights) 2 \n",
      "\n",
      "3 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 64, 28, 28) , output: (None, 64, 30, 30) , len(weights) 0 \n",
      "\n",
      "4 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 64, 30, 30) , output: (None, 64, 28, 28) , len(weights) 2 \n",
      "\n",
      "5 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 64, 28, 28) , output: (None, 64, 14, 14) , len(weights) 0 \n",
      "\n",
      "6 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 64, 14, 14) , output: (None, 64, 16, 16) , len(weights) 0 \n",
      "\n",
      "7 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 64, 16, 16) , output: (None, 128, 14, 14) , len(weights) 2 \n",
      "\n",
      "8 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 128, 14, 14) , output: (None, 128, 16, 16) , len(weights) 0 \n",
      "\n",
      "9 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 16, 16) , output: (None, 128, 14, 14) , len(weights) 2 \n",
      "\n",
      "10 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 128, 14, 14) , output: (None, 128, 7, 7) , len(weights) 0 \n",
      "\n",
      "11 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 128, 7, 7) , output: (None, 128, 9, 9) , len(weights) 0 \n",
      "\n",
      "12 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 9, 9) , output: (None, 256, 7, 7) , len(weights) 2 \n",
      "\n",
      "13 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 7, 7) , output: (None, 256, 9, 9) , len(weights) 0 \n",
      "\n",
      "14 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 9, 9) , output: (None, 256, 7, 7) , len(weights) 2 \n",
      "\n",
      "15 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 7, 7) , output: (None, 256, 9, 9) , len(weights) 0 \n",
      "\n",
      "16 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 9, 9) , output: (None, 256, 7, 7) , len(weights) 2 \n",
      "\n",
      "17 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 256, 7, 7) , output: (None, 256, 3, 3) , len(weights) 0 \n",
      "\n",
      "18 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 3, 3) , output: (None, 256, 5, 5) , len(weights) 0 \n",
      "\n",
      "19 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 5, 5) , output: (None, 512, 3, 3) , len(weights) 2 \n",
      "\n",
      "20 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 3, 3) , output: (None, 512, 5, 5) , len(weights) 0 \n",
      "\n",
      "21 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 5, 5) , output: (None, 512, 3, 3) , len(weights) 2 \n",
      "\n",
      "22 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 3, 3) , output: (None, 512, 5, 5) , len(weights) 0 \n",
      "\n",
      "23 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 5, 5) , output: (None, 512, 3, 3) , len(weights) 2 \n",
      "\n",
      "24 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 3, 3) , output: (None, 512, 1, 1) , len(weights) 0 \n",
      "\n",
      "25 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 1, 1) , output: (None, 512, 3, 3) , len(weights) 0 \n",
      "\n",
      "26 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 3, 3) , output: (None, 512, 1, 1) , len(weights) 2 \n",
      "\n",
      "27 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 1, 1) , output: (None, 512, 3, 3) , len(weights) 0 \n",
      "\n",
      "28 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 3, 3) , output: (None, 512, 1, 1) , len(weights) 2 \n",
      "\n",
      "29 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 1, 1) , output: (None, 512, 3, 3) , len(weights) 0 \n",
      "\n",
      "30 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 3, 3) , output: (None, 512, 1, 1) , len(weights) 2 \n",
      "\n",
      "31 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 1, 1) , output: (None, 512, 0, 0) , len(weights) 0 \n",
      "\n",
      "None\n",
      "22222\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The shape of the input to \"Flatten\" is not fully defined (got (512, 0, 0). Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-e6d7882dbeb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-a2d25d322786>\u001b[0m in \u001b[0;36mget_model2\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"22222\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#error here: The shape of the input to \"Flatten\" is not fully defined (got (512, 0, 0).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;31m#Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    330\u001b[0m                  output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;31m# This will call layer.build() if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_inbound_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m             \u001b[0;31m# Outputs were already computed when calling self.add_inbound_node.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36madd_inbound_node\u001b[0;34m(self, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;31m# creating the node automatically updates self.inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;31m# as well as outbound_nodes on inbound layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_output_shape_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(cls, outbound_layer, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m# TODO: try to auto-infer shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;31m# if exception is raised by get_output_shape_for.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0moutput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_shape_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/layers/core.pyc\u001b[0m in \u001b[0;36mget_output_shape_for\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    474\u001b[0m             raise ValueError('The shape of the input to \"Flatten\" '\n\u001b[1;32m    475\u001b[0m                              \u001b[0;34m'is not fully defined '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m                              \u001b[0;34m'(got '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m                              \u001b[0;34m'Make sure to pass a complete \"input_shape\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                              \u001b[0;34m'or \"batch_input_shape\" argument to the first '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The shape of the input to \"Flatten\" is not fully defined (got (512, 0, 0). Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model."
     ]
    }
   ],
   "source": [
    "model = get_model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batchnormalisation : uses batches and test_batches created from image.ImageDataGenerator.flow(blah...)\n",
    "\n",
    "def get_model_bn_do2():\n",
    "    model = Sequential([\n",
    "        \n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "\n",
    "        #ConvBlock(2, 64)\n",
    "        ZeroPadding2D((1, 1)),\n",
    "        Convolution2D(64, 3, 3, activation='relu'),\n",
    "        ZeroPadding2D((1, 1)),\n",
    "        Convolution2D(64, 3, 3, activation='relu'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "\n",
    "        #ConvBlock(2, 128)\n",
    "        ZeroPadding2D((1, 1)),\n",
    "        Convolution2D(128, 3, 3, activation='relu'),\n",
    "        ZeroPadding2D((1, 1)),\n",
    "        Convolution2D(128, 3, 3, activation='relu'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "\n",
    "        #ConvBlock(3, 256)\n",
    "        ZeroPadding2D((1, 1)),\n",
    "        Convolution2D(256, 3, 3, activation='relu'),\n",
    "        ZeroPadding2D((1, 1)),\n",
    "        Convolution2D(256, 3, 3, activation='relu'),\n",
    "        ZeroPadding2D((1, 1)),\n",
    "        Convolution2D(256, 3, 3, activation='relu'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "\n",
    "        #ConvBlock(3, 512)\n",
    "        ZeroPadding2D((1, 1)),\n",
    "        Convolution2D(512, 3, 3, activation='relu'),\n",
    "        ZeroPadding2D((1, 1)),\n",
    "        Convolution2D(512, 3, 3, activation='relu'),\n",
    "        ZeroPadding2D((1, 1)),\n",
    "        Convolution2D(512, 3, 3, activation='relu'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "\n",
    "\n",
    "        #ConvBlock(3, 512)\n",
    "        ZeroPadding2D((1, 1)),\n",
    "        Convolution2D(512, 3, 3, activation='relu'),\n",
    "        ZeroPadding2D((1, 1)),\n",
    "        Convolution2D(512, 3, 3, activation='relu'),\n",
    "        ZeroPadding2D((1, 1)),\n",
    "        Convolution2D(512, 3, 3, activation='relu'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        #FCBlock\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        #FCBlock\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(10, activation='softmax')#nb: dense 10 output since 10 categories (10 digits 0-9)\n",
    "\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_11 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The shape of the input to \"Flatten\" is not fully defined (got (512, 0, 0). Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-380343621b60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_model_bn_do2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-e1e440e7d82d>\u001b[0m in \u001b[0;36mget_model_bn_do2\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#nb: dense 10 output since 10 categories (10 digits 0-9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         ])\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    330\u001b[0m                  output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;31m# This will call layer.build() if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_inbound_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m             \u001b[0;31m# Outputs were already computed when calling self.add_inbound_node.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36madd_inbound_node\u001b[0;34m(self, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;31m# creating the node automatically updates self.inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;31m# as well as outbound_nodes on inbound layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_output_shape_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(cls, outbound_layer, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m# TODO: try to auto-infer shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;31m# if exception is raised by get_output_shape_for.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0moutput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_shape_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/layers/core.pyc\u001b[0m in \u001b[0;36mget_output_shape_for\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    474\u001b[0m             raise ValueError('The shape of the input to \"Flatten\" '\n\u001b[1;32m    475\u001b[0m                              \u001b[0;34m'is not fully defined '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m                              \u001b[0;34m'(got '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m                              \u001b[0;34m'Make sure to pass a complete \"input_shape\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                              \u001b[0;34m'or \"batch_input_shape\" argument to the first '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The shape of the input to \"Flatten\" is not fully defined (got (512, 0, 0). Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model."
     ]
    }
   ],
   "source": [
    "get_model_bn_do2().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batchnormalisation : uses batches and test_batches created from image.ImageDataGenerator.flow(blah...)\n",
    "\n",
    "def get_model_bn_do():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),#added dropout here since it appears overtraining & validation not converging.\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_8 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_8 (Lambda)                (None, 1, 28, 28)     0           lambda_input_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_83 (Convolution2D) (None, 32, 26, 26)    320         lambda_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 32, 26, 26)    128         convolution2d_83[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_84 (Convolution2D) (None, 32, 24, 24)    9248        batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_33 (MaxPooling2D)   (None, 32, 12, 12)    0           convolution2d_84[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNorma (None, 32, 12, 12)    128         maxpooling2d_33[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_85 (Convolution2D) (None, 64, 10, 10)    18496       batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_8 (BatchNorma (None, 64, 10, 10)    256         convolution2d_85[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_86 (Convolution2D) (None, 64, 8, 8)      36928       batchnormalization_8[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_34 (MaxPooling2D)   (None, 64, 4, 4)      0           convolution2d_86[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)              (None, 1024)          0           maxpooling2d_34[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_9 (BatchNorma (None, 1024)          4096        flatten_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 1024)          0           batchnormalization_9[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 512)           524800      dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_10 (BatchNorm (None, 512)           2048        dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 512)           0           batchnormalization_10[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 10)            5130        dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 601,578\n",
      "Trainable params: 598,250\n",
      "Non-trainable params: 3,328\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "get_model_bn_do().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model():\n",
    "    model = get_model_bn_do()\n",
    "    model.summary()\n",
    "    print (\"model.optimizer.lr:\", model.optimizer.lr)\n",
    "    history1 = model.fit_generator(batches, batches.n, nb_epoch=1, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.n)\n",
    "    print(\"model.fit_generator(..) completed with model.optimizer.lr:\", model.optimizer.lr)\n",
    "    model.optimizer.lr=0.1\n",
    "    history2 = model.fit_generator(batches, batches.n, nb_epoch=4, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.n)\n",
    "    print(\"model.fit_generator(..) completed with model.optimizer.lr:\", model.optimizer.lr)\n",
    "    plot_history([history1, history2])\n",
    "    model.optimizer.lr=0.01\n",
    "    history3 = model.fit_generator(batches, batches.n, nb_epoch=12, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.n)\n",
    "    print(\"model.fit_generator(..) completed with model.optimizer.lr:\", model.optimizer.lr)\n",
    "    plot_history([history1, history2, history3])\n",
    "    model.optimizer.lr=0.001\n",
    "    history4 = model.fit_generator(batches, batches.n, nb_epoch=18, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.n)\n",
    "    print(\"model.fit_generator(..) completed with model.optimizer.lr:\", model.optimizer.lr)\n",
    "    plot_history([history1, history2, history3, history4])\n",
    "    model.optimizer.lr=0.0001\n",
    "    history5 = model.fit_generator(batches, batches.n, nb_epoch=27, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.n)\n",
    "    print(\"model.fit_generator(..) completed with model.optimizer.lr:\", model.optimizer.lr)\n",
    "    plot_history([history1, history2, history3, history4, history5])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [fit_model() for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = DATAPATH + 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"models:\", type(models), len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,m in enumerate(models):\n",
    "    m.save_weights(model_path+'cnn-mnist23-'+str(i)+'_2.h5')#nb: why .pkl instead of .h5? .pkl usually for pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = np.array([m.evaluate(X_test, y_test, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_mean = evals.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"evals_mean:\", evals_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (evals_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = np.stack([m.predict(X_test, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = all_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.metrics.categorical_accuracy(y_test, avg_preds).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start loading test data\n",
    "#Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive.\n",
    "colNames = []\n",
    "colDtypes = {}\n",
    "\n",
    "for i in range(784):\n",
    "    colNames.append(\"pixel\"+str(i))\n",
    "    colDtypes[\"pixel\"+str(i)] = np.int64\n",
    "print (colNames[0:2] + colNames[-2:])\n",
    "colNames = colNames\n",
    "print (colNames[0:2] + colNames[-2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(DATAPATH+'test.csv', names=colNames, dtype=colDtypes, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pixelData = df_test.as_matrix()\n",
    "print (\"test_pixelData.shape:\", test_pixelData.shape, test_pixelData.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_pixelData.reshape((test_pixelData.shape[0], 28, 28))\n",
    "print (\"X_test.shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X_test.shape)==3:\n",
    "    print(\"expand shape\")\n",
    "    X_test = np.expand_dims(X_test,1)\n",
    "else:\n",
    "        print(\"expand shape already done, don't do again.\")\n",
    "\n",
    "print (\"type(X_test):\", type(X_test), X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = np.stack([m.predict(X_test, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = all_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_preds[0])\n",
    "print(type(avg_preds[0]))\n",
    "print(type(list(avg_preds[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = []\n",
    "for i in range(avg_preds.shape[0]):\n",
    "    category.append(np.argmax(avg_preds[i]))\n",
    "    #print(i, category, avg_preds[i])\n",
    "    #break\n",
    "type(category), len(category), category[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageids = list(range(1, avg_preds.shape[0]+1))\n",
    "print (type(imageids), len(imageids), imageids[0:5], imageids[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe, write to csv\n",
    "#dataframe labels = ImageId,Label\n",
    "#df = pd.read_csv(DATAPATH+'train.csv', names=colNames, dtype=colDtypes, header=1)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'ImageId': imageids, 'Label': category})#, index=index, columns=['ImageId','Label'])\n",
    "print (df.shape)\n",
    "print (df.head())\n",
    "print (df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATAPATH+'submit_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(HOMEPATH)\n",
    "print (\"os.getcwd:\", os.getcwd())\n",
    "\n",
    "from vgg16bn  import Vgg16BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Vgg16BN().model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
