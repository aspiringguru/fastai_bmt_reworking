{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOMEPATH = \"/home/ubuntu/fastai/\"\n",
    "DATAPATH = HOMEPATH + \"data/Kaggle_digit_recognizer/\"\n",
    "print(\"HOMEPATH:\", HOMEPATH)\n",
    "print(\"DATAPATH:\", DATAPATH)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(HOMEPATH)\n",
    "print (\"os.getcwd:\", os.getcwd())\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from __future__ import division, print_function\n",
    "\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive.\n",
    "colNames = []\n",
    "colDtypes = {}\n",
    "colDtypes[\"label\"] = np.int64\n",
    "\n",
    "for i in range(784):\n",
    "    colNames.append(\"pixel\"+str(i))\n",
    "    colDtypes[\"pixel\"+str(i)] = np.int64\n",
    "print (colNames[0:2] + colNames[-2:])\n",
    "colNames = ['label'] + colNames\n",
    "print (colNames[0:2] + colNames[-2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATAPATH+'train.csv', names=colNames, dtype=colDtypes, header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df), df.shape\n",
    "#785 columns = 1 + 28*28\n",
    "#reshape into numy array with shape (4199, 1, 28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = list(df.label.unique())\n",
    "uniques.sort()\n",
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelData = df.as_matrix()[:,1:]\n",
    "print (\"pixelData.shape:\", pixelData.shape)\n",
    "labelData = df.as_matrix()[:,0]\n",
    "print (\"labelData.shape:\", labelData.shape, labelData[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelData = pixelData.reshape((41999, 28, 28))\n",
    "print (\"pixelData.shape:\", pixelData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pixelData, labelData, test_size=0.1, random_state=42)#split was 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"X_train:\", X_train.shape)\n",
    "print (\"X_test:\", X_test.shape)\n",
    "print (\"y_train:\", y_train.shape)\n",
    "print (\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X_test.shape)==3:\n",
    "    print(\"expand shape\")\n",
    "    X_test = np.expand_dims(X_test,1)\n",
    "    X_train = np.expand_dims(X_train,1)\n",
    "else:\n",
    "        print(\"expand shape already done, don't do again.\")\n",
    "\n",
    "print (\"type(X_test):\", type(X_test), X_test.shape)\n",
    "print (\"type(X_train):\", type(X_train), X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"X_train:\", X_train.shape)\n",
    "print (\"X_test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"type(y_train):\", type(y_train), y_train.shape, len(y_train.shape))\n",
    "print (\"type(y_test):\", type(y_test), y_test.shape, len(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(y_test.shape)==1:\n",
    "    y_train = to_categorical(y_train)\n",
    "else:\n",
    "    print (\"y_train already onehot'd, dont try again.\")\n",
    "\n",
    "if len(y_test.shape)==1:\n",
    "    y_test = to_categorical(y_test)\n",
    "else:\n",
    "    print (\"y_train already onehot'd, dont try again.\")\n",
    "\n",
    "print (\"type(y_train):\", type(y_train), y_train.shape)\n",
    "print (\"type(y_test):\", type(y_test), y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"y_train\\n\", y_train[0:5, :])\n",
    "print (\"y_test\\n\", y_test[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(histories):\n",
    "    #histories : list of history objects. nb: history.history dictionary structure\n",
    "    print (\"len(histories):\", len(histories))\n",
    "    if len(histories)==1: \n",
    "        history = histories\n",
    "    else:\n",
    "        history = {}\n",
    "        for i in histories[0].history.keys():\n",
    "            history[i] = []\n",
    "        #create empty history to copy into\n",
    "        for hist in histories:\n",
    "            for key in history.keys():\n",
    "                history[key] += hist.history[key]\n",
    "                #print (key, len(hist.history[key]), len(history[key]))\n",
    "\n",
    "    # list all data in history\n",
    "    print(history.keys(), len(history[history.keys()[0]]))\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history['acc'])\n",
    "    plt.plot(history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validate'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validate'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "#recall: (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "test_batches = gen.flow(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batchnormalisation : uses batches and test_batches created from image.ImageDataGenerator.flow(blah...)\n",
    "\n",
    "def get_model_bn_do():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),#added dropout here since it appears overtraining & validation not converging.\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model():\n",
    "    model = get_model_bn_do()\n",
    "    model.summary()\n",
    "    print (\"model.optimizer.lr:\", model.optimizer.lr)\n",
    "    history1 = model.fit_generator(batches, batches.n, nb_epoch=1, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.n)\n",
    "    print(\"model.fit_generator(..) completed with model.optimizer.lr:\", model.optimizer.lr)\n",
    "    model.optimizer.lr=0.1\n",
    "    history2 = model.fit_generator(batches, batches.n, nb_epoch=4, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.n)\n",
    "    print(\"model.fit_generator(..) completed with model.optimizer.lr:\", model.optimizer.lr)\n",
    "    model.optimizer.lr=0.01\n",
    "    history3 = model.fit_generator(batches, batches.n, nb_epoch=12, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.n)\n",
    "    print(\"model.fit_generator(..) completed with model.optimizer.lr:\", model.optimizer.lr)\n",
    "    model.optimizer.lr=0.001\n",
    "    history4 = model.fit_generator(batches, batches.n, nb_epoch=18, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.n)\n",
    "    print(\"model.fit_generator(..) completed with model.optimizer.lr:\", model.optimizer.lr)\n",
    "    plot_history([history1, history2, history3, history4])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [fit_model() for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = DATAPATH + 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"models:\", type(models), len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,m in enumerate(models):\n",
    "    m.save_weights(model_path+'cnn-mnist23-'+str(i)+'_2.h5')#nb: why .pkl instead of .h5? .pkl usually for pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = np.array([m.evaluate(X_test, y_test, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_mean = evals.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"evals_mean:\", evals_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (evals_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = np.stack([m.predict(X_test, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = all_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.metrics.categorical_accuracy(y_test, avg_preds).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start loading test data\n",
    "#Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive.\n",
    "colNames = []\n",
    "colDtypes = {}\n",
    "\n",
    "for i in range(784):\n",
    "    colNames.append(\"pixel\"+str(i))\n",
    "    colDtypes[\"pixel\"+str(i)] = np.int64\n",
    "print (colNames[0:2] + colNames[-2:])\n",
    "colNames = colNames\n",
    "print (colNames[0:2] + colNames[-2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(DATAPATH+'test.csv', names=colNames, dtype=colDtypes, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pixelData = df_test.as_matrix()\n",
    "print (\"test_pixelData.shape:\", test_pixelData.shape, test_pixelData.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_pixelData.reshape((test_pixelData.shape[0], 28, 28))\n",
    "print (\"X_test.shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X_test.shape)==3:\n",
    "    print(\"expand shape\")\n",
    "    X_test = np.expand_dims(X_test,1)\n",
    "else:\n",
    "        print(\"expand shape already done, don't do again.\")\n",
    "\n",
    "print (\"type(X_test):\", type(X_test), X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = np.stack([m.predict(X_test, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = all_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_preds[0])\n",
    "print(type(avg_preds[0]))\n",
    "print(type(list(avg_preds[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = []\n",
    "for i in range(avg_preds.shape[0]):\n",
    "    category.append(np.argmax(avg_preds[i]))\n",
    "    #print(i, category, avg_preds[i])\n",
    "    #break\n",
    "type(category), len(category), category[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageids = list(range(1, avg_preds.shape[0]+1))\n",
    "print (type(imageids), len(imageids), imageids[0:5], imageids[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe, write to csv\n",
    "#dataframe labels = ImageId,Label\n",
    "#df = pd.read_csv(DATAPATH+'train.csv', names=colNames, dtype=colDtypes, header=1)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'ImageId': imageids, 'Label': category})#, index=index, columns=['ImageId','Label'])\n",
    "print (df.shape)\n",
    "print (df.head())\n",
    "print (df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATAPATH+'submit_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
