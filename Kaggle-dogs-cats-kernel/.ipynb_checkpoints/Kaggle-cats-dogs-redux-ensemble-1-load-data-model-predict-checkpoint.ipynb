{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_or_prod = True #True = sample, False = production\n",
    "\n",
    "batch_size = 64 #ajust to suit memory capacity of hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING_DATA: /home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/sample/\n",
      "WORKING_TEST: /home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/sample/test/\n",
      "WORKING_TRAIN: /home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/sample/train/\n",
      "WORKING_VALID: /home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/sample/valid/\n",
      "s_or_p: _sample_\n"
     ]
    }
   ],
   "source": [
    "HOMEPATH = \"/home/ubuntu/fastai/\"\n",
    "\n",
    "DATA_PATH = HOMEPATH+\"data/Kaggle_dogs-vs-cats-redux-kernels-edition/\"\n",
    "\n",
    "MODEL_PATH = DATA_PATH+\"models/\"\n",
    "RESULTS_PATH = DATA_PATH+\"results/\"\n",
    "\n",
    "\n",
    "SAMPLE_DATA_PATH = DATA_PATH + \"sample/\"#choose this for testing or above for production\n",
    "SAMPLE_TEST_PATH = SAMPLE_DATA_PATH+\"test/\"\n",
    "SAMPLE_TRAIN_PATH = SAMPLE_DATA_PATH + \"train/\"\n",
    "SAMPLE_VALID_PATH = SAMPLE_DATA_PATH + \"valid/\"\n",
    "\n",
    "\n",
    "TEST_PATH = DATA_PATH+\"test/\"\n",
    "TRAIN_PATH = DATA_PATH + \"train/\"\n",
    "VALID_PATH = DATA_PATH + \"valid/\"\n",
    "\n",
    "\n",
    "if sample_or_prod:\n",
    "    WORKING_DATA  = SAMPLE_DATA_PATH\n",
    "    WORKING_TEST  = SAMPLE_TEST_PATH\n",
    "    WORKING_TRAIN = SAMPLE_TRAIN_PATH\n",
    "    WORKING_VALID = SAMPLE_VALID_PATH\n",
    "    s_or_p = \"_sample_\"\n",
    "else:\n",
    "    WORKING_DATA  = DATA_PATH\n",
    "    WORKING_TEST  = TEST_PATH\n",
    "    WORKING_TRAIN = TRAIN_PATH\n",
    "    WORKING_VALID = VALID_PATH\n",
    "    s_or_p = \"_prod_\"\n",
    "\n",
    "    \n",
    "print \"WORKING_DATA:\", WORKING_DATA\n",
    "print \"WORKING_TEST:\", WORKING_TEST\n",
    "print \"WORKING_TRAIN:\", WORKING_TRAIN\n",
    "print \"WORKING_VALID:\", WORKING_VALID\n",
    "print \"s_or_p:\", s_or_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from random import shuffle\n",
    "from shutil import copyfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('os.getcwd:', '/home/ubuntu/fastai')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5110)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(HOMEPATH)\n",
    "print (\"os.getcwd:\", os.getcwd())\n",
    "# Rather than importing everything manually, we'll make things easy\n",
    "#   and load them all in utils.py, and just import them from there.\n",
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition\n",
      "\u001b[01;34m.\u001b[00m\n",
      "├── \u001b[01;34mmodels\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain_convlayer_features_prod_.bc\u001b[00m\n",
      "│   │   ├── \u001b[01;34mdata\u001b[00m\n",
      "│   │   └── \u001b[01;34mmeta\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain_convlayer_features_sample_.bc\u001b[00m\n",
      "│   │   ├── \u001b[01;34mdata\u001b[00m\n",
      "│   │   └── \u001b[01;34mmeta\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain_data_prod_.bc\u001b[00m\n",
      "│   │   ├── \u001b[01;34mdata\u001b[00m\n",
      "│   │   └── \u001b[01;34mmeta\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain_data_sample_.bc\u001b[00m\n",
      "│   │   ├── \u001b[01;34mdata\u001b[00m\n",
      "│   │   └── \u001b[01;34mmeta\u001b[00m\n",
      "│   ├── \u001b[01;34mvalid_convlayer_features_prod_.bc\u001b[00m\n",
      "│   │   ├── \u001b[01;34mdata\u001b[00m\n",
      "│   │   └── \u001b[01;34mmeta\u001b[00m\n",
      "│   ├── \u001b[01;34mvalid_convlayer_features_sample_.bc\u001b[00m\n",
      "│   │   ├── \u001b[01;34mdata\u001b[00m\n",
      "│   │   └── \u001b[01;34mmeta\u001b[00m\n",
      "│   ├── \u001b[01;34mvalid_data_prod_.bc\u001b[00m\n",
      "│   │   ├── \u001b[01;34mdata\u001b[00m\n",
      "│   │   └── \u001b[01;34mmeta\u001b[00m\n",
      "│   └── \u001b[01;34mvalid_data_sample_.bc\u001b[00m\n",
      "│       ├── \u001b[01;34mdata\u001b[00m\n",
      "│       └── \u001b[01;34mmeta\u001b[00m\n",
      "├── \u001b[01;34mresults\u001b[00m\n",
      "├── \u001b[01;34msample\u001b[00m\n",
      "│   ├── \u001b[01;34mtest\u001b[00m\n",
      "│   │   └── \u001b[01;34munknown\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\n",
      "│   │   ├── \u001b[01;34mcat\u001b[00m\n",
      "│   │   └── \u001b[01;34mdog\u001b[00m\n",
      "│   └── \u001b[01;34mvalid\u001b[00m\n",
      "│       ├── \u001b[01;34mcat\u001b[00m\n",
      "│       └── \u001b[01;34mdog\u001b[00m\n",
      "├── \u001b[01;34mtest\u001b[00m\n",
      "│   └── \u001b[01;34munknown\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "│   ├── \u001b[01;34mcat\u001b[00m\n",
      "│   └── \u001b[01;34mdog\u001b[00m\n",
      "└── \u001b[01;34mvalid\u001b[00m\n",
      "    ├── \u001b[01;34mcat\u001b[00m\n",
      "    └── \u001b[01;34mdog\u001b[00m\n",
      "\n",
      "43 directories\n"
     ]
    }
   ],
   "source": [
    "os.chdir(DATA_PATH)\n",
    "print (os.getcwd())\n",
    "!tree -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = ['cat/', 'dog/']#nb: do not change order or trailing slash\n",
    "UNKNOWN = 'unknown/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_LIST = [DATA_PATH, SAMPLE_DATA_PATH, SAMPLE_TEST_PATH, SAMPLE_TEST_PATH+UNKNOWN, SAMPLE_TRAIN_PATH, \n",
    "                 SAMPLE_VALID_PATH, TEST_PATH, TEST_PATH+UNKNOWN, TRAIN_PATH, VALID_PATH, MODEL_PATH, RESULTS_PATH]\n",
    "\n",
    "\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    DATA_DIR_LIST.append(TRAIN_PATH+category)\n",
    "    DATA_DIR_LIST.append(VALID_PATH+category)\n",
    "    DATA_DIR_LIST.append(SAMPLE_TRAIN_PATH+category)\n",
    "    DATA_DIR_LIST.append(SAMPLE_VALID_PATH+category)\n",
    "\n",
    "\n",
    "#delete the variables we don't need to prevent accidental use.\n",
    "del SAMPLE_DATA_PATH\n",
    "del SAMPLE_TEST_PATH\n",
    "del SAMPLE_TRAIN_PATH\n",
    "del SAMPLE_VALID_PATH\n",
    "del TEST_PATH\n",
    "del TRAIN_PATH\n",
    "del VALID_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirFileList(dir_path):\n",
    "    return [name for name in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listDirsFileCount(DATA_DIR_LIST):\n",
    "    DATA_DIR_LIST = sorted(DATA_DIR_LIST)\n",
    "    for dir_ in DATA_DIR_LIST:\n",
    "        print dir_, len(dirFileList(dir_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showLayersInfo(model):\n",
    "    print \"Number of layers : \", len(model.layers)\n",
    "    count = 0\n",
    "    for layer in model.layers:\n",
    "        print count, type(layer), \", trainable:\", layer.trainable\n",
    "        print \"input:\", layer.input_shape, \", output:\",layer.output_shape, \"\\n\"\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validate'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validate'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/ 3\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/models/ 16\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/results/ 1\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/sample/ 0\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/sample/test/ 0\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/sample/test/unknown/ 2500\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/sample/train/ 0\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/sample/train/cat/ 1750\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/sample/train/dog/ 1750\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/sample/valid/ 0\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/sample/valid/cat/ 750\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/sample/valid/dog/ 750\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/test/ 0\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/test/unknown/ 12500\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/train/ 0\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/train/cat/ 8750\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/train/dog/ 8750\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/valid/ 0\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/valid/cat/ 3750\n",
      "/home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/valid/dog/ 3750\n"
     ]
    }
   ],
   "source": [
    "listDirsFileCount(DATA_DIR_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3500 images belonging to 2 classes.\n",
      "Found 1500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trn_batches = get_batches(WORKING_TRAIN, shuffle=False, batch_size=batch_size)\n",
    "val_batches = get_batches(WORKING_VALID, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('trn_batches:', <class 'keras.preprocessing.image.DirectoryIterator'>)\n",
      "('val_batches:', <class 'keras.preprocessing.image.DirectoryIterator'>)\n"
     ]
    }
   ],
   "source": [
    "print (\"trn_batches:\", type(trn_batches))\n",
    "print (\"val_batches:\", type(val_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING_DATA: /home/ubuntu/fastai/data/Kaggle_dogs-vs-cats-redux-kernels-edition/sample/\n",
      "Found 3500 images belonging to 2 classes.\n",
      "Found 1500 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 1 classes.\n",
      "val_classes: <type 'numpy.ndarray'> (1500,) [0 0 0 0 0]\n",
      "trn_classes: <type 'numpy.ndarray'> (3500,) [0 0 0 0 0]\n",
      "val_labels: <type 'numpy.ndarray'> (1500, 2) \n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "trn_labels: <type 'numpy.ndarray'> (3500, 2) \n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "val_filenames: <type 'list'> 1500\n",
      "filenames: <type 'list'> 3500\n",
      "test_filenames: <type 'list'> 2500\n"
     ]
    }
   ],
   "source": [
    "print \"WORKING_DATA:\", WORKING_DATA\n",
    "(val_classes, trn_classes, val_labels, trn_labels, val_filenames, filenames, test_filenames) = get_classes(WORKING_DATA)\n",
    "#utils.get_classes\n",
    "#return (val_batches.classes, batches.classes, onehot(val_batches.classes), onehot(batches.classes),\n",
    "#        val_batches.filenames, batches.filenames, test_batches.filenames)\n",
    "#NB: get_classes expects data in subdirectories 'train', 'valid', 'test'\n",
    "print \"val_classes:\", type(val_classes), val_classes.shape, val_classes[0:5]\n",
    "print \"trn_classes:\", type(trn_classes), trn_classes.shape, trn_classes[0:5]\n",
    "print \"val_labels:\", type(val_labels), val_labels.shape, \"\\n\", val_labels[0:5]\n",
    "print \"trn_labels:\", type(trn_labels), trn_labels.shape, \"\\n\",trn_labels[0:5]\n",
    "print \"val_filenames:\", type(val_filenames), len(val_filenames)\n",
    "print \"filenames:\", type(filenames), len(filenames)\n",
    "print \"test_filenames:\", type(test_filenames), len(test_filenames)\n",
    "\n",
    "#NBB: val_labels = onehot(val_classes) & trn_labels = onehot(trn_classes). onehot 'converts' from 1 to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_3 (Lambda)                (None, 3, 224, 224)   0           lambda_input_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_27 (ZeroPadding2D) (None, 3, 226, 226)   0           lambda_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_27 (Convolution2D) (None, 64, 224, 224)  1792        zeropadding2d_27[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_28 (ZeroPadding2D) (None, 64, 226, 226)  0           convolution2d_27[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_28 (Convolution2D) (None, 64, 224, 224)  36928       zeropadding2d_28[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_11 (MaxPooling2D)   (None, 64, 112, 112)  0           convolution2d_28[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_29 (ZeroPadding2D) (None, 64, 114, 114)  0           maxpooling2d_11[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_29 (Convolution2D) (None, 128, 112, 112) 73856       zeropadding2d_29[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_30 (ZeroPadding2D) (None, 128, 114, 114) 0           convolution2d_29[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_30 (Convolution2D) (None, 128, 112, 112) 147584      zeropadding2d_30[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_12 (MaxPooling2D)   (None, 128, 56, 56)   0           convolution2d_30[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_31 (ZeroPadding2D) (None, 128, 58, 58)   0           maxpooling2d_12[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_31 (Convolution2D) (None, 256, 56, 56)   295168      zeropadding2d_31[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_32 (ZeroPadding2D) (None, 256, 58, 58)   0           convolution2d_31[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_32 (Convolution2D) (None, 256, 56, 56)   590080      zeropadding2d_32[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_33 (ZeroPadding2D) (None, 256, 58, 58)   0           convolution2d_32[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_33 (Convolution2D) (None, 256, 56, 56)   590080      zeropadding2d_33[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_13 (MaxPooling2D)   (None, 256, 28, 28)   0           convolution2d_33[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_34 (ZeroPadding2D) (None, 256, 30, 30)   0           maxpooling2d_13[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_34 (Convolution2D) (None, 512, 28, 28)   1180160     zeropadding2d_34[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_35 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_34[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_35 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_35[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_36 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_35[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_36 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_36[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_14 (MaxPooling2D)   (None, 512, 14, 14)   0           convolution2d_36[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_37 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_14[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_37 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_37[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_38 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_37[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_38 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_38[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_39 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_38[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_39 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_39[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_15 (MaxPooling2D)   (None, 512, 7, 7)     0           convolution2d_39[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 25088)         0           maxpooling2d_15[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 4096)          102764544   flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 4096)          0           dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 4096)          16781312    dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 4096)          0           dense_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 1000)          4097000     dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Vgg16().model\n",
    "#model is stock vgg16 model, all layers trainable, input [3,224,224], output 1,000 classes. \n",
    "#needs to be modified to predict 2 classes.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers :  38\n",
      "0 <class 'keras.layers.core.Lambda'> , trainable: True\n",
      "input: (None, 3, 224, 224) , output: (None, 3, 224, 224) \n",
      "\n",
      "1 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 3, 224, 224) , output: (None, 3, 226, 226) \n",
      "\n",
      "2 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 3, 226, 226) , output: (None, 64, 224, 224) \n",
      "\n",
      "3 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 64, 224, 224) , output: (None, 64, 226, 226) \n",
      "\n",
      "4 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 64, 226, 226) , output: (None, 64, 224, 224) \n",
      "\n",
      "5 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 64, 224, 224) , output: (None, 64, 112, 112) \n",
      "\n",
      "6 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 64, 112, 112) , output: (None, 64, 114, 114) \n",
      "\n",
      "7 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 64, 114, 114) , output: (None, 128, 112, 112) \n",
      "\n",
      "8 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 128, 112, 112) , output: (None, 128, 114, 114) \n",
      "\n",
      "9 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 114, 114) , output: (None, 128, 112, 112) \n",
      "\n",
      "10 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 128, 112, 112) , output: (None, 128, 56, 56) \n",
      "\n",
      "11 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 128, 56, 56) , output: (None, 128, 58, 58) \n",
      "\n",
      "12 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 58, 58) , output: (None, 256, 56, 56) \n",
      "\n",
      "13 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 58, 58) \n",
      "\n",
      "14 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 58, 58) , output: (None, 256, 56, 56) \n",
      "\n",
      "15 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 58, 58) \n",
      "\n",
      "16 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 58, 58) , output: (None, 256, 56, 56) \n",
      "\n",
      "17 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 28, 28) \n",
      "\n",
      "18 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 28, 28) , output: (None, 256, 30, 30) \n",
      "\n",
      "19 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 30, 30) , output: (None, 512, 28, 28) \n",
      "\n",
      "20 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 30, 30) \n",
      "\n",
      "21 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 30, 30) , output: (None, 512, 28, 28) \n",
      "\n",
      "22 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 30, 30) \n",
      "\n",
      "23 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 30, 30) , output: (None, 512, 28, 28) \n",
      "\n",
      "24 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 14, 14) \n",
      "\n",
      "25 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) \n",
      "\n",
      "26 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) \n",
      "\n",
      "27 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) \n",
      "\n",
      "28 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) \n",
      "\n",
      "29 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) \n",
      "\n",
      "30 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) \n",
      "\n",
      "31 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 7, 7) \n",
      "\n",
      "32 <class 'keras.layers.core.Flatten'> , trainable: True\n",
      "input: (None, 512, 7, 7) , output: (None, 25088) \n",
      "\n",
      "33 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 25088) , output: (None, 4096) \n",
      "\n",
      "34 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) \n",
      "\n",
      "35 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) \n",
      "\n",
      "36 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) \n",
      "\n",
      "37 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 1000) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "showLayersInfo(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers,fc_layers = split_at(model, Convolution2D)\n",
    "#utils.split_at(model, layer_type) \n",
    "#splits model at last occurrance of layer_type. (in this case Convolution2D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers :  31\n",
      "0 <class 'keras.layers.core.Lambda'> , trainable: True\n",
      "input: (None, 3, 224, 224) , output: (None, 3, 224, 224) \n",
      "\n",
      "1 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 3, 224, 224) , output: (None, 3, 226, 226) \n",
      "\n",
      "2 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 3, 226, 226) , output: (None, 64, 224, 224) \n",
      "\n",
      "3 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 64, 224, 224) , output: (None, 64, 226, 226) \n",
      "\n",
      "4 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 64, 226, 226) , output: (None, 64, 224, 224) \n",
      "\n",
      "5 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 64, 224, 224) , output: (None, 64, 112, 112) \n",
      "\n",
      "6 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 64, 112, 112) , output: (None, 64, 114, 114) \n",
      "\n",
      "7 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 64, 114, 114) , output: (None, 128, 112, 112) \n",
      "\n",
      "8 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 128, 112, 112) , output: (None, 128, 114, 114) \n",
      "\n",
      "9 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 114, 114) , output: (None, 128, 112, 112) \n",
      "\n",
      "10 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 128, 112, 112) , output: (None, 128, 56, 56) \n",
      "\n",
      "11 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 128, 56, 56) , output: (None, 128, 58, 58) \n",
      "\n",
      "12 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 58, 58) , output: (None, 256, 56, 56) \n",
      "\n",
      "13 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 58, 58) \n",
      "\n",
      "14 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 58, 58) , output: (None, 256, 56, 56) \n",
      "\n",
      "15 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 58, 58) \n",
      "\n",
      "16 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 58, 58) , output: (None, 256, 56, 56) \n",
      "\n",
      "17 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 28, 28) \n",
      "\n",
      "18 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 28, 28) , output: (None, 256, 30, 30) \n",
      "\n",
      "19 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 30, 30) , output: (None, 512, 28, 28) \n",
      "\n",
      "20 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 30, 30) \n",
      "\n",
      "21 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 30, 30) , output: (None, 512, 28, 28) \n",
      "\n",
      "22 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 30, 30) \n",
      "\n",
      "23 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 30, 30) , output: (None, 512, 28, 28) \n",
      "\n",
      "24 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 14, 14) \n",
      "\n",
      "25 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) \n",
      "\n",
      "26 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) \n",
      "\n",
      "27 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) \n",
      "\n",
      "28 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) \n",
      "\n",
      "29 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) \n",
      "\n",
      "30 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "conv_model = Sequential(conv_layers)\n",
    "#31 layers, all trainable, last layer = Convolution2D\n",
    "showLayersInfo(conv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers :  7\n",
      "0 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 7, 7) \n",
      "\n",
      "1 <class 'keras.layers.core.Flatten'> , trainable: True\n",
      "input: (None, 512, 7, 7) , output: (None, 25088) \n",
      "\n",
      "2 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 25088) , output: (None, 4096) \n",
      "\n",
      "3 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) \n",
      "\n",
      "4 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) \n",
      "\n",
      "5 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) \n",
      "\n",
      "6 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 1000) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "showLayersInfo(Sequential(fc_layers))\n",
    "#7 layers, all trainable, last layer = Dence, 1000 classes output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 2017-12-20 09:47:22.903706\n",
      "val_features: (1500, 512, 14, 14)\n",
      "trn_features: (3500, 512, 14, 14)\n",
      "Time elapsed (hh:mm:ss.ms) 0:02:11.417398\n"
     ]
    }
   ],
   "source": [
    "startTime= datetime.now()\n",
    "print \"startTime:\", startTime\n",
    "\n",
    "val_features = conv_model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "print \"val_features:\", val_features.shape\n",
    "trn_features = conv_model.predict_generator(trn_batches, trn_batches.nb_sample)\n",
    "print \"trn_features:\", trn_features.shape\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print 'Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed)\n",
    "\n",
    "#https://keras.io/models/sequential/\n",
    "#predict_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
    "#Returns: A Numpy array of predictions.\n",
    "#sample mode: takes approx 2 minutes to run/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_array(MODEL_PATH + 'train_convlayer_features.bc', trn_features)\n",
    "#save_array(MODEL_PATH + 'valid_convlayer_features.bc', val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn_features = load_array(MODEL_PATH+'train_convlayer_features.bc')\n",
    "#val_features = load_array(MODEL_PATH+'valid_convlayer_features.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 2017-12-20 09:49:34.341189\n",
      "Found 3500 images belonging to 2 classes.\n",
      "trn: (3500, 3, 224, 224)\n",
      "Found 1500 images belonging to 2 classes.\n",
      "val: (1500, 3, 224, 224)\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:50.967448\n"
     ]
    }
   ],
   "source": [
    "startTime= datetime.now()\n",
    "print \"startTime:\", startTime\n",
    "\n",
    "trn = get_data(WORKING_TRAIN)\n",
    "print \"trn:\", trn.shape\n",
    "val = get_data(WORKING_VALID)\n",
    "print \"val:\", val.shape\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print 'Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed)\n",
    "#sample mode: tales approx 50s to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_array(MODEL_PATH+'train_data.bc', trn)\n",
    "#save_array(MODEL_PATH+'valid_data.bc', val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn = load_array(MODEL_PATH+'train_data.bc')\n",
    "#val = load_array(MODEL_PATH+'valid_data.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@start# of layers: 38\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Layer dropout_6 has multiple inbound nodes, hence the notion of \"layer output\" is ill-defined. Use `get_output_at(node_index)` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-9e9fa91adb81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"@start# of layers:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"@end# of layers:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutbound_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m             \u001b[0;31m# update self.inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36moutput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             raise AttributeError('Layer ' + self.name +\n\u001b[0;32m--> 786\u001b[0;31m                                  \u001b[0;34m' has multiple inbound nodes, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m                                  \u001b[0;34m'hence the notion of \"layer output\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                                  \u001b[0;34m'is ill-defined. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Layer dropout_6 has multiple inbound nodes, hence the notion of \"layer output\" is ill-defined. Use `get_output_at(node_index)` instead."
     ]
    }
   ],
   "source": [
    "print \"@start# of layers:\", len(model.layers)\n",
    "model.pop()\n",
    "model.pop()\n",
    "print \"@end# of layers:\", len(model.layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of layers: 37\n",
      "not ok to delete.\n",
      "@end: # of layers: 37\n"
     ]
    }
   ],
   "source": [
    "print \"# of layers:\", len(model.layers)\n",
    "if len(model.layers)==38:\n",
    "    print \"ok to delete\"\n",
    "    try:\n",
    "        model.pop()\n",
    "        model.pop()\n",
    "    except:\n",
    "        e = sys.exc_info()[0]\n",
    "        print \"error trapped:\", e\n",
    "else:\n",
    "    print \"not ok to delete.\"\n",
    "print \"@end: # of layers:\", len(model.layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 3, 224, 224)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           lambda_1[0][0]                   \n",
      "                                                                   lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 224, 224)  1792        zeropadding2d_1[0][0]            \n",
      "                                                                   zeropadding2d_1[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 64, 226, 226)  0           convolution2d_1[0][0]            \n",
      "                                                                   convolution2d_1[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 224, 224)  36928       zeropadding2d_2[0][0]            \n",
      "                                                                   zeropadding2d_2[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_2[0][0]            \n",
      "                                                                   convolution2d_2[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             \n",
      "                                                                   maxpooling2d_1[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 112, 112) 73856       zeropadding2d_3[0][0]            \n",
      "                                                                   zeropadding2d_3[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 128, 114, 114) 0           convolution2d_3[0][0]            \n",
      "                                                                   convolution2d_3[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 128, 112, 112) 147584      zeropadding2d_4[0][0]            \n",
      "                                                                   zeropadding2d_4[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_4[0][0]            \n",
      "                                                                   convolution2d_4[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 128, 58, 58)   0           maxpooling2d_2[0][0]             \n",
      "                                                                   maxpooling2d_2[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 56, 56)   295168      zeropadding2d_5[0][0]            \n",
      "                                                                   zeropadding2d_5[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_5[0][0]            \n",
      "                                                                   convolution2d_5[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_6[0][0]            \n",
      "                                                                   zeropadding2d_6[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_6[0][0]            \n",
      "                                                                   convolution2d_6[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_7[0][0]            \n",
      "                                                                   zeropadding2d_7[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_7[0][0]            \n",
      "                                                                   convolution2d_7[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 256, 30, 30)   0           maxpooling2d_3[0][0]             \n",
      "                                                                   maxpooling2d_3[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 512, 28, 28)   1180160     zeropadding2d_8[0][0]            \n",
      "                                                                   zeropadding2d_8[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 512, 30, 30)   0           convolution2d_8[0][0]            \n",
      "                                                                   convolution2d_8[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 28, 28)   2359808     zeropadding2d_9[0][0]            \n",
      "                                                                   zeropadding2d_9[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_9[0][0]            \n",
      "                                                                   convolution2d_9[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_10[0][0]           \n",
      "                                                                   zeropadding2d_10[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_10[0][0]           \n",
      "                                                                   convolution2d_10[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_4[0][0]             \n",
      "                                                                   maxpooling2d_4[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_11[0][0]           \n",
      "                                                                   zeropadding2d_11[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_11[0][0]           \n",
      "                                                                   convolution2d_11[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_12[0][0]           \n",
      "                                                                   zeropadding2d_12[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_12[0][0]           \n",
      "                                                                   convolution2d_12[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_13[0][0]           \n",
      "                                                                   zeropadding2d_13[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25088)         0           maxpooling2d_5[0][0]             \n",
      "                                                                   maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096)          102764544   flatten_1[0][0]                  \n",
      "                                                                   flatten_1[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           dense_1[0][0]                    \n",
      "                                                                   dense_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4096)          16781312    dropout_1[0][0]                  \n",
      "                                                                   dropout_1[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4096)          0           dense_2[0][0]                    \n",
      "                                                                   dense_2[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1000)          4097000     dropout_2[0][0]                  \n",
      "                                                                   dropout_2[1][0]                  \n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers :  37\n",
      "0 <class 'keras.layers.core.Lambda'> , trainable: True\n",
      "input: (None, 3, 224, 224) , output: (None, 3, 224, 224) \n",
      "\n",
      "1 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 3, 224, 224) , output: (None, 3, 226, 226) \n",
      "\n",
      "2 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 3, 226, 226) , output: (None, 64, 224, 224) \n",
      "\n",
      "3 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 64, 224, 224) , output: (None, 64, 226, 226) \n",
      "\n",
      "4 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 64, 226, 226) , output: (None, 64, 224, 224) \n",
      "\n",
      "5 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 64, 224, 224) , output: (None, 64, 112, 112) \n",
      "\n",
      "6 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 64, 112, 112) , output: (None, 64, 114, 114) \n",
      "\n",
      "7 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 64, 114, 114) , output: (None, 128, 112, 112) \n",
      "\n",
      "8 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 128, 112, 112) , output: (None, 128, 114, 114) \n",
      "\n",
      "9 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 114, 114) , output: (None, 128, 112, 112) \n",
      "\n",
      "10 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 128, 112, 112) , output: (None, 128, 56, 56) \n",
      "\n",
      "11 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 128, 56, 56) , output: (None, 128, 58, 58) \n",
      "\n",
      "12 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 58, 58) , output: (None, 256, 56, 56) \n",
      "\n",
      "13 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 58, 58) \n",
      "\n",
      "14 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 58, 58) , output: (None, 256, 56, 56) \n",
      "\n",
      "15 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 58, 58) \n",
      "\n",
      "16 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 58, 58) , output: (None, 256, 56, 56) \n",
      "\n",
      "17 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 28, 28) \n",
      "\n",
      "18 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 28, 28) , output: (None, 256, 30, 30) \n",
      "\n",
      "19 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 30, 30) , output: (None, 512, 28, 28) \n",
      "\n",
      "20 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 30, 30) \n",
      "\n",
      "21 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 30, 30) , output: (None, 512, 28, 28) \n",
      "\n",
      "22 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 30, 30) \n",
      "\n",
      "23 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 30, 30) , output: (None, 512, 28, 28) \n",
      "\n",
      "24 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 14, 14) \n",
      "\n",
      "25 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) \n",
      "\n",
      "26 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) \n",
      "\n",
      "27 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) \n",
      "\n",
      "28 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) \n",
      "\n",
      "29 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) \n",
      "\n",
      "30 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) \n",
      "\n",
      "31 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 7, 7) \n",
      "\n",
      "32 <class 'keras.layers.core.Flatten'> , trainable: True\n",
      "input: (None, 512, 7, 7) , output: (None, 25088) \n",
      "\n",
      "33 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 25088) , output: (None, 4096) \n",
      "\n",
      "34 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) \n",
      "\n",
      "35 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) \n",
      "\n",
      "36 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "showLayersInfo(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('trn_batches:', <class 'keras.preprocessing.image.DirectoryIterator'>, 'trn_batches.nb_sample:', 3500)\n",
      "('val_batches:', <class 'keras.preprocessing.image.DirectoryIterator'>, 'val_batches.nb_sample:', 1500)\n"
     ]
    }
   ],
   "source": [
    "print (\"trn_batches:\", type(trn_batches), \"trn_batches.nb_sample:\", trn_batches.nb_sample)\n",
    "print (\"val_batches:\", type(val_batches), \"val_batches.nb_sample:\", val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('startTime:', datetime.datetime(2017, 12, 20, 9, 50, 26, 639125))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-66117573350b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"startTime:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mll_val_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"ll_val_feat:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll_val_feat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mll_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, val_samples, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                                             \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                                             \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m                                             pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, val_samples, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1761\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1763\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/Theano-0.9.0-py2.7.egg/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/Theano-0.9.0-py2.7.egg/theano/ifelse.pyc\u001b[0m in \u001b[0;36mthunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "\n",
    "ll_val_feat = model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "print \"ll_val_feat:\", ll_val_feat.shape\n",
    "ll_feat = model.predict_generator(trn_batches, trn_batches.nb_sample)\n",
    "print \"ll_feat:\", ll_feat.shape\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "#NB: 64^2 = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_array(MODEL_PATH + 'train_ll_feat.bc', ll_feat)\n",
    "#save_array(MODEL_PATH + 'valid_ll_feat.bc', ll_val_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ll_feat = load_array(MODEL_PATH+ 'train_ll_feat.bc')\n",
    "#ll_val_feat = load_array(MODEL_PATH + 'valid_ll_feat.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_data(WORKING_TEST)\n",
    "print type(test), test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_array(MODEL_PATH+'test_data.bc', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = load_array(MODEL_PATH+'test_data.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ll_layers():\n",
    "    #get_ll_layers:create 3 layers, BatchNormalization + Dropout + Dense\n",
    "    return [ \n",
    "        BatchNormalization(input_shape=(4096,)),\n",
    "        Dropout(0.5),\n",
    "        Dense(2, activation='softmax') \n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_last_layer(i):\n",
    "    #get_ll_layers:create 3 layers, BatchNormalization + Dropout + Dense\n",
    "    #set learning rate, train model, set learning rate again, train model.\n",
    "    #pop last three layers from vgg16 model, make all layers non trainable.\n",
    "    #add 3 layers created in get_ll_layers to end of model.\n",
    "    #copy weights from 3 layers just trained to last three layers in vgg16 model.\n",
    "    ll_layers = get_ll_layers()\n",
    "    ll_model = Sequential(ll_layers)\n",
    "    ll_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    ll_model.optimizer.lr=1e-5\n",
    "    history = ll_model.fit(ll_feat, trn_labels, validation_data=(ll_val_feat, val_labels), nb_epoch=12)\n",
    "    print \"train_last_layer:i:\", i, \", ll_model.optimizer.lr:\", ll_model.optimizer.lr \n",
    "    plot_history(history)\n",
    "    \n",
    "    ll_model.optimizer.lr=1e-7\n",
    "    ll_model.fit(ll_feat, trn_labels, validation_data=(ll_val_feat, val_labels), nb_epoch=1)\n",
    "    #nb: cannot show history with only one epoch.\n",
    "    print \"ll_model.optimizer.lr:\", ll_model.optimizer.lr\n",
    "    ll_model.save_weights(MODEL_PATH+'ll_bn' + i + '.h5')\n",
    "\n",
    "    #create new vgg16 model & pop last 3 layers.\n",
    "    vgg = Vgg16()\n",
    "    model = vgg.model\n",
    "    model.pop(); model.pop(); model.pop()\n",
    "    #\n",
    "    for layer in model.layers: layer.trainable=False\n",
    "    #set all layers to non trainable\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    #create three layers ()\n",
    "    ll_layers = get_ll_layers()\n",
    "    #get_ll_layers:create 3 layers, BatchNormalization + Dropout + Dense, add these layers to model.\n",
    "    for layer in ll_layers: model.add(layer)\n",
    "    #copy the weights from the above trained ll_model to the just added  last 3 layers in model.\n",
    "    for l1,l2 in zip(ll_model.layers, model.layers[-3:]):\n",
    "        l2.set_weights(l1.get_weights())\n",
    "    \n",
    "    #compile model so it is ready for use.\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.save_weights(MODEL_PATH+'bn' + i + '.h5')\n",
    "    print \"@ end of train_last_layer, # layers = \", len(model.layers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model(model):\n",
    "    #split model into 2 sets of layers. \n",
    "    #conv_layers = start up to & including the last Convolution2D\n",
    "    #fc_layers   = rest of the model\n",
    "    #returns model, list of layers, int position of last Convolution2D layer. \n",
    "    \n",
    "    layers = model.layers\n",
    "    \n",
    "    #last_conv_idx = index of last Convolution2D layer\n",
    "    last_conv_idx = [index for index,layer in enumerate(layers) \n",
    "                         if type(layer) is Convolution2D][-1]\n",
    "\n",
    "    conv_layers = layers[:last_conv_idx+1]\n",
    "    conv_model = Sequential(conv_layers)\n",
    "    fc_layers = layers[last_conv_idx+1:]\n",
    "    return conv_model, fc_layers, last_conv_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fc_layers(p, in_shape):\n",
    "    #get_fc_layers creates 9 layers, with nominated input shape, nominated dropout rate\n",
    "    #MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout, Dense, BatchNormalization, Dropout, Dense\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=in_shape),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(2, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dense_layers(i, model):\n",
    "    \n",
    "    print \"start: train_dense_layers: i:\", i\n",
    "    print \"len(model.layers):\", len(model.layers)\n",
    "    #split model about last Convolutional2D layer\n",
    "    conv_model, fc_layers, last_conv_idx = get_conv_model(model)\n",
    "    #conv_model = Sqeuential(conv_layers) = list of layers, from start up to & including the last Convolution2D layer.\n",
    "    #fc_layers   = rest of the model\n",
    "    \n",
    "    \n",
    "    #shape of last Convolution2D layer output.\n",
    "    conv_shape = conv_model.output_shape[1:]\n",
    "    \n",
    "    ##get_fc_layers creates 9 layers, with nominated input shape, nominated dropout rate\n",
    "    #conv_shape ensures input shape from conv_model can be accepted.\n",
    "    fc_model = Sequential(get_fc_layers(0.5, conv_shape))\n",
    "    \n",
    "    showLayersInfo(fc_model)\n",
    "    showLayersInfo(Sequential(fc_layers))\n",
    "    #copy weights from layers in fc_layers to the newly created fc_model. \n",
    "    for l1,l2 in zip(fc_model.layers, fc_layers): \n",
    "        print(\"fc_model.layers:\", fc_model.layers, \"fc_layers:\", fc_layers)\n",
    "        weights = l2.get_weights()\n",
    "        print \"type(fc_layers.get_weights()):\", type(weights)\n",
    "        print \"type(fc_model.layers.get_weights()):\", l1.get_weights()\n",
    "        l1.set_weights(weights)\n",
    "    \n",
    "    \n",
    "    fc_model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    fc_model.fit(trn_features, trn_labels, nb_epoch=2, \n",
    "         batch_size=batch_size, validation_data=(val_features, val_labels))\n",
    "\n",
    "    #setup data augmentation.\n",
    "    gen = image.ImageDataGenerator(rotation_range=10, \n",
    "                                   width_shift_range=0.05, \n",
    "                                   width_zoom_range=0.05, \n",
    "                                   zoom_range=0.05, \n",
    "                                   channel_shift_range=10, \n",
    "                                   height_shift_range=0.05, \n",
    "                                   shear_range=0.05, \n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "    batches = gen.flow(trn, trn_labels, batch_size=batch_size)\n",
    "    \n",
    "    val_batches = image.ImageDataGenerator().flow(val, \n",
    "                                                  val_labels, \n",
    "                                                  shuffle=False, \n",
    "                                                  batch_size=batch_size)\n",
    "    \n",
    "    print \"type(val_batches):\", type(val_batches), \"val_batches.N:\", val_batches.N\n",
    "\n",
    "    print \"len(conv_model.layers):\", len(conv_model.layers)\n",
    "    \n",
    "    #set all layers in conv_model to non trainable\n",
    "    for layer in conv_model.layers: \n",
    "        layer.trainable = False\n",
    "\n",
    "    ##get_fc_layers creates 9 layers, with nominated input shape, nominated dropout rate\n",
    "    #conv_shape ensures input shape from conv_model can be accepted.\n",
    "    #add all layers to end of conv_model\n",
    "    for layer in get_fc_layers(0.5, conv_shape): \n",
    "        conv_model.add(layer)\n",
    "    print \"showLayersInfo(conv_model): after 1. setting layers to non trainable & 2. adding get_fc_layers to conv_model\"\n",
    "    showLayersInfo(conv_model)\n",
    "        \n",
    "    \n",
    "    #copy weights from fc_model.layers to the last 9 layers in conv_model.\n",
    "    #nb: weights in fc_model were trained \n",
    "    for l1,l2 in zip(conv_model.layers[last_conv_idx+1:], fc_model.layers): \n",
    "        l1.set_weights(l2.get_weights())\n",
    "\n",
    "    conv_model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    conv_model.save_weights(model_path+'no_dropout_bn' + i + '.h5')\n",
    "    \n",
    "    \n",
    "    conv_model.fit_generator(batches, \n",
    "                             samples_per_epoch=batches.N, \n",
    "                             nb_epoch=1, \n",
    "                             validation_data=val_batches, \n",
    "                             nb_val_samples=val_batches.N)\n",
    "    \n",
    "    #now make more of the models trainable.\n",
    "    for layer in conv_model.layers[16:]: layer.trainable = True\n",
    "\n",
    "    print \"showLayersInfo(conv_model): after 1. copying weights to conv_model from fc_model.layers.\"\n",
    "    print \"2. fitting, setting layers 16: to trainable.\"\n",
    "    \n",
    "    showLayersInfo(conv_model)\n",
    "\n",
    "\n",
    "    history = conv_model.fit_generator(batches, \n",
    "                             samples_per_epoch=batches.N, \n",
    "                             nb_epoch=8, \n",
    "                             validation_data=val_batches, \n",
    "                             nb_val_samples=val_batches.N)\n",
    "\n",
    "    print \"history = conv_model.fit_generator(blah....), conv_model.optimizer.lr:\", conv_model.optimizer.lr\n",
    "    plot_history(history)\n",
    "    \n",
    "    conv_model.optimizer.lr = 1e-7\n",
    "    history = conv_model.fit_generator(batches, \n",
    "                             samples_per_epoch=batches.N, \n",
    "                             nb_epoch=10, \n",
    "                             validation_data=val_batches, \n",
    "                             nb_val_samples=val_batches.N)\n",
    "\n",
    "    print \"history = conv_model.fit_generator(blah....), conv_model.optimizer.lr:\", conv_model.optimizer.lr\n",
    "    plot_history(history)\n",
    "    \n",
    "    conv_model.save_weights(model_path + 'aug' + i + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    i = str(i)\n",
    "    print \"i:\", i\n",
    "    model = train_last_layer(i)\n",
    "    train_dense_layers(i, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_model = vgg_ft(2)\n",
    "for layer in ens_model.layers: layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
