{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/state-farm-distracted-driver-detection  \n",
    "\n",
    "based on prev work by bmt.\n",
    "Kaggle-dogs-cats-kernel/Kaggle-cats-dogs-redux-ensemble-1-load-data-model-predict.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_or_prod = True #True = sample, False = production\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c0: safe driving  \n",
    "c1: texting - right  \n",
    "c2: talking on the phone - right  \n",
    "c3: texting - left  \n",
    "c4: talking on the phone - left  \n",
    "c5: operating the radio  \n",
    "c6: drinking  \n",
    "c7: reaching behind  \n",
    "c8: hair and makeup  \n",
    "c9: talking to passenger  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('HOMEPATH:', '/home/ubuntu/fastai/')\n",
      "('DATA_PATH:', '/home/ubuntu/fastai/data/state/')\n"
     ]
    }
   ],
   "source": [
    "HOMEPATH = \"/home/ubuntu/fastai/\"\n",
    "DATA_PATH = HOMEPATH + \"data/state/\"\n",
    "print(\"HOMEPATH:\", HOMEPATH)\n",
    "print(\"DATA_PATH:\", DATA_PATH)\n",
    "import os\n",
    "from __future__ import division, print_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from random import shuffle\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING_DATA: /home/ubuntu/fastai/data/state/sample/\n",
      "WORKING_TEST: /home/ubuntu/fastai/data/state/sample/test/\n",
      "WORKING_TRAIN: /home/ubuntu/fastai/data/state/sample/train/\n",
      "WORKING_VALID: /home/ubuntu/fastai/data/state/sample/valid/\n",
      "s_or_p: _sample_\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = DATA_PATH+\"models/\"\n",
    "RESULTS_PATH = DATA_PATH+\"results/\"\n",
    "\n",
    "\n",
    "SAMPLE_DATA_PATH = DATA_PATH + \"sample/\"#choose this for testing or above for production\n",
    "SAMPLE_TEST_PATH = SAMPLE_DATA_PATH+\"test/\"\n",
    "SAMPLE_TRAIN_PATH = SAMPLE_DATA_PATH + \"train/\"\n",
    "SAMPLE_VALID_PATH = SAMPLE_DATA_PATH + \"valid/\"\n",
    "\n",
    "\n",
    "TEST_PATH = DATA_PATH+\"test/\"\n",
    "TRAIN_PATH = DATA_PATH + \"train/\"\n",
    "VALID_PATH = DATA_PATH + \"valid/\"\n",
    "\n",
    "\n",
    "if sample_or_prod:\n",
    "    WORKING_DATA  = SAMPLE_DATA_PATH\n",
    "    WORKING_TEST  = SAMPLE_TEST_PATH\n",
    "    WORKING_TRAIN = SAMPLE_TRAIN_PATH\n",
    "    WORKING_VALID = SAMPLE_VALID_PATH\n",
    "    s_or_p = \"_sample_\"\n",
    "else:\n",
    "    WORKING_DATA  = DATA_PATH\n",
    "    WORKING_TEST  = TEST_PATH\n",
    "    WORKING_TRAIN = TRAIN_PATH\n",
    "    WORKING_VALID = VALID_PATH\n",
    "    s_or_p = \"_prod_\"\n",
    "\n",
    "    \n",
    "print (\"WORKING_DATA:\", WORKING_DATA)\n",
    "print (\"WORKING_TEST:\", WORKING_TEST)\n",
    "print (\"WORKING_TRAIN:\", WORKING_TRAIN)\n",
    "print (\"WORKING_VALID:\", WORKING_VALID)\n",
    "print (\"s_or_p:\", s_or_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastai/data/state\n",
      "\u001b[01;34m.\u001b[00m\n",
      "├── \u001b[01;34mmodels\u001b[00m\n",
      "├── \u001b[01;34mresults\u001b[00m\n",
      "├── \u001b[01;34msample\u001b[00m\n",
      "│   ├── \u001b[01;34mtest\u001b[00m\n",
      "│   │   └── \u001b[01;34munknown\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\n",
      "│   │   ├── \u001b[01;34mc0\u001b[00m\n",
      "│   │   ├── \u001b[01;34mc1\u001b[00m\n",
      "│   │   ├── \u001b[01;34mc2\u001b[00m\n",
      "│   │   ├── \u001b[01;34mc3\u001b[00m\n",
      "│   │   ├── \u001b[01;34mc4\u001b[00m\n",
      "│   │   ├── \u001b[01;34mc5\u001b[00m\n",
      "│   │   ├── \u001b[01;34mc6\u001b[00m\n",
      "│   │   ├── \u001b[01;34mc7\u001b[00m\n",
      "│   │   ├── \u001b[01;34mc8\u001b[00m\n",
      "│   │   └── \u001b[01;34mc9\u001b[00m\n",
      "│   └── \u001b[01;34mvalid\u001b[00m\n",
      "│       ├── \u001b[01;34mc0\u001b[00m\n",
      "│       ├── \u001b[01;34mc1\u001b[00m\n",
      "│       ├── \u001b[01;34mc2\u001b[00m\n",
      "│       ├── \u001b[01;34mc3\u001b[00m\n",
      "│       ├── \u001b[01;34mc4\u001b[00m\n",
      "│       ├── \u001b[01;34mc5\u001b[00m\n",
      "│       ├── \u001b[01;34mc6\u001b[00m\n",
      "│       ├── \u001b[01;34mc7\u001b[00m\n",
      "│       ├── \u001b[01;34mc8\u001b[00m\n",
      "│       └── \u001b[01;34mc9\u001b[00m\n",
      "├── \u001b[01;34mtest\u001b[00m\n",
      "│   └── \u001b[01;34munknown\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "│   ├── \u001b[01;34mc0\u001b[00m\n",
      "│   ├── \u001b[01;34mc1\u001b[00m\n",
      "│   ├── \u001b[01;34mc2\u001b[00m\n",
      "│   ├── \u001b[01;34mc3\u001b[00m\n",
      "│   ├── \u001b[01;34mc4\u001b[00m\n",
      "│   ├── \u001b[01;34mc5\u001b[00m\n",
      "│   ├── \u001b[01;34mc6\u001b[00m\n",
      "│   ├── \u001b[01;34mc7\u001b[00m\n",
      "│   ├── \u001b[01;34mc8\u001b[00m\n",
      "│   └── \u001b[01;34mc9\u001b[00m\n",
      "└── \u001b[01;34mvalid\u001b[00m\n",
      "    ├── \u001b[01;34mc0\u001b[00m\n",
      "    ├── \u001b[01;34mc1\u001b[00m\n",
      "    ├── \u001b[01;34mc2\u001b[00m\n",
      "    ├── \u001b[01;34mc3\u001b[00m\n",
      "    ├── \u001b[01;34mc4\u001b[00m\n",
      "    ├── \u001b[01;34mc5\u001b[00m\n",
      "    ├── \u001b[01;34mc6\u001b[00m\n",
      "    ├── \u001b[01;34mc7\u001b[00m\n",
      "    ├── \u001b[01;34mc8\u001b[00m\n",
      "    └── \u001b[01;34mc9\u001b[00m\n",
      "\n",
      "51 directories\n"
     ]
    }
   ],
   "source": [
    "os.chdir(DATA_PATH)\n",
    "print (os.getcwd())\n",
    "!tree -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirFileList(dir_path):\n",
    "    return [name for name in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, name))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATEGORIES: ['c0/', 'c1/', 'c2/', 'c3/', 'c4/', 'c5/', 'c6/', 'c7/', 'c8/', 'c9/']\n"
     ]
    }
   ],
   "source": [
    "CATEGORIES = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    CATEGORIES.append(\"c\"+str(i)+\"/\")\n",
    "print (\"CATEGORIES:\", CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKNOWN = 'unknown/'\n",
    "\n",
    "DATA_DIR_LIST = [DATA_PATH, SAMPLE_DATA_PATH, SAMPLE_TEST_PATH, SAMPLE_TEST_PATH+UNKNOWN, SAMPLE_TRAIN_PATH, \n",
    "                 SAMPLE_VALID_PATH, TEST_PATH, TEST_PATH+UNKNOWN, TRAIN_PATH, VALID_PATH, MODEL_PATH, RESULTS_PATH]\n",
    "\n",
    "\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    DATA_DIR_LIST.append(TRAIN_PATH+category)\n",
    "    DATA_DIR_LIST.append(VALID_PATH+category)\n",
    "    DATA_DIR_LIST.append(SAMPLE_TRAIN_PATH+category)\n",
    "    DATA_DIR_LIST.append(SAMPLE_VALID_PATH+category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showLayersInfo(model):\n",
    "    print (\"Number of layers : \", len(model.layers))\n",
    "    count = 0\n",
    "    for layer in model.layers:\n",
    "        print (count, type(layer), \", trainable:\", layer.trainable)\n",
    "        print (\"input:\", layer.input_shape, \", output:\",layer.output_shape, \", len(weights)\", len(layer.get_weights()), \"\\n\")\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validate'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validate'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listDirsFileCount(DATA_DIR_LIST):\n",
    "    DATA_DIR_LIST = sorted(DATA_DIR_LIST)\n",
    "    for dir_ in DATA_DIR_LIST:\n",
    "        print (dir_, len(dirFileList(dir_)))\n",
    "        \n",
    "#NB: could have used global DATA_DIR_LIST  to access global variable DATA_DIR_LIST \n",
    "# without having to pass DATA_DIR_LIST as an arg, but this gives more flexability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastai/data/state/ 5\n",
      "/home/ubuntu/fastai/data/state/models/ 0\n",
      "/home/ubuntu/fastai/data/state/results/ 2\n",
      "/home/ubuntu/fastai/data/state/sample/ 0\n",
      "/home/ubuntu/fastai/data/state/sample/test/ 0\n",
      "/home/ubuntu/fastai/data/state/sample/test/unknown/ 15945\n",
      "/home/ubuntu/fastai/data/state/sample/train/ 0\n",
      "/home/ubuntu/fastai/data/state/sample/train/c0/ 347\n",
      "/home/ubuntu/fastai/data/state/sample/train/c1/ 314\n",
      "/home/ubuntu/fastai/data/state/sample/train/c2/ 323\n",
      "/home/ubuntu/fastai/data/state/sample/train/c3/ 325\n",
      "/home/ubuntu/fastai/data/state/sample/train/c4/ 323\n",
      "/home/ubuntu/fastai/data/state/sample/train/c5/ 322\n",
      "/home/ubuntu/fastai/data/state/sample/train/c6/ 324\n",
      "/home/ubuntu/fastai/data/state/sample/train/c7/ 278\n",
      "/home/ubuntu/fastai/data/state/sample/train/c8/ 268\n",
      "/home/ubuntu/fastai/data/state/sample/train/c9/ 298\n",
      "/home/ubuntu/fastai/data/state/sample/valid/ 0\n",
      "/home/ubuntu/fastai/data/state/sample/valid/c0/ 153\n",
      "/home/ubuntu/fastai/data/state/sample/valid/c1/ 138\n",
      "/home/ubuntu/fastai/data/state/sample/valid/c2/ 140\n",
      "/home/ubuntu/fastai/data/state/sample/valid/c3/ 145\n",
      "/home/ubuntu/fastai/data/state/sample/valid/c4/ 141\n",
      "/home/ubuntu/fastai/data/state/sample/valid/c5/ 140\n",
      "/home/ubuntu/fastai/data/state/sample/valid/c6/ 143\n",
      "/home/ubuntu/fastai/data/state/sample/valid/c7/ 121\n",
      "/home/ubuntu/fastai/data/state/sample/valid/c8/ 117\n",
      "/home/ubuntu/fastai/data/state/sample/valid/c9/ 131\n",
      "/home/ubuntu/fastai/data/state/test/ 0\n",
      "/home/ubuntu/fastai/data/state/test/unknown/ 79726\n",
      "/home/ubuntu/fastai/data/state/train/ 0\n",
      "/home/ubuntu/fastai/data/state/train/c0/ 1740\n",
      "/home/ubuntu/fastai/data/state/train/c1/ 1585\n",
      "/home/ubuntu/fastai/data/state/train/c2/ 1623\n",
      "/home/ubuntu/fastai/data/state/train/c3/ 1641\n",
      "/home/ubuntu/fastai/data/state/train/c4/ 1625\n",
      "/home/ubuntu/fastai/data/state/train/c5/ 1618\n",
      "/home/ubuntu/fastai/data/state/train/c6/ 1625\n",
      "/home/ubuntu/fastai/data/state/train/c7/ 1402\n",
      "/home/ubuntu/fastai/data/state/train/c8/ 1336\n",
      "/home/ubuntu/fastai/data/state/train/c9/ 1489\n",
      "/home/ubuntu/fastai/data/state/valid/ 0\n",
      "/home/ubuntu/fastai/data/state/valid/c0/ 749\n",
      "/home/ubuntu/fastai/data/state/valid/c1/ 682\n",
      "/home/ubuntu/fastai/data/state/valid/c2/ 694\n",
      "/home/ubuntu/fastai/data/state/valid/c3/ 705\n",
      "/home/ubuntu/fastai/data/state/valid/c4/ 701\n",
      "/home/ubuntu/fastai/data/state/valid/c5/ 694\n",
      "/home/ubuntu/fastai/data/state/valid/c6/ 700\n",
      "/home/ubuntu/fastai/data/state/valid/c7/ 600\n",
      "/home/ubuntu/fastai/data/state/valid/c8/ 575\n",
      "/home/ubuntu/fastai/data/state/valid/c9/ 640\n"
     ]
    }
   ],
   "source": [
    "listDirsFileCount(DATA_DIR_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working directory: /home/ubuntu/fastai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5110)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(HOMEPATH)\n",
    "print (\"current working directory:\", os.getcwd())\n",
    "\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "#path = \"data/state/\"\n",
    "path = \"data/state/sample/\"\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3122 images belonging to 10 classes.\n",
      "Found 1369 images belonging to 10 classes.\n",
      "Found 15945 images belonging to 1 classes.\n",
      "/home/ubuntu/fastai/data/state/sample/train/ <class 'keras.preprocessing.image.DirectoryIterator'>\n",
      "/home/ubuntu/fastai/data/state/sample/valid/ <class 'keras.preprocessing.image.DirectoryIterator'>\n",
      "/home/ubuntu/fastai/data/state/sample/test/ <class 'keras.preprocessing.image.DirectoryIterator'>\n"
     ]
    }
   ],
   "source": [
    "trn_batches = get_batches(WORKING_TRAIN, shuffle=False, batch_size=batch_size)#should be shuffle=True\n",
    "val_batches = get_batches(WORKING_VALID, shuffle=False, batch_size=batch_size)\n",
    "test_batches = get_batches(WORKING_TEST, shuffle=False, batch_size=batch_size)\n",
    "print (WORKING_TRAIN, type(trn_batches))\n",
    "print (WORKING_VALID, type(val_batches))\n",
    "print (WORKING_TEST, type(test_batches))\n",
    "\n",
    "#https://keras.io/preprocessing/image/\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/DirectoryIterator\n",
    "#NB: utils.get_batches has default target_size=(224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3122 images belonging to 10 classes.\n",
      "Found 1369 images belonging to 10 classes.\n",
      "Found 15945 images belonging to 1 classes.\n",
      "val_classes <type 'numpy.ndarray'> (1369,)\n",
      "trn_classes <type 'numpy.ndarray'> (3122,)\n",
      "val_labels <type 'numpy.ndarray'> (1369, 10)\n",
      "trn_labels <type 'numpy.ndarray'> (3122, 10)\n",
      "val_filenames <type 'list'> 1369\n",
      "filenames <type 'list'> 3122\n",
      "test_filename <type 'list'> 15945\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, val_filenames, filenames, test_filename) = get_classes(WORKING_DATA)\n",
    "\n",
    "print (\"val_classes\", type(val_classes), val_classes.shape)\n",
    "print (\"trn_classes\", type(trn_classes), trn_classes.shape)\n",
    "print (\"val_labels\", type(val_labels), val_labels.shape)\n",
    "print (\"trn_labels\", type(trn_labels), trn_labels.shape)\n",
    "print (\"val_filenames\", type(val_filenames), len(val_filenames))\n",
    "print (\"filenames\", type(filenames), len(filenames))\n",
    "print (\"test_filename\", type(test_filename), len(test_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_filename[0] unknown/img_92913.jpg\n"
     ]
    }
   ],
   "source": [
    "print (\"test_filename[0]\", test_filename[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"val_classes:\", type(val_classes[0]), val_classes[0], np.unique(val_classes))\n",
    "print (\"trn_classes:\", type(trn_classes[0]), trn_classes[0], np.unique(trn_classes))\n",
    "print (\"val_labels:\", type(val_labels[0]), val_labels[0], np.unique(val_labels))\n",
    "print (\"trn_labels:\", type(trn_labels[0]), trn_labels[0], np.unique(trn_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_path: /home/ubuntu/fastai/data/state/train/c0/\n",
      "image_sizes: set([(480, 640, 3)])\n",
      "No. of disctinct image sizes: 1\n"
     ]
    }
   ],
   "source": [
    "#quick sanity check on image sizes in the data. \n",
    "temp_path = TRAIN_PATH+CATEGORIES[0]\n",
    "print (\"temp_path:\", temp_path)\n",
    "files = dirFileList(temp_path)\n",
    "\n",
    "image_sizes = set([])\n",
    "for i in range(len(files)):\n",
    "    img_shape = cv2.imread(temp_path+files[i]).shape\n",
    "    #print (\"i:\", i, \":\", img_shape)\n",
    "    image_sizes.add(img_shape)\n",
    "print (\"image_sizes:\", image_sizes)\n",
    "print (\"No. of distinct image sizes:\", len(image_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Vgg16().model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showLayersInfo(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers,fc_layers = split_at(model, Convolution2D)\n",
    "#utils.split_at(model, layer_type) \n",
    "#splits model at last occurrance of layer_type. (in this case Convolution2D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model        # of layers: 38\n",
      "conv_layers  # of layers: 31\n",
      "fc_layers    # of layers: 7\n"
     ]
    }
   ],
   "source": [
    "print (\"model        # of layers:\",  len(model.layers))\n",
    "print (\"conv_layers  # of layers:\",  len(conv_layers))\n",
    "print (\"fc_layers    # of layers:\",  len(fc_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = Sequential(conv_layers)\n",
    "#31 layers, all trainable, last layer = Convolution2D\n",
    "#showLayersInfo(conv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showLayersInfo(Sequential(fc_layers))\n",
    "#7 layers, all trainable, last layer = Dense, 1000 classes output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 2018-01-04 08:51:38.104244\n",
      "val_features: (1369, 512, 14, 14)\n",
      "trn_features: (3122, 512, 14, 14)\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:56.304315\n"
     ]
    }
   ],
   "source": [
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "\n",
    "#val_batches: <class 'keras.preprocessing.image.DirectoryIterator'>\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/DirectoryIterator\n",
    "#\n",
    "\n",
    "val_features = conv_model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "print (\"val_features:\", val_features.shape)\n",
    "trn_features = conv_model.predict_generator(trn_batches, trn_batches.nb_sample)\n",
    "print (\"trn_features:\", trn_features.shape)\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print ('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "#NB: val_features and trn_features have shape (No of input images, 512, 14, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_array(MODEL_PATH + 'train_convlayer_features.bc', trn_features)\n",
    "#save_array(MODEL_PATH + 'valid_convlayer_features.bc', val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn_features = load_array(MODEL_PATH+'train_convlayer_features.bc')\n",
    "#val_features = load_array(MODEL_PATH+'valid_convlayer_features.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 2018-01-04 09:02:55.554154\n",
      "Found 3122 images belonging to 10 classes.\n",
      "trn: (3122, 3, 224, 224)\n",
      "Found 1369 images belonging to 10 classes.\n",
      "val: (1369, 3, 224, 224)\n",
      "Found 15945 images belonging to 1 classes.\n",
      "test: (15945, 3, 224, 224)\n",
      "Time elapsed (hh:mm:ss.ms) 0:04:07.367869\n"
     ]
    }
   ],
   "source": [
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "\n",
    "trn = get_data(WORKING_TRAIN)\n",
    "print (\"trn:\", trn.shape)\n",
    "val = get_data(WORKING_VALID)\n",
    "print (\"val:\", val.shape)\n",
    "test = get_data(WORKING_TEST)\n",
    "print (\"test:\", test.shape)\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print ('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "#sample mode: tales approx 50s to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_array(MODEL_PATH+'train_data.bc', trn)\n",
    "#save_array(MODEL_PATH+'valid_data.bc', val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn = load_array(MODEL_PATH+'train_data.bc')\n",
    "#val = load_array(MODEL_PATH+'valid_data.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers :  38\n",
      "0 <class 'keras.layers.core.Lambda'> , trainable: True\n",
      "input: (None, 3, 224, 224) , output: (None, 3, 224, 224) , len(weights) 0 \n",
      "\n",
      "1 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 3, 224, 224) , output: (None, 3, 226, 226) , len(weights) 0 \n",
      "\n",
      "2 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 3, 226, 226) , output: (None, 64, 224, 224) , len(weights) 2 \n",
      "\n",
      "3 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 64, 224, 224) , output: (None, 64, 226, 226) , len(weights) 0 \n",
      "\n",
      "4 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 64, 226, 226) , output: (None, 64, 224, 224) , len(weights) 2 \n",
      "\n",
      "5 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 64, 224, 224) , output: (None, 64, 112, 112) , len(weights) 0 \n",
      "\n",
      "6 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 64, 112, 112) , output: (None, 64, 114, 114) , len(weights) 0 \n",
      "\n",
      "7 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 64, 114, 114) , output: (None, 128, 112, 112) , len(weights) 2 \n",
      "\n",
      "8 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 128, 112, 112) , output: (None, 128, 114, 114) , len(weights) 0 \n",
      "\n",
      "9 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 114, 114) , output: (None, 128, 112, 112) , len(weights) 2 \n",
      "\n",
      "10 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 128, 112, 112) , output: (None, 128, 56, 56) , len(weights) 0 \n",
      "\n",
      "11 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 128, 56, 56) , output: (None, 128, 58, 58) , len(weights) 0 \n",
      "\n",
      "12 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 58, 58) , output: (None, 256, 56, 56) , len(weights) 2 \n",
      "\n",
      "13 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 58, 58) , len(weights) 0 \n",
      "\n",
      "14 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 58, 58) , output: (None, 256, 56, 56) , len(weights) 2 \n",
      "\n",
      "15 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 58, 58) , len(weights) 0 \n",
      "\n",
      "16 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 58, 58) , output: (None, 256, 56, 56) , len(weights) 2 \n",
      "\n",
      "17 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 28, 28) , len(weights) 0 \n",
      "\n",
      "18 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 28, 28) , output: (None, 256, 30, 30) , len(weights) 0 \n",
      "\n",
      "19 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 30, 30) , output: (None, 512, 28, 28) , len(weights) 2 \n",
      "\n",
      "20 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 30, 30) , len(weights) 0 \n",
      "\n",
      "21 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 30, 30) , output: (None, 512, 28, 28) , len(weights) 2 \n",
      "\n",
      "22 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 30, 30) , len(weights) 0 \n",
      "\n",
      "23 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 30, 30) , output: (None, 512, 28, 28) , len(weights) 2 \n",
      "\n",
      "24 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 14, 14) , len(weights) 0 \n",
      "\n",
      "25 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) , len(weights) 0 \n",
      "\n",
      "26 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) , len(weights) 2 \n",
      "\n",
      "27 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) , len(weights) 0 \n",
      "\n",
      "28 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) , len(weights) 2 \n",
      "\n",
      "29 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) , len(weights) 0 \n",
      "\n",
      "30 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) , len(weights) 2 \n",
      "\n",
      "31 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 7, 7) , len(weights) 0 \n",
      "\n",
      "32 <class 'keras.layers.core.Flatten'> , trainable: True\n",
      "input: (None, 512, 7, 7) , output: (None, 25088) , len(weights) 0 \n",
      "\n",
      "33 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 25088) , output: (None, 4096) , len(weights) 2 \n",
      "\n",
      "34 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 0 \n",
      "\n",
      "35 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 2 \n",
      "\n",
      "36 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 0 \n",
      "\n",
      "37 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 1000) , len(weights) 2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "showLayersInfo(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@start# of layers: 38\n",
      "@end# of layers: 36\n"
     ]
    }
   ],
   "source": [
    "print (\"@start# of layers:\", len(model.layers))#should be 38 layers before popping\n",
    "model.pop()\n",
    "model.pop()\n",
    "print (\"@end# of layers:\", len(model.layers))#should be 36 layers after popping\n",
    "#showLayersInfo(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 3, 224, 224)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           lambda_1[0][0]                   \n",
      "                                                                   lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 224, 224)  1792        zeropadding2d_1[0][0]            \n",
      "                                                                   zeropadding2d_1[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 64, 226, 226)  0           convolution2d_1[0][0]            \n",
      "                                                                   convolution2d_1[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 224, 224)  36928       zeropadding2d_2[0][0]            \n",
      "                                                                   zeropadding2d_2[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_2[0][0]            \n",
      "                                                                   convolution2d_2[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             \n",
      "                                                                   maxpooling2d_1[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 112, 112) 73856       zeropadding2d_3[0][0]            \n",
      "                                                                   zeropadding2d_3[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 128, 114, 114) 0           convolution2d_3[0][0]            \n",
      "                                                                   convolution2d_3[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 128, 112, 112) 147584      zeropadding2d_4[0][0]            \n",
      "                                                                   zeropadding2d_4[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_4[0][0]            \n",
      "                                                                   convolution2d_4[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 128, 58, 58)   0           maxpooling2d_2[0][0]             \n",
      "                                                                   maxpooling2d_2[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 56, 56)   295168      zeropadding2d_5[0][0]            \n",
      "                                                                   zeropadding2d_5[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_5[0][0]            \n",
      "                                                                   convolution2d_5[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_6[0][0]            \n",
      "                                                                   zeropadding2d_6[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_6[0][0]            \n",
      "                                                                   convolution2d_6[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_7[0][0]            \n",
      "                                                                   zeropadding2d_7[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_7[0][0]            \n",
      "                                                                   convolution2d_7[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 256, 30, 30)   0           maxpooling2d_3[0][0]             \n",
      "                                                                   maxpooling2d_3[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 512, 28, 28)   1180160     zeropadding2d_8[0][0]            \n",
      "                                                                   zeropadding2d_8[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 512, 30, 30)   0           convolution2d_8[0][0]            \n",
      "                                                                   convolution2d_8[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 28, 28)   2359808     zeropadding2d_9[0][0]            \n",
      "                                                                   zeropadding2d_9[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_9[0][0]            \n",
      "                                                                   convolution2d_9[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_10[0][0]           \n",
      "                                                                   zeropadding2d_10[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_10[0][0]           \n",
      "                                                                   convolution2d_10[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_4[0][0]             \n",
      "                                                                   maxpooling2d_4[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_11[0][0]           \n",
      "                                                                   zeropadding2d_11[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_11[0][0]           \n",
      "                                                                   convolution2d_11[1][0]           \n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convolution2d_12 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_12[0][0]           \n",
      "                                                                   zeropadding2d_12[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_12[0][0]           \n",
      "                                                                   convolution2d_12[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_13[0][0]           \n",
      "                                                                   zeropadding2d_13[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25088)         0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096)          102764544   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4096)          16781312    dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers :  36\n",
      "0 <class 'keras.layers.core.Lambda'> , trainable: True\n",
      "input: (None, 3, 224, 224) , output: (None, 3, 224, 224) , len(weights) 0 \n",
      "\n",
      "1 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 3, 224, 224) , output: (None, 3, 226, 226) , len(weights) 0 \n",
      "\n",
      "2 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 3, 226, 226) , output: (None, 64, 224, 224) , len(weights) 2 \n",
      "\n",
      "3 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 64, 224, 224) , output: (None, 64, 226, 226) , len(weights) 0 \n",
      "\n",
      "4 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 64, 226, 226) , output: (None, 64, 224, 224) , len(weights) 2 \n",
      "\n",
      "5 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 64, 224, 224) , output: (None, 64, 112, 112) , len(weights) 0 \n",
      "\n",
      "6 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 64, 112, 112) , output: (None, 64, 114, 114) , len(weights) 0 \n",
      "\n",
      "7 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 64, 114, 114) , output: (None, 128, 112, 112) , len(weights) 2 \n",
      "\n",
      "8 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 128, 112, 112) , output: (None, 128, 114, 114) , len(weights) 0 \n",
      "\n",
      "9 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 114, 114) , output: (None, 128, 112, 112) , len(weights) 2 \n",
      "\n",
      "10 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 128, 112, 112) , output: (None, 128, 56, 56) , len(weights) 0 \n",
      "\n",
      "11 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 128, 56, 56) , output: (None, 128, 58, 58) , len(weights) 0 \n",
      "\n",
      "12 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 128, 58, 58) , output: (None, 256, 56, 56) , len(weights) 2 \n",
      "\n",
      "13 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 58, 58) , len(weights) 0 \n",
      "\n",
      "14 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 58, 58) , output: (None, 256, 56, 56) , len(weights) 2 \n",
      "\n",
      "15 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 58, 58) , len(weights) 0 \n",
      "\n",
      "16 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 58, 58) , output: (None, 256, 56, 56) , len(weights) 2 \n",
      "\n",
      "17 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 28, 28) , len(weights) 0 \n",
      "\n",
      "18 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 28, 28) , output: (None, 256, 30, 30) , len(weights) 0 \n",
      "\n",
      "19 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 30, 30) , output: (None, 512, 28, 28) , len(weights) 2 \n",
      "\n",
      "20 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 30, 30) , len(weights) 0 \n",
      "\n",
      "21 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 30, 30) , output: (None, 512, 28, 28) , len(weights) 2 \n",
      "\n",
      "22 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 30, 30) , len(weights) 0 \n",
      "\n",
      "23 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 30, 30) , output: (None, 512, 28, 28) , len(weights) 2 \n",
      "\n",
      "24 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 14, 14) , len(weights) 0 \n",
      "\n",
      "25 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) , len(weights) 0 \n",
      "\n",
      "26 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) , len(weights) 2 \n",
      "\n",
      "27 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) , len(weights) 0 \n",
      "\n",
      "28 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) , len(weights) 2 \n",
      "\n",
      "29 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) , len(weights) 0 \n",
      "\n",
      "30 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) , len(weights) 2 \n",
      "\n",
      "31 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 7, 7) , len(weights) 0 \n",
      "\n",
      "32 <class 'keras.layers.core.Flatten'> , trainable: True\n",
      "input: (None, 512, 7, 7) , output: (None, 25088) , len(weights) 0 \n",
      "\n",
      "33 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 25088) , output: (None, 4096) , len(weights) 2 \n",
      "\n",
      "34 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 0 \n",
      "\n",
      "35 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "showLayersInfo(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_batches: <class 'keras.preprocessing.image.DirectoryIterator'> trn_batches.nb_sample: 3122\n",
      "val_batches: <class 'keras.preprocessing.image.DirectoryIterator'> val_batches.nb_sample: 1369\n"
     ]
    }
   ],
   "source": [
    "print (\"trn_batches:\", type(trn_batches), \"trn_batches.nb_sample:\", trn_batches.nb_sample)\n",
    "print (\"val_batches:\", type(val_batches), \"val_batches.nb_sample:\", val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 2018-01-04 09:07:29.688633\n",
      "ll_val_feat: (1369, 4096)\n",
      "ll_feat: (3122, 4096)\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:56.123319\n"
     ]
    }
   ],
   "source": [
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "\n",
    "ll_val_feat = model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "print (\"ll_val_feat:\", ll_val_feat.shape)\n",
    "ll_feat = model.predict_generator(trn_batches, trn_batches.nb_sample)\n",
    "print (\"ll_feat:\", ll_feat.shape)\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print ('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "#https://keras.io/models/sequential/\n",
    "#predict_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
    "#Returns : A Numpy array of predictions.\n",
    "#NB: ll_val_feat & ll_feat has shape = (number of imaes, 4096)\n",
    "#last layer of model is Dense with output: (None, 4096)\n",
    "#NB: model = Vgg16().model then last two layers pop'd. \n",
    "#ie: not a standard VGG16 model and output needs fixing to predict classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_array(MODEL_PATH + 'train_ll_feat.bc', ll_feat)\n",
    "#save_array(MODEL_PATH + 'valid_ll_feat.bc', ll_val_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ll_feat = load_array(MODEL_PATH+ 'train_ll_feat.bc')\n",
    "#ll_val_feat = load_array(MODEL_PATH + 'valid_ll_feat.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ll_layers():\n",
    "    #get_ll_layers:create 3 layers, BatchNormalization + Dropout + Dense\n",
    "    #NB: Dense needs to have 10 classes for this problem\n",
    "    return [ \n",
    "        BatchNormalization(input_shape=(4096,)),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax') \n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_last_layer(i):\n",
    "    #nb: i is used in the filename to save weights.\n",
    "    #get_ll_layers:create 3 layers, BatchNormalization + Dropout + Dense\n",
    "    #set learning rate, train model, set learning rate again, train model.\n",
    "    #pop last three layers from vgg16 model, make all layers non trainable.\n",
    "    #add 3 layers created in get_ll_layers to end of model.\n",
    "    #copy weights from 3 layers just trained to last three layers in vgg16 model.\n",
    "    ll_layers = get_ll_layers()\n",
    "    ll_model = Sequential(ll_layers)\n",
    "    ll_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    ll_model.optimizer.lr=1e-5\n",
    "    history = ll_model.fit(ll_feat, trn_labels, validation_data=(ll_val_feat, val_labels), nb_epoch=12)\n",
    "    print (\"train_last_layer:i:\", i, \", ll_model.optimizer.lr:\", ll_model.optimizer.lr )\n",
    "    plot_history(history)\n",
    "    \n",
    "    ll_model.optimizer.lr=1e-7\n",
    "    ll_model.fit(ll_feat, trn_labels, validation_data=(ll_val_feat, val_labels), nb_epoch=1)\n",
    "    #nb: cannot show history with only one epoch.\n",
    "    print (\"ll_model.optimizer.lr:\", ll_model.optimizer.lr)\n",
    "    ll_model.save_weights(MODEL_PATH+'ll_bn' + s_or_p + i + '.h5')\n",
    "\n",
    "    #create new vgg16 model & pop last 3 layers.\n",
    "    vgg = Vgg16()\n",
    "    model = vgg.model\n",
    "    print(\"train_last_layer, model just created from Vgg16(), # layers = \", len(model.layers))\n",
    "    model.pop(); model.pop(); model.pop()\n",
    "    #\n",
    "    for layer in model.layers: layer.trainable=False\n",
    "    #set all layers to non trainable\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    #create three layers ()\n",
    "    ll_layers = get_ll_layers()\n",
    "    #get_ll_layers:create 3 layers, BatchNormalization + Dropout + Dense, add these layers to model.\n",
    "    for layer in ll_layers: model.add(layer)\n",
    "    #copy the weights from the above trained ll_model to the just added  last 3 layers in model.\n",
    "    for l1,l2 in zip(ll_model.layers, model.layers[-3:]):\n",
    "        l2.set_weights(l1.get_weights())\n",
    "    \n",
    "    #compile model so it is ready for use.\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.save_weights(MODEL_PATH+'bn' + s_or_p + i + '.h5')\n",
    "    print (\"@ end of train_last_layer, # layers = \", len(model.layers))\n",
    "    showLayersInfo(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model(model):\n",
    "    #split model into 2 sets of layers. \n",
    "    #conv_layers = start up to & including the last Convolution2D\n",
    "    #fc_layers   = rest of the model\n",
    "    #returns model, list of layers, int position of last Convolution2D layer. \n",
    "    \n",
    "    layers = model.layers\n",
    "    \n",
    "    #last_conv_idx = index of last Convolution2D layer\n",
    "    last_conv_idx = [index for index,layer in enumerate(layers) \n",
    "                         if type(layer) is Convolution2D][-1]\n",
    "\n",
    "    conv_layers = layers[:last_conv_idx+1]\n",
    "    conv_model = Sequential(conv_layers)\n",
    "    fc_layers = layers[last_conv_idx+1:]\n",
    "    return conv_model, fc_layers, last_conv_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fc_layers(p, in_shape):\n",
    "    #get_fc_layers creates 9 layers, with nominated input shape, nominated dropout rate\n",
    "    #previously dropped two layers to prevent model failing\n",
    "    #MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout, Dense, BatchNormalization, Dropout, Dense\n",
    "    #NB: last layer = Dense - must have 10 classes to suit this problem\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=in_shape),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        #BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        #Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(10, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dense_layers(i, model):\n",
    "    #nb: i is used in the filename to save weights.\n",
    "    \n",
    "    print (\"start: train_dense_layers: i:\", i)\n",
    "    print (\"len(model.layers):\", len(model.layers))\n",
    "    #split model about last Convolutional2D layer\n",
    "    conv_model, fc_layers, last_conv_idx = get_conv_model(model)\n",
    "    #conv_model = Sqeuential(conv_layers) = list of layers, from start up to & including the last Convolution2D layer.\n",
    "    #fc_layers   = rest of the model       \n",
    "    \n",
    "    #shape of last Convolution2D layer output.\n",
    "    conv_shape = conv_model.output_shape[1:]\n",
    "    \n",
    "    ##get_fc_layers creates 9 layers, with nominated input shape, nominated dropout rate\n",
    "    #conv_shape ensures input shape from conv_model can be accepted.\n",
    "    fc_model = Sequential(get_fc_layers(0.5, conv_shape))\n",
    "    #MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout, Dense, BatchNormalization, Dropout, Dense\n",
    "\n",
    "    print (\"train_dense_layers: showLayersInfo(fc_model):-----------START------------------------\")\n",
    "    showLayersInfo(fc_model)\n",
    "    print (\"train_dense_layers: showLayersInfo(Sequential(fc_layers)):-----------START-----------\")\n",
    "    showLayersInfo(Sequential(fc_layers))\n",
    "    print (\"-----------------------END-----------------------------------------------------------\")\n",
    "    print (\"len(fc_model.layers):\", len(fc_model.layers))#9 layers - as from def get_fc_layers\n",
    "    print (\"len(fc_layers):\", len(fc_layers))            #7 layers - layers split from vgg16 after last Convolutional2D layer\n",
    "    #copy weights from layers in fc_layers to the newly created fc_model. \n",
    "    count = 0\n",
    "    for l1,l2 in zip(fc_model.layers, fc_layers): \n",
    "        print (\"count:\", count)\n",
    "        print(\"l1:\", l1)\n",
    "        print(\"l2:\", l2)\n",
    "        weights = l2.get_weights()\n",
    "        print (\"l1.get_weights():\", len(l1.get_weights()))\n",
    "        print (\"l2.get_weights():\", len(l2.get_weights()))\n",
    "        l1.set_weights(weights)\n",
    "        count += 1\n",
    "    \n",
    "    print (\"marker AA\")\n",
    "    fc_model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    fc_model.fit(trn_features, trn_labels, nb_epoch=2, \n",
    "         batch_size=batch_size, validation_data=(val_features, val_labels))\n",
    "    print (\"marker BB\")\n",
    "\n",
    "    #setup data augmentation.\n",
    "    gen = image.ImageDataGenerator(rotation_range=10, \n",
    "                                   width_shift_range=0.05, \n",
    "                                   #width_zoom_range=0.05, #error - why????\n",
    "                                   zoom_range=0.05, \n",
    "                                   channel_shift_range=10, \n",
    "                                   height_shift_range=0.05, \n",
    "                                   shear_range=0.05, \n",
    "                                   horizontal_flip=True)\n",
    "    print (\"marker CC\")\n",
    "\n",
    "    batches = gen.flow(trn, trn_labels, batch_size=batch_size)\n",
    "    \n",
    "    print (\"marker DD\")\n",
    "\n",
    "    val_batches = image.ImageDataGenerator().flow(val, \n",
    "                                                  val_labels, \n",
    "                                                  shuffle=False, \n",
    "                                                  batch_size=batch_size)\n",
    "    \n",
    "    print (\"type(val_batches):\", type(val_batches), \"val_batches.n:\", val_batches.n)\n",
    "\n",
    "    print (\"len(conv_model.layers):\", len(conv_model.layers))\n",
    "    \n",
    "    #set all layers in conv_model set to non trainable\n",
    "    for layer in conv_model.layers: \n",
    "        layer.trainable = False\n",
    "\n",
    "    print (\"marker EE-all layers in conv_model set to non trainable\")\n",
    "    ##get_fc_layers creates 9 layers, with nominated input shape, nominated dropout rate\n",
    "    #MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout, Dense, BatchNormalization, Dropout, Dense\n",
    "    #conv_shape ensures input shape from conv_model can be accepted.\n",
    "    #add all layers to end of conv_model\n",
    "    for layer in get_fc_layers(0.5, conv_shape): \n",
    "        conv_model.add(layer)\n",
    "    print (\"showLayersInfo(conv_model): after 1. setting layers to non trainable & 2. adding get_fc_layers to conv_model\")\n",
    "    showLayersInfo(conv_model)\n",
    "        \n",
    "    \n",
    "    #copy weights from fc_model.layers to the layers after last_conv_idx in conv_model.\n",
    "    #nb: weights in fc_model were trained \n",
    "    for l1,l2 in zip(conv_model.layers[last_conv_idx+1:], fc_model.layers): \n",
    "        l1.set_weights(l2.get_weights())\n",
    "    print (\"marker FF-copied weights from fc_model.layers to the layers after last_conv_idx in conv_model.\")\n",
    "    \n",
    "    conv_model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    conv_model.save_weights(MODEL_PATH+'no_dropout_bn' + s_or_p + i + '.h5')\n",
    "    \n",
    "    \n",
    "    conv_model.fit_generator(batches, \n",
    "                             samples_per_epoch=batches.n, \n",
    "                             nb_epoch=1, \n",
    "                             validation_data=val_batches, \n",
    "                             nb_val_samples=val_batches.n)\n",
    "    \n",
    "    #now make more of the models trainable.\n",
    "    for layer in conv_model.layers[16:]: layer.trainable = True\n",
    "\n",
    "    print (\"showLayersInfo(conv_model): after 1. copying weights to conv_model from fc_model.layers.\")\n",
    "    print (\"2. fitting, setting layers 16: to trainable.\")\n",
    "    \n",
    "    showLayersInfo(conv_model)\n",
    "\n",
    "\n",
    "    history = conv_model.fit_generator(batches, \n",
    "                             samples_per_epoch=batches.n, \n",
    "                             nb_epoch=8, \n",
    "                             validation_data=val_batches, \n",
    "                             nb_val_samples=val_batches.n)\n",
    "\n",
    "    print (\"history = conv_model.fit_generator(blah....), conv_model.optimizer.lr:\", conv_model.optimizer.lr)\n",
    "    plot_history(history)\n",
    "    \n",
    "    conv_model.optimizer.lr = 1e-7\n",
    "    history = conv_model.fit_generator(batches, \n",
    "                             samples_per_epoch=batches.n, \n",
    "                             nb_epoch=10, \n",
    "                             validation_data=val_batches, \n",
    "                             nb_val_samples=val_batches.n)\n",
    "\n",
    "    print (\"history = conv_model.fit_generator(blah....), conv_model.optimizer.lr:\", conv_model.optimizer.lr)\n",
    "    plot_history(history)\n",
    "    \n",
    "    conv_model.save_weights(MODEL_PATH + s_or_p + 'aug' + i + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.models.Sequential"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(conv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "Train on 3122 samples, validate on 1369 samples\n",
      "Epoch 1/12\n",
      "3122/3122 [==============================] - 0s - loss: 3.2560 - acc: 0.1105 - val_loss: 2.8118 - val_acc: 0.1052\n",
      "Epoch 2/12\n",
      "3122/3122 [==============================] - 0s - loss: 3.2008 - acc: 0.1111 - val_loss: 2.7410 - val_acc: 0.0935\n",
      "Epoch 3/12\n",
      "3122/3122 [==============================] - 0s - loss: 3.1059 - acc: 0.1294 - val_loss: 2.7898 - val_acc: 0.0869\n",
      "Epoch 4/12\n",
      "3122/3122 [==============================] - 0s - loss: 3.0121 - acc: 0.1288 - val_loss: 2.8508 - val_acc: 0.0825\n",
      "Epoch 5/12\n",
      "3122/3122 [==============================] - 0s - loss: 2.9138 - acc: 0.1416 - val_loss: 2.9058 - val_acc: 0.0760\n",
      "Epoch 6/12\n",
      "3122/3122 [==============================] - 0s - loss: 2.8805 - acc: 0.1477 - val_loss: 2.9530 - val_acc: 0.0730\n",
      "Epoch 7/12\n",
      "3122/3122 [==============================] - 0s - loss: 2.7638 - acc: 0.1694 - val_loss: 2.9879 - val_acc: 0.0679\n",
      "Epoch 8/12\n",
      "3122/3122 [==============================] - 0s - loss: 2.6875 - acc: 0.1835 - val_loss: 3.0150 - val_acc: 0.0643\n",
      "Epoch 9/12\n",
      "3122/3122 [==============================] - 0s - loss: 2.6311 - acc: 0.1992 - val_loss: 3.0420 - val_acc: 0.0592\n",
      "Epoch 10/12\n",
      "3122/3122 [==============================] - 0s - loss: 2.5944 - acc: 0.1989 - val_loss: 3.0642 - val_acc: 0.0599\n",
      "Epoch 11/12\n",
      "3122/3122 [==============================] - 0s - loss: 2.4853 - acc: 0.2098 - val_loss: 3.0873 - val_acc: 0.0562\n",
      "Epoch 12/12\n",
      "3122/3122 [==============================] - 0s - loss: 2.4319 - acc: 0.2274 - val_loss: 3.1135 - val_acc: 0.0548\n",
      "train_last_layer:i: 0 , ll_model.optimizer.lr: 1e-05\n",
      "['acc', 'loss', 'val_acc', 'val_loss']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f232661f790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd8VGXa//HPld5JgySUEHqvCU1w\nBQHF3lBQwC6wdtdn1d11110f91ld/anrqkhTxIIi9gaKUlRqaKH3FiAkIaT35P79cYaAMUACmZyZ\nyfV+vXgxmXNm5pqI8527nPsWYwxKKaUUgJfdBSillHIdGgpKKaWqaCgopZSqoqGglFKqioaCUkqp\nKhoKSimlqmgoKFVLIjJLRJ6p5bn7RGTE+T6PUg1NQ0EppVQVDQWllFJVNBSUR3F02/xRRFJEpEBE\nZopIjIh8KyJ5IrJQRCJOOf9qEdksItkislhEupxyrI+IrHU87kMgoNprXSki6x2PXSYiPc+x5ntE\nZJeIZInIFyLS3HG/iMhLIpIuIrkislFEujuOXS4iWxy1HRKR/zmnX5hS1WgoKE90AzAS6AhcBXwL\n/BloivVv/kEAEekIzAEedhz7BvhSRPxExA/4DHgHiAQ+cjwvjsf2Ad4EJgFRwFTgCxHxr0uhInIx\n8C/gJiAO2A984Dh8CfA7x/to4jjnmOPYTGCSMSYU6A78WJfXVep0NBSUJ/qvMeaoMeYQ8BOw0hiz\nzhhTDHwK9HGcNwb42hjzvTGmDHgBCAQuAAYCvsDLxpgyY8w8YPUprzERmGqMWWmMqTDGvA2UOB5X\nF+OAN40xa40xJcCfgEEikgCUAaFAZ0CMMVuNMUccjysDuopImDHmuDFmbR1fV6kaaSgoT3T0lNtF\nNfwc4rjdHOubOQDGmErgINDCceyQ+fWKkftPud0aeNTRdZQtItlAK8fj6qJ6DflYrYEWxpgfgVeB\n14B0EZkmImGOU28ALgf2i8gSERlUx9dVqkYaCqoxO4z14Q5YffhYH+yHgCNAC8d9J8Sfcvsg8E9j\nTPgpf4KMMXPOs4ZgrO6oQwDGmFeMMYlAV6xupD867l9tjLkGaIbVzTW3jq+rVI00FFRjNhe4QkSG\ni4gv8ChWF9AyYDlQDjwoIr4icj3Q/5THTgcmi8gAx4BwsIhcISKhdaxhDnCHiPR2jEf8H1Z31z4R\n6ed4fl+gACgGKh1jHuNEpImj2ysXqDyP34NSVTQUVKNljNkOjAf+C2RiDUpfZYwpNcaUAtcDtwNZ\nWOMPn5zy2GTgHqzunePALse5da1hIfBX4GOs1kk7YKzjcBhW+BzH6mI6BjzvODYB2CciucBkrLEJ\npc6b6CY7SimlTtCWglJKqSoaCkoppapoKCillKqioaCUUqqKj90F1FV0dLRJSEiwuwyllHIra9as\nyTTGND3beW4XCgkJCSQnJ9tdhlJKuRUR2X/2s7T7SCml1Ck0FJRSSlXRUFBKKVXF7cYUalJWVkZq\nairFxcV2l+LyAgICaNmyJb6+vnaXopRyQR4RCqmpqYSGhpKQkMCvF7VUpzLGcOzYMVJTU2nTpo3d\n5SilXJBHdB8VFxcTFRWlgXAWIkJUVJS2qJRSp+URoQBoINSS/p6UUmfiMaFwNmUVlRzJLqKsQped\nV0qp02k0oVBQUk5mfinb0vJIPV5ISXlFvT13dnY2r7/+ep0fd/nll5OdnV1vdSil1PlqNKEQHuRH\nx9gQIoJ8OV5Yxo60fA5mFVJcdv7hcLpQKC8vP+PjvvnmG8LDw8/79ZVSqr54xOyj2vL38aZlRBAx\nYZVk5JWQVVDK8cJSmgT60jTUnyC/c/t1PPHEE+zevZvevXvj6+tLQEAAERERbNu2jR07dnDttddy\n8OBBiouLeeihh5g4cSJwcsmO/Px8LrvsMoYMGcKyZcto0aIFn3/+OYGBgfX59pVS6qw8LhT+8eVm\nthzOrdW5BmusobyiEmPA20vw9fHCu9pgbNfmYTx1VbfTPs+zzz7Lpk2bWL9+PYsXL+aKK65g06ZN\nVdM+33zzTSIjIykqKqJfv37ccMMNREVF/eo5du7cyZw5c5g+fTo33XQTH3/8MePHj6/bm1dKqfPk\ncaFQFwL4eXvh5+1FWUUlZRWG4tIKKxy8vfD2OreZOv379//VdQCvvPIKn376KQAHDx5k586dvwmF\nNm3a0Lt3bwASExPZt2/fOb22UkqdD48LhTN9oz+bykpDVmEpGXkllFVUEujrTdNQf5oE1u3q3+Dg\n4KrbixcvZuHChSxfvpygoCCGDh1a43UC/v7+Vbe9vb0pKio65/ehlFLnyuNC4Xx4eQnRIf5EBvuR\nXVhGRl4JB7IK8fexwiE8yBevGub5h4aGkpeXV+Nz5uTkEBERQVBQENu2bWPFihXOfhtKKXXONBRq\n4CVCZLAfEUG+5BSVkZ5XQurxQtJzvYgO9ScyyA+vU7qWoqKiGDx4MN27dycwMJCYmJiqY6NGjeKN\nN96gS5cudOrUiYEDB9rxlpRSqlbEGGN3DXWSlJRkqm+ys3XrVrp06eK01zTGkFdcTnpeCYWl5fh4\neREd6kdUsP85jzvYydm/L6WU6xGRNcaYpLOdpy2FWhARwgJ9CQ3woaCkgvS8YtJyisnIKyEqxJ/o\nYD98vBvNJR9KKQ+moVAHIkJIgA8hASEUlpaTnltCem4xmXklRAX7ER3qj6+Gg1LKjTktFEQkAFgK\n+DteZ54x5qlq5/wBuBsoBzKAO40xtdpH1G5Bfj4kRPtQXFZBel4JmfklZBaUEhlkXQjn5+Ntd4lK\nKVVnzvxaWwJcbIzpBfQGRolI9VHWdUCSMaYnMA/4txPrcYoAX2/iI4PoGBtKRJAvWYVlbK/HJTSU\nUqohOS0UjCXf8aOv44+pds4iY0yh48cVQEtn1eNsJ5bQ6BwTSlSIHzlFZexKzye7sNTu0pRSqtac\n2gEuIt4ish5IB743xqw8w+l3Ad+e5nkmikiyiCRnZGQ4o9R64+vjRfPwQDrFhhLg682BrELScotx\nt1leSqnGyamhYIypMMb0xmoB9BeR7jWdJyLjgSTg+dM8zzRjTJIxJqlp06bOK7ge+Xp70bZpMBFB\nfqTnFnMgq5CKSisYQkJCADh8+DCjR4+u8fFDhw6l+tTb6l5++WUKCwvPeI5SStVFg0yVMcZkA4uA\nUdWPicgI4C/A1caYkoaop6F4idAyIpC4JoHkFpWxOyOf0lP2cWjevDnz5s075+fXUFBK1TenhYKI\nNBWRcMftQGAksK3aOX2AqViBkO6sWpztiSee4LXXXqv6+e9//zvPPPMMw4cPJzExkYsvSGLz8h8o\nq6hkV3pB1Xn79u2je3er8VRUVMTYsWPp0qUL11133a/WPvr9739PUlIS3bp146mnrAlcr7zyCocP\nH2bYsGEMGzYMgO+++45BgwbRt29fbrzxRvLz81FKqbpw5nUKccDbIuKNFT5zjTFficjTQLIx5gus\n7qIQ4CPH3sEHjDFXn9erfvsEpG08v8qri+0Blz172sNjxozh4Ycf5r777gNg7ty5LFiwgAcffJCw\nsDAyMzMZOHAgm7ZsY39WEZUGjhX8ulE0ZcoUgoKC2Lp1KykpKfTt27fq2D//+U8iIyOpqKhg+PDh\npKSk8OCDD/Liiy+yaNEioqOjyczM5JlnnmHhwoUEBwfz3HPP8eKLL/K3v/2tfn8XSimP5rRQMMak\nAH1quP9vp9we4azXb0h9+vQhPT2dw4cPk5GRQUREBLGxsTzyyCMsXboULy8vDh06RHZWJu2aNUOA\nQ8eLKMw9uVrq0qVLefDBBwHo2bMnPXv2rDo2d+5cpk2bRnl5OUeOHGHLli2/Og6wYsUKtmzZwuDB\ngwEoLS1l0KBBzn/zSimP4nlXNJ/hG70z3XjjjcybN4+0tDTGjBnDe++9R0ZGBmvWrMHX15eEhASK\ni4vx8fJCBKJD/NlwsJRSxyY/p7N3715eeOEFVq9eTUREBLfffnuNS28bYxg5ciRz5sxx5ttUSnk4\nXZOhnowZM4YPPviAefPmceONN5KTk0OzZs3w9fVl0aJF7N//6wu1m4cHEtckgEoDuzLyGTR4CO+/\n/z4AmzZtIiUlBYDc3FyCg4Np0qQJR48e5dtvT87aPXXJ7oEDB/LLL7+wa9cuAAoKCtixY0dDvHWl\nlAfxvJaCTbp160ZeXh4tWrQgLi6OcePGcdVVV9GjRw+SkpLo3Lnzbx4THuSHn7cXlZUw4rrxrPrT\ng3Tp0oUuXbqQmJgIQK9evejTpw+dO3emVatWVd1DABMnTmTUqFE0b96cRYsWMWvWLG6++WZKSqzx\nimeeeYaOHTs2zC9AKeURdOlsF1BaXsn+YwUUlVUQ2ySApiH+SA2b+dQXd/99KaXqrrZLZ2v3kQvw\n8/GiXdMQmgT6kpZTTOrxIior3SuslVKeQUPBRXh5CfGRQcSEBXC8sJQ9mQWUnWEAWimlnMFjQsHd\nusFqIiLEhAXQOiqY4rIKdqXnU1haXq+v4Qm/J6WU83hEKAQEBHDs2DGP+cBrEuhLu6YhCLA7o6De\nVlo1xnDs2DECAgLq5fmUUp7HI2YftWzZktTUVFx9BdW6qqg0HC8oJW1/JaEBPoQF+HK+488BAQG0\nbOm2K5QrpZzMI0LB19eXNm3a2F2GU5SWV/LUF5uZs+oAI7o046UxvQkN8LW7LKWUh/KI7iNP5ufj\nxf9d152nr+nGou0ZXP/6MvYfKzj7A5VS6hxoKLgBEeHWQQnMvrM/6XklXPPaLyzblWl3WUopD6Sh\n4EYGt4/mi/sHEx3iz4Q3V/HO8n0eM7iulHINGgpupnVUMJ/eewEXdWzKXz/fzF8+20RpuV7PoJRH\nK8qGnQvh6Ganv5RHDDQ3NqEBvky/NYnnF2znjSW72Z2ez5TxiUQG+9ldmlLqfBkDx3bDwZWOP6sg\nY6t1rP8kuPzfTn15DQU35e0lPHFZZzrHhvLYxylc/erPTL81iS5xYXaXppSqi7IiOLzuZAAcXAmF\nx6xjAU2gZX/ofgO06g8tEp1ejoaCm7u2TwsSooOZODuZG6Ys48WbejGqe5zdZSmlTif3yCmtgJVw\nZANUOlYuiGoPHUdZAdBqIER3BK+G7eX3iFVSFRzNLWbSO2tYfzCbh4Z34KHhHfDyct5Kq0qpWqgo\nh6ObTrYADq6CnAPWMZ8A65t/q/7QaoDVIgiOcloptV0lVVsKHiImLIAPJg7kL59u4j8/7GTrkVxe\nHNObEH/9T6xUgyk6DqnJJ1sBqWugzHFdUWic9eE/8PcQPwBieoCP640D6ieGBwnw9eaFG3vStXkY\n//x6C9e//gvTb02idVSw3aUp5Xl+NSC8wjEgvM06Jt4Q2wP6jD/ZEmjSkvNep6YBaPeRh/p5Zyb3\nvb8WEXjtlr4Mbh9td0lKuS9j4PheOLzeGhQ+st4aCyjOsY4HhDs+/B1jAS36gp9rfRmrbfeRhoIH\n23+sgHtmJ7M7o4C/XN6FOwYnOHVHN6U8gjGQtcf64D+8/rcB4O0HMd0grjc07wPxAyGqQ4MPCNeV\njikoWkcF88m9g3nkw/U8/dUWth7J5ZnruuPv4213aUq5hpoC4PAGKKkWAN2uh+aOEGjaxSXHAuqL\nhoKHC/H3Yer4RF7+YSev/LCTXRn5TB2fSLMw3VNBNTInAuBE98/h9XAkpVoAdIceNzhaAb09PgBq\not1Hjcg3G4/w6NwNhAX6MHVCEr1bhdtdklLOUVnpGAM4XQD4Wy2A5r0bTQBo95H6jct7xNEmOph7\nZidz09TlPHt9D67vqxvuKDdXWWHNAkpLOSUANkBJrnX8RAD0uMHq/onrDc26gLfuS1ITDYVGpktc\nGF/cP4R731vDH+ZuYOuRXB4f1Rkfb9ceJFMKgPJSax2gIynWB39aCqRtOnktgLc/xHaHHjeebAVo\nANSJhkIjFBnsxzt3DeCZr7Yw/ae9bEvL49Wb+9IkSP/HUS6ktMBaFfTIhpN/0rdCZZl13C/Uuhag\n760Q1xPielnLQmgAnBcdU2jkPlh1gL9+vokW4YFMvzWJDjGhdpekGqOi47/+9n8kBY7tBONYFj4o\nyvrQj3V8+Mf1gog2Lj8N1JXomIKqlbH942nfLITJ767luteX8fKY3ozoGmN3WcqT5aU5vvk7xgDS\nUiD7wMnjYS2tb/7drz8ZAmHN3eJqYE+gLQUFwOHsIia9s4ZNh3N4dGRH7hvWXi90U+fHGOvD/sTF\nXydaAgXpJ8+JbOf45u/48I/t5dRF4RozbSmoOmkeHshHkwfx+McpvPDdDrYeyeP5G3sS5Kf/RFQt\nVVZYK4IeWAEHllt/5x2xjom3NeDbfsTJEIjpDgG6/4er0f/jVZUAX29eHtObrnFhPDt/G3syC5h+\nayItI4LsLk25otICa0XQEyGQmgyledaxsJbQerC1BESLRGjWFXz1gkl3oN1HqkaLt6fzwJx1+Hp7\n8fq4vgxsq036Ri8/3REAjhA4sgFMBSDWdQDxAyF+kLUiaHgru6tV1eiCeOq87cnI5+7ZyRw4VshT\nV3dj/IB4HWdoLIyBY7tOdgMdWG4tEQGOzWGSrD0B4gdBy34QqFfHuzodU1DnrW3TED67bzAPzVnH\nXz/bxJbDufzj6m74+eg0QI9TXmp98z+w3Nof4MDyk/sEB0VZH/6Jd1h/x/Xy6OUgGjsNBXVGYQG+\nzLitH//vu+28vng3u9LzeH1cIk1D/e0uTZ2P4hw4uPpkS+BQMpQXW8ci21n7BJ/oDopqr9NBGxHt\nPlK19sWGwzw2bwORQX5MuzWJ7i2a2F2Sqq2cQ6d0Ba2wZglhwMvHuhYgfpAjBAZCSDO7q1VOYPuY\ngogEAEsBf6wWyTxjzFPVzvEHZgOJwDFgjDFm35meV0PBXpsO5TBxdjJZhaW8eFNvLu8RZ3dJqrrK\nSsjcDvuXnQyBE5vF+4VYYwCtLzg5M8jFdghTzuEKoSBAsDEmX0R8gZ+Bh4wxK045516gpzFmsoiM\nBa4zxow50/NqKNgvM7+EibOTWXsgm8dGdeL3F7XTAWg7lZdYS0Sf2hIozraOhcQ4WgGDoPUgaNYN\nvLXXuDGyfaDZWGmT7/jR1/GnegJdA/zdcXse8KqIiHG3Pq1GJjrEn/fvGcgf56Xw7/nb2ZtRwD+v\n66ED0A2lKNvaJL5qPGANVJRYx6I7QterId7REohI0PEAVSdO/cogIt7AGqA98JoxZmW1U1oABwGM\nMeUikgNEAZnOrEudvwBfb14Z25s20cG88sNODh4v5I3xiYQH6ayUepeTenJa6P7lkL6FqvGAuN7Q\n/x6rO6jVAAiOtrta5eacGgrGmAqgt4iEA5+KSHdjzKa6Po+ITAQmAsTHx9dzlepciQh/GNmRNtFB\nPD5vI9e/vow3b+9HQrT2UZ+zykrI2OZoBThaAjkHrWN+IdCqP3S71uoOapEIfnq1uapfDTb7SET+\nBhQaY1445b4FwN+NMctFxAdIA5qeqftIxxRc06q9WUx6JxkDTJuQRP82kXaX5B4qyqzunxODwgdX\nWNNFQccDVL2yfUxBRJoCZcaYbBEJBEYCz1U77QvgNmA5MBr4UccT3FP/NpF8eu9g7py1mvEzVvLc\n6B5c10e3+qxRUTbsWgjbv4Vd358MgeiO0PUaHQ9QtnLm14444G3HuIIXMNcY85WIPA0kG2O+AGYC\n74jILiALGOvEepSTJUQH8+m9g5n87hoe+XADezMKeGRkR52ZBNYSEdvnw45vrVZBZTkERUPnK6Hj\npdbicToeoFyAXrym6l1peSVPfraRucmpXNWrOc+P7kmAr7fdZTWsygpr1dDt38CO+dY4AUDTztDp\nMuh4GbRMAq9G9ntRtrG9+0g1Xn4+Xjx3Q0/aRIfw3PxtHDpeyLRbk4gO8fClMUryYfePVgjsmG+t\nHeTlY80MSrzdWjoiso3dVSp1RhoKyilEhN8PbUfrqCAe+XA9173+C2/e1s/z9oDOSbXGBnbMh71L\noaIUAppAh0usFkG74bqCqHIrGgrKqS7vEUfz8EDufjuZ66csY8q4RIZ0cOO+88pKa3vJ7d9a4wNp\nG637I9tC/4knF5Lz9rW3TqXOkY4pqAZxKLuIu2atZmd6Pv97TXduGeBG15uUFcGeJY7xgQWQnwbi\nZV0sdmJ8ILqDzhRSLk3HFJRLaeHYA/qBOev486cb2ZuZzxOXdcHby0U/SPOOnhwb2L0IyovALxTa\nX2yFQIdLdIN55ZE0FFSDCQ3wZcatSTz91Ram/7SXfccK+c/Y3gT5ucg/w7Ii2PwprJllbTQD0CQe\n+k6wuoUShoCPhw+Wq0bPRf5vVI2Fj7cXT1/TnbbRwTz91RZumrqcGbf2I7aJjZu6Z+6C5Ddh/XvW\n6qLRnWDYk1bXUEw37RZSjYqGgrLF7YPbEB8VxAPvr+Pa135h5u1JdGvegJv2VJRZYwSrZ8LeJeDl\nC12ugn53WReSaRCoRkoHmpWtthzO5a63V5NTVMYrY/swomuMc18w55DVPbR2tjVg3KSVdQ1B31t1\nxzHl0WzfZMdZNBQ8T3puMXe9ncymwzk8eUVX7hycUL9LY1RWwp4fYfWb1jRSY6DDSEi6y/pbrypW\njYDOPlJuo1lYAB9OGsgjH67nf7/awr7MAp66qis+3ue5aU/BMVj3Dqx5C47vg+CmMPhhq2UQ0bo+\nSlfK42goKJcQ5OfDlHGJPLdgG1OX7GF/ViGv3tKHsIA6XgRmjDVzaPVM2PKZdYVx68Fw8V+hy9Xg\no5sAKXUmGgrKZXh5CX+6rAttooJ58rNNjJ6yjJm39aNVZC02kinOhZQPIfktSN8M/mGQeAck3QHN\nuji/eKU8hIaCcjlj+8fTKjKIye+u4brXf2H6rUn0iY+o+eS0jVarYONHUJoPcb3gqlegx2jw0x3g\nlKorHWhWLmtXeh53zkrmaG4xT17ZlSt7xBER7AdlxVbX0OqZkLoKfAKg+2hIuhNa9NXppErVQGcf\nKY9wLL+Eye+uYfW+47SRNB4O/5lLy34goDwHE9UBSboTet8MgadpSSilAJ19pDxEVLAfHw7NIX/p\nFMIO/0R5kTcLKhJ5t2Iku3P6MPRQM4aFFDO4Q1ndB6WVUr+hoaBcU2WFtQ7Rzy/hdXQTYWEtYNiT\n+PSdQH8iKNqRwaLt6Xy7KY25yan4eAlJCREM69SMYZ2b0aFZiG4DqtQ50O4j5VrKS2DDB/DLy9a+\nxtGd4MI/QPcbatyjoLyikrUHslm0PZ1F29LZlpYHWKuyDu3UlGGdmnFB+yjXWXRPKZvomIJyL6UF\nsOZtWPZfyDsMcb3hd/8Dna4Ar9pfxHYkp4jF2zNYtC2dX3ZlUlBagZ+3FwPaRla1ItpE66wk1fho\nKCj3UHQcVs2AFa9DURYkXGi1DNoOO+9ZRCXlFSTvO86ibeks3pHBrvR8ABKighjqCIgBbSIJ8NVl\nLpTn01BQri0/HZa/Zk0rLc2z9isY8geIH+C0lzyYVcji7eks2p7Bst2ZFJdVEuDrxeB20Qzt3Iyh\nHZvW7kI5pdyQhoJyTdkH4JdXrDWJKkqh23Uw5BGI7dGgZRSXVbBizzEWb8/gx23pHMgqBKBDsxCG\ndW7G7Rck0Dw8sEFrUsqZNBSUa8nYAT+/BBvnAmJdWzD4YYhqZ3dlGGPYm1nAou0ZLN6ezso9WTQN\n9eeDiQO15aA8hoaCcg2H18FPL8LWL60rj5PugEH3Q5MWdld2WpsO5TBuxkpC/H34cNJAWkZoMCj3\nV9tQOM+1iZWqgTGw7xd453qYNhT2LLFmEj2yCUb9y6UDAaB7iya8e9cA8orLuHn6Cg5lF9ldklIN\nplahICIPiUiYWGaKyFoRucTZxSk3Ywzs+A7eHAWzLoe0FBjxdysMLn4SgqPtrrDWerRswrt3DyC7\nsIybp63gSI4Gg2ocattSuNMYkwtcAkQAE4BnnVaVci+VFbDpE3jjQnj/Rsg9BJe/AA9vtAaRA8Ls\nrvCc9GwZzjt3DeB4QSk3T1tBWk6x3SUp5XS1DYUTE8YvB94xxmw+5T7VWJWXwtp34NV+MO8OKC+G\na6fAg+ug/z3g6/6zd3q3Cuftu/qTmV/KLdNXkJ6rwaA8W21DYY2IfIcVCgtEJBSodF5ZyqWVFcGK\nN+CV3vDF/eAfAjfNhvtWQu9balyOwp31jY/g7Tv7cTS3mLHTV5Cep8GgPFetZh+JiBfQG9hjjMkW\nkUigpTEmxdkFVqezj2xUUQ7r34XFz1lLUbQebF193G54o9jDYPW+LG57cxXNwwOZc89Amob6212S\nUrVW37OPBgHbHYEwHngSyDmfApUbqay0xgxe6w9fPgRNWsJtX8Ed30D7EY0iEAD6JUTy1u39OHS8\niHEzVpCZX2J3SUrVu9qGwhSgUER6AY8Cu4HZTqtKuQZjYOdCmHaRNWbg4w9j58Bd30GbC+2uzhYD\n2kbx5u39OJBVyPgZKzmmwaA8TG1DodxY/UzXAK8aY14DQp1XlrLdwVUw60p47wYozobrpsHkn6Hz\n5Y2mZXA6g9pFMfO2fuzNLGDcjJVkFZTaXZJS9aa2oZAnIn/Cmor6tWOMwbNGE5Xl6BaYczPMHAmZ\nO6yppfevgV5jwEtXEz1hcPtoZtyWxJ7MAsbPWEl2oQaD8gy1DYUxQAnW9QppQEvgeadVpRpe1l74\nZCJMucC6Gvniv8JD662ppT5+dlfnki7s0JTptyaxKyOfcTNWklNYZndJSp23Wq99JCIxQD/Hj6uM\nMelOq+oMdPZRPcs7CkufhzWzrJbAgEnWQnVBkXZX5jYWbU9n0uw1dIoN5d27B9AkUBvRyvXU6+wj\nEbkJWAXcCNwErBSR0edXorJVUTYs/Id1rUHym9BnvHXR2cinNRDqaFinZkwZ35dtabncOnMlucXa\nYlDuq7bXKWwARp5oHYhIU2ChMaaXk+v7jfNqKRRm6QdeaSGsmgo/v2wNIHcfDcP+7BJLWLu777cc\n5d731tC9RRNm39mf0ABtMSjXUd/XKXhV6y46drbHikgrEVkkIltEZLOIPFTDOU1E5EsR2eA4545a\n1lN3OxbAyz1g+evWRViNTUWZtcvZK31g4d+hVX+Y9BOMnqmBUE9Gdo3h1Vv6sjE1h9vfWk1+SSP8\nd6bcXm1DYb6ILBCR20XkduCm00JxAAAWaUlEQVRr4JuzPKYceNQY0xUYCNwnIl2rnXMfsMXR4hgK\n/D8Rcc6oZnQHiB8IC/4E04fCwdVOeRmXU1kJKR9Z6xN9/QeISIA7voVxH0FcT7ur8ziXdovlvzf3\nYf3BbO54axUFGgzKzdQqFIwxfwSmAT0df6YZYx4/y2OOGGPWOm7nAVuB6gvpGyBURAQIAbKwwqT+\nRbaFcfPgxllQkGlNufzyIatLyRMZY7WOpv4OPrkb/ILhlrlw53xofYHd1Xm0y3rE8crYPqw9kM0d\ns1ZTWKrBoNxHg+y8JiIJwFKgu2MJ7hP3hwJfAJ2xLoYbY4z5+kzPVS+zj4pzYfG/YOUbEBgJlzwD\nvcZ6zkVZ+5fDD/+AA8utlsGwJ6H7DeCleyo1pC83HOahD9bRv00kb93en0A/vc5D2adetuMUkTys\nb/O/OQQYY8xZF8oXkRBgCfBPY8wn1Y6NBgYDfwDaAd8DvU4NDsd5E4GJAPHx8Yn79+8/28vWzpEU\n+OoROJQMrYfAlS9C007189x2SNsIPzwNO7+DkBi46DHoc6teZ2Cjz9cf4pEP1zOwrXUVtAaDsotL\n7NEsIr7AV8ACY8yLNRz/GnjWGPOT4+cfgSeMMatO95z1fp1CZSWsfRsWPmXNzLngAfjdH8HPTfbl\nNQZSk2HF67D5EwhoYl1nMGCS1WWkbPfpulT+MHcDg9tZV0EH+GowqIZn+x7NjnGCmcDWmgLB4QAw\n3HF+DNAJ2OOsmmrk5WVtJn//GugxGn5+EV4fANvnN2gZdVZWDOvfh+nDYOYI2Pm9tcvZQxus5aw1\nEFzGdX1a8sLoXvyyO5N7ZidTXFZhd0lKnZbTWgoiMgT4CdjIyQ15/gzEAxhj3hCR5sAsIA6rS+pZ\nY8y7Z3pep1/RvO9n+OoPkLkdOl8Jo56F8FbOe726yj4IyTNhzdtQlAXRnaylKHqNBX9do9CVzU0+\nyOMfp3BRx6ZMnZCIv4+2GFTDcYnuI2dokGUuykth+auw5N8gXjD0CRj4e/t2FDMG9i6FVdNgu2Mm\ncKfLrTBoc5HnDJA3Ah+uPsDjH2/k4s7WVdAaDKqhaCjUh+P74dvHYMd8aNYVrnzJutahoZTkQ8oH\nsGo6ZGyzZkol3gZJd0J4fMPVoerV+ysP8OdPNzKiSzNeH5eIn4/OClPOp6FQX4yBbV/Dt49Dbqq1\nRtCIpyE4ynmvmbkLVk+3xgxKciGuF/SfBN2vB99A572uajDvrNjPXz/bxMiuMbx2S18NBuV0tQ0F\nn4Yoxq2JQJcroe1QWPKcNctn2zcw8h/Qe3z9zf2vrLAGi1dNg90/gJcvdLvWCoOWSdpF5GEmDGyN\nMYa/fb6ZB+as5eUxfXS6qnIJ2lKoq6NbrOUiDiyHVgOtaxtiup378xVmwfr3YPUMOL4PQuOs7qG+\nt0FoTL2VrVzTW7/s5R9fbiEhKoh/j+5F/zaNfMFG5TTafeRMlZXWB/n3f4PiHBh0L1z0BPiH1P45\n0jZarYKUj6C8COIvsAaOu1xl34C2ssWy3Zk8/nEKqceLuG1QAo+N6kSQnzbiVf3SUGgIhVlWMKx7\nB8JawmXPWtNYT9fVU1EGW7+0Bo4PLAOfQOh5kxUGsT0atnblUgpKynl+wXZmLdtHfGQQz93Qk0Ht\nnDhupRodDYWGdGCFdW1D+mbocClc/m9rzaET8o5aV00nvwl5RyC8tRUEfcZDYIRtZSvXs3LPMR77\nOIX9xwqZMLA1T1zWmWB/bTWo86eh0NAqyqwF9hb9C0wlXPRHaD3YGivY/BlUlkH7EdB/ovW3lw4q\nqpoVlVbw/ILtvLVsL82bBPLv0T0Z3D7a7rKUm9NQsEtOqjV9ddtX1s/+YdB7HPS7G6Lb21ubcivJ\n+7J4bF4KezILuLl/PH++vLPu5qbOmYaC3Xb/CLlHoOs1dRuAVuoUxWUVvPj9Dmb8tIfYsACevaEn\nv+vY1O6ylBvSUFDKg6w7cJw/zkthV3o+Y5Ja8ZcruxCmrQZVB7avkqqUqj994iP46oEh/H5oOz5a\nc5BLXlzKom3pZ3+gUnWkoaCUmwjw9ebxUZ359N7BhAX6cMes1Tw6dwM5hWV2l6Y8iIaCUm6mV6tw\nvnxgCA9c3J7P1h9i5EtL+H7LUbvLUh5CQ0EpN+Tv482jl3Ti8/sGExnsxz2zk3n4g3UcLyi1uzTl\n5jQUlHJj3Vs04Yv7h/DwiA58lXKEkS8tZf6mNLvLUm5MQ0EpN+fn48XDIzryxf1DiAnzZ/K7a7j/\n/bUcyy+xuzTlhjQUlPIQXZuH8dl9g3l0ZEcWbE7jkpeW8nXKEbvLUm5GQ0EpD+Lr7cUDwzvw5QND\naB4eyH3vr+Xe99aQqa0GVUsaCkp5oM6xYXx67wU8NqoTC7ekM/LFJXyx4TDudrGqangaCkp5KB9v\nL+4d2p6vHxxC66hgHpyzjknvrCE9r9ju0pQL01BQysN1iAnl499fwJ8v78ziHRkMfX4x//pmKxl5\n2qWkfkvXPlKqEdmTkc/LC3fyVcph/Hy8uLl/PJN+147YJgF2l6acTBfEU0qd1p6MfF5btJvP1h/C\nW4Sb+rVk8kXtaBkRZHdpykk0FJRSZ3XgWCFTluxi3ppUjIEb+rbk3mHtaB0VbHdpqp5pKCilau1Q\ndhFTl+zmg9UHqag0XNOrOfcOa0/7ZroXiKfQUFBK1dnR3GKmLd3Deyv3U1JeyRU94njg4g50ig21\nuzR1njQUlFLnLDO/hBk/7eWd5fsoKK3g0m4xPHBxB7q3aGJ3aeocaSgopc7b8YJS3vplL28t20de\ncTkXd27GAxe3p098hN2lqTrSUFBK1ZucojJmL9vHzF/2kl1YxoUdonng4g70bxNpd2mqljQUlFL1\nLr+knHdX7Gf60j0cKyhlQJtIHhzegQvaRSEidpenzkBDQSnlNEWlFby/6gBTl+wmPa+EvvHhPDC8\nA0M7NtVwcFEaCkoppysuq+Cj5INMWbybwznF9GzZhPuHtWdk1xgNBxejoaCUajCl5ZV8sjaV1xfv\n5kBWIZ1jQ3ng4g5c1j0WLy8NB1egoaCUanDlFZV8vv4wry3axZ7MAto3C2HcgHgu7RZL8/BAu8tr\n1DQUlFK2qag0fL3xCG8s3s2WI7kA9GzZhEu7xXJpt1i9UtoGGgpKKZewJyOfBZuPMn9zGhsOZgPQ\nvlkIoxwB0b1FmI4/NAANBaWUyzmSU8R3m48yf1Maq/ZlUVFpaBEeyCXdYhjVLZakhEi8dQzCKTQU\nlFIuLauglIVbj7JgUxo/7cqktLySqGA/RnaN4dLusVzQLgp/H2+7y/QYtoeCiLQCZgMxgAGmGWP+\nU8N5Q4GXAV8g0xhz0ZmeV0NBKc+TX1LO4u3pLNh8lB+3HqWgtIJQfx+GdW7GqO6xXNSxKcH+PnaX\n6dZcIRTigDhjzFoRCQXWANcaY7acck44sAwYZYw5ICLNjDHpZ3peDQWlPFtxWQXLdmeyYNNRvt96\nlKyCUvx9vLiwQ1NGdY9lRJdmhAf52V2m26ltKDgteo0xR4Ajjtt5IrIVaAFsOeW0W4BPjDEHHOed\nMRCUUp4vwNebizvHcHHnGP5ZUcnqfcdZsDmNBZvTWLj1KN5ewsC2kVzaLZZLusbqVqL1rEHGFEQk\nAVgKdDfG5J5y/4luo25AKPAfY8zsMz2XthSUapyMMaSk5rBgcxrzN6exJ6MAgD7x4VzaLZZR3WJJ\niNYd407H9u6jUwoJAZYA/zTGfFLt2KtAEjAcCASWA1cYY3ZUO28iMBEgPj4+cf/+/U6tWSnl+nal\n5zF/kxUQmw5Z3zW7xoXxn7G96RCjmwJV5xKhICK+wFfAAmPMizUcfwIINMY85fh5JjDfGPPR6Z5T\nWwpKqeoOZhXy3ZajvLFkNxWVhtl39tcNgaqpbSh4ObEAAWYCW2sKBIfPgSEi4iMiQcAAYKuzalJK\neaZWkUHcNaQNH00aRKCvNzdPW8HqfVl2l+WWnBYKwGBgAnCxiKx3/LlcRCaLyGQAY8xWYD6QAqwC\nZhhjNjmxJqWUB0uIDuajyYNoGurPhJkrWbojw+6S3I5evKaU8jiZ+SVMmLmK3en5vHJzH0Z1j7W7\nJNvZ3n2klFJ2iQ7x54N7BtKtRRj3vb+WT9el2l2S29BQUEp5pCZBvrx71wAGtInkkQ838M4KnbVY\nGxoKSimPFezvw5u392NEl2b89bNNTFm82+6SXJ6GglLKowX4ejNlfCJX92rOc/O38fyCbbjbWGpD\n0hWmlFIez9fbi5fG9CbY35vXFu2moKSCv13ZVbcKrYGGglKqUfD2Ev7vuh4E+/kw4+e95JeU8+z1\nPfDx1g6TU2koKKUaDRHhL1d0ITTAl5cW7qCwtJyXx/TBz0eD4QQNBaVUoyIiPDSiA8H+3jzz9VYK\nSpJ5Y3wigX66oQ/oQLNSqpG6+8K2PHt9D5buzOC2t1aRV1xmd0kuQUNBKdVoje0fzytj+7B2/3HG\nzVjJ8YJSu0uynYaCUqpRu6pXc6ZOSGRbWh5jpi0nPbfY7pJspaGglGr0hneJYdYd/Ug9XsSNU5eT\nerzQ7pJso6GglFLABe2ieffuARwvKOXGN5azOyPf7pJsoaGglFIOfeMj+HDSIMoqKrnpjeVsOZx7\n9gd5GA0FpZQ6RZe4MOZOGoS/jxdjpy1nzf7jdpfUoDQUlFKqmrZNQ5g7eRCRwX5MmLmSX3Zl2l1S\ng9FQUEqpGrSMCGLu5EG0igjijlmrWbjlqN0lNQgNBaWUOo1moQF8OGkgXWJDmfzuGr7YcNjukpxO\nQ0Eppc4gPMiP9+4ZSGLrCB76YB1zVh2wuySn0lBQSqmzCPH3YdYd/bmoY1P+9MlGZvy0x+6SnEZD\nQSmlaiHQz5tpE5K4okccz3y9lZe+3+GRm/XoKqlKKVVLfj5evHJzH4L8vPnPDzs5mlvMIyM7EhMW\nYHdp9UZDQSml6sDbS3juhp5EBvsx/ac9fLL2ENf1acE9v2tL+2Yhdpd33sTdmj9JSUkmOTnZ7jKU\nUooDxwqZ/tMe5iYfpLSikpFdYph0UTsSW0fYXdpviMgaY0zSWc/TUFBKqfNzLL+Et5fvZ/byfWQX\nltE/IZJJF7VlWKdmLrMPtIaCUko1sIKScuYmH2TGT3s5lF1Ex5gQJv6uHVf3am77lp8aCkopZZOy\nikq+TjnCG0t2sy0tj7gmAdw1pA1j+8cT4m/PUK6GglJK2cwYw5IdGUxdsofle44RFuDDhEGtuf2C\nNjQN9W/QWjQUlFLKhaw/mM3UJbuZvzkNX28vRie25J4L29ImOrhBXl9DQSmlXNDezAKmLd3Dx2tT\nKauoZFS3WCZf1I5ercKd+roaCkop5cLS84p5e9k+3lm+n9zicga2jWTyRe24qGNTROp/xpKGglJK\nuYH8knI+WHWAGT/tJS23mM6xoUy+qB1X9IzD17v+ZixpKCillBspLa/kiw2HmbpkNzvT82kRHsjd\nF7ZhTL9WBPmd/4wlDQWllHJDlZWGRdvTmbpkD6v2ZREe5MutgxK4bVBrokLOfcaShoJSSrm5NfuP\nM3XJbr7bcpQAXy/+55JO3H1h23N6rtqGgi6Ip5RSLiqxdQTTbk1iV3o+05fuoWVEoNNfU0NBKaVc\nXPtmITw3umeDvJZusqOUUqqKhoJSSqkqTgsFEWklIotEZIuIbBaRh85wbj8RKReR0c6qRyml1Nk5\nc0yhHHjUGLNWREKBNSLyvTFmy6kniYg38BzwnRNrUUopVQtOaykYY44YY9Y6bucBW4EWNZz6APAx\nkO6sWpRSStVOg4wpiEgC0AdYWe3+FsB1wJSGqEMppdSZOT0URCQEqyXwsDEmt9rhl4HHjTGVZ3mO\niSKSLCLJGRkZzipVKaUaPade0SwivsBXwAJjzIs1HN8LnFgOMBooBCYaYz473XPqFc1KKVV3ti9z\nIdbar28DWcaYh2tx/izgK2PMvLOclwHsP8eyooHMc3ysO/Dk96fvzX158vtzp/fW2hjT9GwnOXP2\n0WBgArBRRNY77vszEA9gjHnjXJ60Nm/qdEQkuTZJ6a48+f3pe3Nfnvz+PPG9OS0UjDE/c7JrqDbn\n3+6sWpRSStWOXtGslFKqSmMLhWl2F+Bknvz+9L25L09+fx733txuPwWllFLO09haCkoppc5AQ0Ep\npVSVRhMKIjJKRLaLyC4RecLueupLXVajdVci4i0i60TkK7trqW8iEi4i80Rkm4hsFZFBdtdUX0Tk\nEce/yU0iMkdEAuyu6XyIyJsiki4im065L1JEvheRnY6/I+yssT40ilBwrMT6GnAZ0BW4WUS62ltV\nvTmxGm1XYCBwnwe9txMewlpQ0RP9B5hvjOkM9MJD3qdjXbMHgSRjTHfAGxhrb1XnbRYwqtp9TwA/\nGGM6AD84fnZrjSIUgP7ALmPMHmNMKfABcI3NNdWLOqxG65ZEpCVwBTDD7lrqm4g0AX4HzAQwxpQa\nY7Ltrape+QCBIuIDBAGHba7nvBhjlgJZ1e6+BmvlBhx/X9ugRTlBYwmFFsDBU35OxYM+OE843Wq0\nbu5l4DHgjIsmuqk2QAbwlqN7bIaIBNtdVH0wxhwCXgAOAEeAHGOMJ+6ZEmOMOeK4nQbE2FlMfWgs\noeDxzrIarVsSkSuBdGPMGrtrcRIfoC8wxRjTByjAA7ofABx969dgBV9zIFhExttblXMZa36/28/x\nbyyhcAhodcrPLR33eQTHarQfA+8ZYz6xu556NBi4WkT2YXX5XSwi79pbUr1KBVKNMSdadvOwQsIT\njAD2GmMyjDFlwCfABTbX5AxHRSQOwPG3228W1lhCYTXQQUTaiIgf1oDXFzbXVC8cq9HOBLbWtDy5\nOzPG/MkY09IYk4D13+xHY4zHfNs0xqQBB0Wkk+Ou4cCWMzzEnRwABopIkOPf6HA8ZBC9mi+A2xy3\nbwM+t7GWeuHMVVJdhjGmXETuBxZgzYJ40xiz2eay6kuNq9EaY76xsSZVew8A7zm+rOwB7rC5nnph\njFkpIvOAtVgz5Nbh5ktCiMgcYCgQLSKpwFPAs8BcEbkLa0n/m+yrsH7oMhdKKaWqNJbuI6WUUrWg\noaCUUqqKhoJSSqkqGgpKKaWqaCgopZSqoqGgVAMSkaGeuNqr8hwaCkoppapoKChVAxEZLyKrRGS9\niEx17OmQLyIvOfYI+EFEmjrO7S0iK0QkRUQ+PbGmvoi0F5GFIrJBRNaKSDvH04ecsofCe44rfpVy\nCRoKSlUjIl2AMcBgY0xvoAIYBwQDycaYbsASrCtaAWYDjxtjegIbT7n/PeA1Y0wvrHV/Tqym2Qd4\nGGtvj7ZYV6Ur5RIaxTIXStXRcCARWO34Eh+ItdBZJfCh45x3gU8ceyKEG2OWOO5/G/hIREKBFsaY\nTwGMMcUAjudbZYxJdfy8HkgAfnb+21Lq7DQUlPotAd42xvzpV3eK/LXaeee6RkzJKbcr0P8PlQvR\n7iOlfusHYLSINIOqfXhbY/3/Mtpxzi3Az8aYHOC4iFzouH8CsMSxC16qiFzreA5/EQlq0Heh1DnQ\nbyhKVWOM2SIiTwLfiYgXUAbch7UJTn/HsXSscQewlkx+w/Ghf+pKpxOAqSLytOM5bmzAt6HUOdFV\nUpWqJRHJN8aE2F2HUs6k3UdKKaWqaEtBKaVUFW0pKKWUqqKhoJRSqoqGglJKqSoaCkoppapoKCil\nlKry/wHK8Cq5gCNhKQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f23214d4f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3122 samples, validate on 1369 samples\n",
      "Epoch 1/1\n",
      "3122/3122 [==============================] - 0s - loss: 2.4203 - acc: 0.2309 - val_loss: 3.1366 - val_acc: 0.0504\n",
      "ll_model.optimizer.lr: 1e-07\n",
      "train_last_layer, model just created from Vgg16(), # layers =  38\n",
      "@ end of train_last_layer, # layers =  38\n",
      "Number of layers :  38\n",
      "0 <class 'keras.layers.core.Lambda'> , trainable: False\n",
      "input: (None, 3, 224, 224) , output: (None, 3, 224, 224) , len(weights) 0 \n",
      "\n",
      "1 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 3, 224, 224) , output: (None, 3, 226, 226) , len(weights) 0 \n",
      "\n",
      "2 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 3, 226, 226) , output: (None, 64, 224, 224) , len(weights) 2 \n",
      "\n",
      "3 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 64, 224, 224) , output: (None, 64, 226, 226) , len(weights) 0 \n",
      "\n",
      "4 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 64, 226, 226) , output: (None, 64, 224, 224) , len(weights) 2 \n",
      "\n",
      "5 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: False\n",
      "input: (None, 64, 224, 224) , output: (None, 64, 112, 112) , len(weights) 0 \n",
      "\n",
      "6 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 64, 112, 112) , output: (None, 64, 114, 114) , len(weights) 0 \n",
      "\n",
      "7 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 64, 114, 114) , output: (None, 128, 112, 112) , len(weights) 2 \n",
      "\n",
      "8 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 128, 112, 112) , output: (None, 128, 114, 114) , len(weights) 0 \n",
      "\n",
      "9 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 128, 114, 114) , output: (None, 128, 112, 112) , len(weights) 2 \n",
      "\n",
      "10 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: False\n",
      "input: (None, 128, 112, 112) , output: (None, 128, 56, 56) , len(weights) 0 \n",
      "\n",
      "11 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 128, 56, 56) , output: (None, 128, 58, 58) , len(weights) 0 \n",
      "\n",
      "12 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 128, 58, 58) , output: (None, 256, 56, 56) , len(weights) 2 \n",
      "\n",
      "13 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 58, 58) , len(weights) 0 \n",
      "\n",
      "14 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 256, 58, 58) , output: (None, 256, 56, 56) , len(weights) 2 \n",
      "\n",
      "15 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 58, 58) , len(weights) 0 \n",
      "\n",
      "16 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 256, 58, 58) , output: (None, 256, 56, 56) , len(weights) 2 \n",
      "\n",
      "17 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: False\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 28, 28) , len(weights) 0 \n",
      "\n",
      "18 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 256, 28, 28) , output: (None, 256, 30, 30) , len(weights) 0 \n",
      "\n",
      "19 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 256, 30, 30) , output: (None, 512, 28, 28) , len(weights) 2 \n",
      "\n",
      "20 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 30, 30) , len(weights) 0 \n",
      "\n",
      "21 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 512, 30, 30) , output: (None, 512, 28, 28) , len(weights) 2 \n",
      "\n",
      "22 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 30, 30) , len(weights) 0 \n",
      "\n",
      "23 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 512, 30, 30) , output: (None, 512, 28, 28) , len(weights) 2 \n",
      "\n",
      "24 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: False\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 14, 14) , len(weights) 0 \n",
      "\n",
      "25 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) , len(weights) 0 \n",
      "\n",
      "26 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) , len(weights) 2 \n",
      "\n",
      "27 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) , len(weights) 0 \n",
      "\n",
      "28 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) , len(weights) 2 \n",
      "\n",
      "29 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) , len(weights) 0 \n",
      "\n",
      "30 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) , len(weights) 2 \n",
      "\n",
      "31 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: False\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 7, 7) , len(weights) 0 \n",
      "\n",
      "32 <class 'keras.layers.core.Flatten'> , trainable: False\n",
      "input: (None, 512, 7, 7) , output: (None, 25088) , len(weights) 0 \n",
      "\n",
      "33 <class 'keras.layers.core.Dense'> , trainable: False\n",
      "input: (None, 25088) , output: (None, 4096) , len(weights) 2 \n",
      "\n",
      "34 <class 'keras.layers.core.Dropout'> , trainable: False\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 0 \n",
      "\n",
      "35 <class 'keras.layers.normalization.BatchNormalization'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 4 \n",
      "\n",
      "36 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 0 \n",
      "\n",
      "37 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 10) , len(weights) 2 \n",
      "\n",
      "start: train_dense_layers: i: 0\n",
      "len(model.layers): 38\n",
      "train_dense_layers: showLayersInfo(fc_model):-----------START------------------------\n",
      "Number of layers :  7\n",
      "0 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 7, 7) , len(weights) 0 \n",
      "\n",
      "1 <class 'keras.layers.core.Flatten'> , trainable: True\n",
      "input: (None, 512, 7, 7) , output: (None, 25088) , len(weights) 0 \n",
      "\n",
      "2 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 25088) , output: (None, 4096) , len(weights) 2 \n",
      "\n",
      "3 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 0 \n",
      "\n",
      "4 <class 'keras.layers.normalization.BatchNormalization'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 4 \n",
      "\n",
      "5 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 0 \n",
      "\n",
      "6 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 10) , len(weights) 2 \n",
      "\n",
      "train_dense_layers: showLayersInfo(Sequential(fc_layers)):-----------START-----------\n",
      "Number of layers :  7\n",
      "0 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: False\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 7, 7) , len(weights) 0 \n",
      "\n",
      "1 <class 'keras.layers.core.Flatten'> , trainable: False\n",
      "input: (None, 512, 7, 7) , output: (None, 25088) , len(weights) 0 \n",
      "\n",
      "2 <class 'keras.layers.core.Dense'> , trainable: False\n",
      "input: (None, 25088) , output: (None, 4096) , len(weights) 2 \n",
      "\n",
      "3 <class 'keras.layers.core.Dropout'> , trainable: False\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 0 \n",
      "\n",
      "4 <class 'keras.layers.normalization.BatchNormalization'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 4 \n",
      "\n",
      "5 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 0 \n",
      "\n",
      "6 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 10) , len(weights) 2 \n",
      "\n",
      "-----------------------END-----------------------------------------------------------\n",
      "len(fc_model.layers): 7\n",
      "len(fc_layers): 7\n",
      "count: 0\n",
      "l1: <keras.layers.pooling.MaxPooling2D object at 0x7f231e06c350>\n",
      "l2: <keras.layers.pooling.MaxPooling2D object at 0x7f231e2cb510>\n",
      "l1.get_weights(): 0\n",
      "l2.get_weights(): 0\n",
      "count: 1\n",
      "l1: <keras.layers.core.Flatten object at 0x7f231e449150>\n",
      "l2: <keras.layers.core.Flatten object at 0x7f231e2a6390>\n",
      "l1.get_weights(): 0\n",
      "l2.get_weights(): 0\n",
      "count: 2\n",
      "l1: <keras.layers.core.Dense object at 0x7f231e077090>\n",
      "l2: <keras.layers.core.Dense object at 0x7f231e2ae110>\n",
      "l1.get_weights(): 2\n",
      "l2.get_weights(): 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 3\n",
      "l1: <keras.layers.core.Dropout object at 0x7f231e077110>\n",
      "l2: <keras.layers.core.Dropout object at 0x7f231e2aebd0>\n",
      "l1.get_weights(): 0\n",
      "l2.get_weights(): 0\n",
      "count: 4\n",
      "l1: <keras.layers.normalization.BatchNormalization object at 0x7f231e077150>\n",
      "l2: <keras.layers.normalization.BatchNormalization object at 0x7f231e1cac10>\n",
      "l1.get_weights(): 4\n",
      "l2.get_weights(): 4\n",
      "count: 5\n",
      "l1: <keras.layers.core.Dropout object at 0x7f231e0771d0>\n",
      "l2: <keras.layers.core.Dropout object at 0x7f231e2b4610>\n",
      "l1.get_weights(): 0\n",
      "l2.get_weights(): 0\n",
      "count: 6\n",
      "l1: <keras.layers.core.Dense object at 0x7f231e077210>\n",
      "l2: <keras.layers.core.Dense object at 0x7f231e26f350>\n",
      "l1.get_weights(): 2\n",
      "l2.get_weights(): 2\n",
      "marker AA\n",
      "Train on 3122 samples, validate on 1369 samples\n",
      "Epoch 1/2\n",
      "3122/3122 [==============================] - 5s - loss: 2.3107 - acc: 0.2966 - val_loss: 0.6170 - val_acc: 0.8232\n",
      "Epoch 2/2\n",
      "3122/3122 [==============================] - 5s - loss: 0.9527 - acc: 0.6931 - val_loss: 0.2975 - val_acc: 0.9343\n",
      "marker BB\n",
      "marker CC\n",
      "marker DD\n",
      "type(val_batches): <class 'keras.preprocessing.image.NumpyArrayIterator'> val_batches.n: 1369\n",
      "len(conv_model.layers): 31\n",
      "marker EE-all layers in conv_model set to non trainable\n",
      "showLayersInfo(conv_model): after 1. setting layers to non trainable & 2. adding get_fc_layers to conv_model\n",
      "Number of layers :  38\n",
      "0 <class 'keras.layers.core.Lambda'> , trainable: False\n",
      "input: (None, 3, 224, 224) , output: (None, 3, 224, 224) , len(weights) 0 \n",
      "\n",
      "1 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 3, 224, 224) , output: (None, 3, 226, 226) , len(weights) 0 \n",
      "\n",
      "2 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 3, 226, 226) , output: (None, 64, 224, 224) , len(weights) 2 \n",
      "\n",
      "3 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 64, 224, 224) , output: (None, 64, 226, 226) , len(weights) 0 \n",
      "\n",
      "4 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 64, 226, 226) , output: (None, 64, 224, 224) , len(weights) 2 \n",
      "\n",
      "5 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: False\n",
      "input: (None, 64, 224, 224) , output: (None, 64, 112, 112) , len(weights) 0 \n",
      "\n",
      "6 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 64, 112, 112) , output: (None, 64, 114, 114) , len(weights) 0 \n",
      "\n",
      "7 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 64, 114, 114) , output: (None, 128, 112, 112) , len(weights) 2 \n",
      "\n",
      "8 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 128, 112, 112) , output: (None, 128, 114, 114) , len(weights) 0 \n",
      "\n",
      "9 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 128, 114, 114) , output: (None, 128, 112, 112) , len(weights) 2 \n",
      "\n",
      "10 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: False\n",
      "input: (None, 128, 112, 112) , output: (None, 128, 56, 56) , len(weights) 0 \n",
      "\n",
      "11 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 128, 56, 56) , output: (None, 128, 58, 58) , len(weights) 0 \n",
      "\n",
      "12 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 128, 58, 58) , output: (None, 256, 56, 56) , len(weights) 2 \n",
      "\n",
      "13 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 58, 58) , len(weights) 0 \n",
      "\n",
      "14 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 256, 58, 58) , output: (None, 256, 56, 56) , len(weights) 2 \n",
      "\n",
      "15 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 58, 58) , len(weights) 0 \n",
      "\n",
      "16 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 256, 58, 58) , output: (None, 256, 56, 56) , len(weights) 2 \n",
      "\n",
      "17 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: False\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 28, 28) , len(weights) 0 \n",
      "\n",
      "18 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 256, 28, 28) , output: (None, 256, 30, 30) , len(weights) 0 \n",
      "\n",
      "19 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 256, 30, 30) , output: (None, 512, 28, 28) , len(weights) 2 \n",
      "\n",
      "20 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 30, 30) , len(weights) 0 \n",
      "\n",
      "21 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 512, 30, 30) , output: (None, 512, 28, 28) , len(weights) 2 \n",
      "\n",
      "22 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 30, 30) , len(weights) 0 \n",
      "\n",
      "23 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 512, 30, 30) , output: (None, 512, 28, 28) , len(weights) 2 \n",
      "\n",
      "24 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: False\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 14, 14) , len(weights) 0 \n",
      "\n",
      "25 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) , len(weights) 0 \n",
      "\n",
      "26 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) , len(weights) 2 \n",
      "\n",
      "27 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) , len(weights) 0 \n",
      "\n",
      "28 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) , len(weights) 2 \n",
      "\n",
      "29 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) , len(weights) 0 \n",
      "\n",
      "30 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) , len(weights) 2 \n",
      "\n",
      "31 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 7, 7) , len(weights) 0 \n",
      "\n",
      "32 <class 'keras.layers.core.Flatten'> , trainable: True\n",
      "input: (None, 512, 7, 7) , output: (None, 25088) , len(weights) 0 \n",
      "\n",
      "33 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 25088) , output: (None, 4096) , len(weights) 2 \n",
      "\n",
      "34 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 0 \n",
      "\n",
      "35 <class 'keras.layers.normalization.BatchNormalization'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 4 \n",
      "\n",
      "36 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 0 \n",
      "\n",
      "37 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 10) , len(weights) 2 \n",
      "\n",
      "marker FF-copied weights from fc_model.layers to the layers after last_conv_idx in conv_model.\n",
      "Epoch 1/1\n",
      "3122/3122 [==============================] - 116s - loss: 2.0489 - acc: 0.3828 - val_loss: 0.2797 - val_acc: 0.9277\n",
      "showLayersInfo(conv_model): after 1. copying weights to conv_model from fc_model.layers.\n",
      "2. fitting, setting layers 16: to trainable.\n",
      "Number of layers :  38\n",
      "0 <class 'keras.layers.core.Lambda'> , trainable: False\n",
      "input: (None, 3, 224, 224) , output: (None, 3, 224, 224) , len(weights) 0 \n",
      "\n",
      "1 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 3, 224, 224) , output: (None, 3, 226, 226) , len(weights) 0 \n",
      "\n",
      "2 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 3, 226, 226) , output: (None, 64, 224, 224) , len(weights) 2 \n",
      "\n",
      "3 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 64, 224, 224) , output: (None, 64, 226, 226) , len(weights) 0 \n",
      "\n",
      "4 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 64, 226, 226) , output: (None, 64, 224, 224) , len(weights) 2 \n",
      "\n",
      "5 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: False\n",
      "input: (None, 64, 224, 224) , output: (None, 64, 112, 112) , len(weights) 0 \n",
      "\n",
      "6 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 64, 112, 112) , output: (None, 64, 114, 114) , len(weights) 0 \n",
      "\n",
      "7 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 64, 114, 114) , output: (None, 128, 112, 112) , len(weights) 2 \n",
      "\n",
      "8 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 128, 112, 112) , output: (None, 128, 114, 114) , len(weights) 0 \n",
      "\n",
      "9 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 128, 114, 114) , output: (None, 128, 112, 112) , len(weights) 2 \n",
      "\n",
      "10 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: False\n",
      "input: (None, 128, 112, 112) , output: (None, 128, 56, 56) , len(weights) 0 \n",
      "\n",
      "11 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 128, 56, 56) , output: (None, 128, 58, 58) , len(weights) 0 \n",
      "\n",
      "12 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 128, 58, 58) , output: (None, 256, 56, 56) , len(weights) 2 \n",
      "\n",
      "13 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 58, 58) , len(weights) 0 \n",
      "\n",
      "14 <class 'keras.layers.convolutional.Convolution2D'> , trainable: False\n",
      "input: (None, 256, 58, 58) , output: (None, 256, 56, 56) , len(weights) 2 \n",
      "\n",
      "15 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: False\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 58, 58) , len(weights) 0 \n",
      "\n",
      "16 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 58, 58) , output: (None, 256, 56, 56) , len(weights) 2 \n",
      "\n",
      "17 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 256, 56, 56) , output: (None, 256, 28, 28) , len(weights) 0 \n",
      "\n",
      "18 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 256, 28, 28) , output: (None, 256, 30, 30) , len(weights) 0 \n",
      "\n",
      "19 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 256, 30, 30) , output: (None, 512, 28, 28) , len(weights) 2 \n",
      "\n",
      "20 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 30, 30) , len(weights) 0 \n",
      "\n",
      "21 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 30, 30) , output: (None, 512, 28, 28) , len(weights) 2 \n",
      "\n",
      "22 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 30, 30) , len(weights) 0 \n",
      "\n",
      "23 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 30, 30) , output: (None, 512, 28, 28) , len(weights) 2 \n",
      "\n",
      "24 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 28, 28) , output: (None, 512, 14, 14) , len(weights) 0 \n",
      "\n",
      "25 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) , len(weights) 0 \n",
      "\n",
      "26 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) , len(weights) 2 \n",
      "\n",
      "27 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) , len(weights) 0 \n",
      "\n",
      "28 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) , len(weights) 2 \n",
      "\n",
      "29 <class 'keras.layers.convolutional.ZeroPadding2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 16, 16) , len(weights) 0 \n",
      "\n",
      "30 <class 'keras.layers.convolutional.Convolution2D'> , trainable: True\n",
      "input: (None, 512, 16, 16) , output: (None, 512, 14, 14) , len(weights) 2 \n",
      "\n",
      "31 <class 'keras.layers.pooling.MaxPooling2D'> , trainable: True\n",
      "input: (None, 512, 14, 14) , output: (None, 512, 7, 7) , len(weights) 0 \n",
      "\n",
      "32 <class 'keras.layers.core.Flatten'> , trainable: True\n",
      "input: (None, 512, 7, 7) , output: (None, 25088) , len(weights) 0 \n",
      "\n",
      "33 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 25088) , output: (None, 4096) , len(weights) 2 \n",
      "\n",
      "34 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 0 \n",
      "\n",
      "35 <class 'keras.layers.normalization.BatchNormalization'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 4 \n",
      "\n",
      "36 <class 'keras.layers.core.Dropout'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 4096) , len(weights) 0 \n",
      "\n",
      "37 <class 'keras.layers.core.Dense'> , trainable: True\n",
      "input: (None, 4096) , output: (None, 10) , len(weights) 2 \n",
      "\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3122/3122 [==============================] - 117s - loss: 1.5185 - acc: 0.5077 - val_loss: 0.2468 - val_acc: 0.9350\n",
      "Epoch 2/8\n",
      "3122/3122 [==============================] - 116s - loss: 1.1898 - acc: 0.5993 - val_loss: 0.2151 - val_acc: 0.9452\n",
      "Epoch 3/8\n",
      "3122/3122 [==============================] - 116s - loss: 0.9669 - acc: 0.6813 - val_loss: 0.1833 - val_acc: 0.9533\n",
      "Epoch 4/8\n",
      "3122/3122 [==============================] - 116s - loss: 0.8552 - acc: 0.7293 - val_loss: 0.1638 - val_acc: 0.9591\n",
      "Epoch 5/8\n",
      "3122/3122 [==============================] - 116s - loss: 0.7185 - acc: 0.7723 - val_loss: 0.1595 - val_acc: 0.9627\n",
      "Epoch 6/8\n",
      "3122/3122 [==============================] - 116s - loss: 0.6370 - acc: 0.8011 - val_loss: 0.1499 - val_acc: 0.9627\n",
      "Epoch 7/8\n",
      "3122/3122 [==============================] - 116s - loss: 0.5520 - acc: 0.8232 - val_loss: 0.1451 - val_acc: 0.9591\n",
      "Epoch 8/8\n",
      "3122/3122 [==============================] - 116s - loss: 0.5021 - acc: 0.8360 - val_loss: 0.1259 - val_acc: 0.9679\n",
      "history = conv_model.fit_generator(blah....), conv_model.optimizer.lr: <CudaNdarrayType(float32, scalar)>\n",
      "['acc', 'loss', 'val_acc', 'val_loss']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUyiIiEiYQkFERML+P5lvn0xEHQTKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f231b65dd50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2315f44750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3122/3122 [==============================] - 117s - loss: 0.4598 - acc: 0.8479 - val_loss: 0.1211 - val_acc: 0.9657\n",
      "Epoch 2/10\n",
      "3122/3122 [==============================] - 116s - loss: 0.3981 - acc: 0.8770 - val_loss: 0.1002 - val_acc: 0.9730\n",
      "Epoch 3/10\n",
      "3122/3122 [==============================] - 116s - loss: 0.3853 - acc: 0.8799 - val_loss: 0.0998 - val_acc: 0.9766\n",
      "Epoch 4/10\n",
      " 256/3122 [=>............................] - ETA: 75s - loss: 0.3324 - acc: 0.8906"
     ]
    }
   ],
   "source": [
    "#build the ensemble\n",
    "#multiple model builds, model trainings. takes long time.\n",
    "for i in range(5):\n",
    "    i = str(i)\n",
    "    print (\"i:\", i)\n",
    "    model = train_last_layer(i)\n",
    "    #a tthis point, model = vgg16 model, minus last three layers, plus layers BatchNormalization + Dropout + Dense\n",
    "    #get_ll_layers:create 3 layers, BatchNormalization + Dropout + Dense\n",
    "    #train_last_layer uses get_ll_layers to create 3 layer model, trains it, then pops last 3 layers from vgg16model\n",
    "    #at end of train_last_layer model has 38 layers with last three layers being BatchNormalization + Dropout + Dense\n",
    "\n",
    "    train_dense_layers(i, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print (MODEL_PATH + s_or_p + 'aug' + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_model2 = train_last_layer(str(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in ens_model2.layers: layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ens_pred(arr, fname):\n",
    "    ens_pred = []\n",
    "    for i in range(5):\n",
    "        i = str(i)\n",
    "        print (\"loading weights file:\", i)\n",
    "        ens_model2.load_weights('{}{}{}.h5'.format(MODEL_PATH, fname, i))\n",
    "        print (\"predicting from weights file:\", i)\n",
    "        preds = ens_model2.predict(arr, batch_size=batch_size)\n",
    "        ens_pred.append(preds)\n",
    "        print (\"len(ens_pred):\", len(ens_pred), \", len(preds):\", len(preds))\n",
    "    return ens_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall: val = get_data(WORKING_VALID)\n",
    "#val: (1500, 3, 224, 224)\n",
    "\n",
    "val_pred2 = get_ens_pred(val, 'aug')\n",
    "#nb: this loads weights from the files with 'aug' in filename. this is the final model build in method train_dense_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"len(val_pred2):\", len(val_pred2))\n",
    "print(val_pred2[0].shape)\n",
    "print(val_pred2[0][0:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc categorical_accuracy for each prediction and for the average.\n",
    "cat_acc = []\n",
    "for i in range(5):\n",
    "    temp_val_preds = val_pred2[i]\n",
    "    print (\"i:\", i, type(temp_val_preds), temp_val_preds.shape)\n",
    "    cat_acc.append(float(categorical_accuracy(val_labels, temp_val_preds).eval()))\n",
    "    print (\"i:\", i, type(temp_val_preds), temp_val_preds.shape, \", categorical accuracy:\", cat_acc[i])\n",
    "print (\"cat_acc:\", type(cat_acc), cat_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_avg_preds2 = np.stack(val_pred2).mean(axis=0)\n",
    "#get the mean prediction across all \n",
    "print (\"type(val_avg_preds2):\", type(val_avg_preds2), val_avg_preds2.shape)\n",
    "print(val_avg_preds2[0:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"categorical accuracy from mean      :\", float(categorical_accuracy(val_labels, val_avg_preds2).eval()))\n",
    "print (\"best individual categorical accuracy:\", np.max(cat_acc))\n",
    "#NB: mean accuracy is higher because it is choosing the best prediction row by row. then comparing with actual category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall: test = get_data(WORKING_TEST)\n",
    "#<type 'numpy.ndarray'> (2500, 3, 224, 224)\n",
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "\n",
    "test_pred2 = get_ens_pred(test, 'aug')\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "\n",
    "#print (\"test_pred2.shape:\", test_pred2.shape)\n",
    "#approx time to run : production version: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"len(val_pred2):\", len(test_pred2))\n",
    "print(test_pred2[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_pred2[0][0:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_test_pred2 = np.stack(test_pred2).mean(axis=0)\n",
    "#get the mean prediction across all \n",
    "print (\"type(avg_test_pred2):\", type(avg_test_pred2), avg_test_pred2.shape)\n",
    "print(avg_test_pred2[0:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_test_pred2 = avg_test_pred2[:,1]\n",
    "print (\"type(avg_test_pred2):\", type(avg_test_pred2), avg_test_pred2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB: need to check last few block suit 10 category predictions and output format required for kaggle submisison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission : must have 79726 rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
